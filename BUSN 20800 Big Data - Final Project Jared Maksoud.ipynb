{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# BUSN 20800 Big Data Final project\n",
    "\n",
    "## Due date: March 8th, 2024, 11:59 a.m. (not p.m.!)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Problem 1: Text Analysis of Presidents' Addresses (50 points)\n",
    "\n",
    "The State of the Union is an annual address by the President of the United States before a joint session of congress. In it, the President reviews the previous year and lays out his legislative agenda for the coming year. This dataset contains the full text of the State of the Union address from 1790 (Washington) to 2021 (Biden). http://stateoftheunion.onetwothree.net/texts/index.html\n",
    "\n",
    "In this project, you are requested to analyze the addresses delivered by presidents. All functions are provided as given and you don't need to modify any of them."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Run the following codes to load the data, you don't need to modify any codes here."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "import numpy as np\n",
    "import pylab as py\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from nltk.corpus import stopwords\n",
    "import nltk\n",
    "from tqdm import tqdm\n",
    "import pickle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>president</th>\n",
       "      <th>text</th>\n",
       "      <th>year</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>James Monroe</td>\n",
       "      <td>Fellow-Citizens of the Senate and House of Re...</td>\n",
       "      <td>1821</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>William McKinley</td>\n",
       "      <td>To the Senate and House of Representatives:\\r...</td>\n",
       "      <td>1897</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Dwight D. Eisenhower</td>\n",
       "      <td>[Delivered in person before a joint session] \\...</td>\n",
       "      <td>1960</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Calvin Coolidge</td>\n",
       "      <td>Since the close of the last Congress the Natio...</td>\n",
       "      <td>1923</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>James Madison</td>\n",
       "      <td>Fellow-Citizens of the Senate and House of Re...</td>\n",
       "      <td>1816</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "              president                                               text  \\\n",
       "0          James Monroe   Fellow-Citizens of the Senate and House of Re...   \n",
       "1      William McKinley   To the Senate and House of Representatives:\\r...   \n",
       "2  Dwight D. Eisenhower  [Delivered in person before a joint session] \\...   \n",
       "3       Calvin Coolidge  Since the close of the last Congress the Natio...   \n",
       "4         James Madison   Fellow-Citizens of the Senate and House of Re...   \n",
       "\n",
       "   year  \n",
       "0  1821  \n",
       "1  1897  \n",
       "2  1960  \n",
       "3  1923  \n",
       "4  1816  "
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "open_file = open('speech', \"rb\")\n",
    "speeches = pickle.load(open_file)\n",
    "open_file.close()\n",
    "\n",
    "df_speech = pd.DataFrame(speeches)\n",
    "df_speech.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#  Part I. LDA model (10 points)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### What is LDA?\n",
    "\n",
    "latent Dirichlet allocation (LDA) is a generative probabilistic model for collections ofdiscrete data such as text corpora. LDA is a three-level hierarchical Bayesian model, in which each item of a collection is modeled as a finite mixture over an underlying set of topics. The \"latent\" part of LDA refers to the fact that the topic structure—the topics themselves, the distribution of topics in each document, and the distribution of words in each topic—are hidden structures that the model aims to learn from the observed documents.\n",
    "\n",
    "Here are some key concepts:\n",
    "\n",
    "- Document: In LDA, a document is a sequence of words. A document can be as long or as short as desired, but LDA typically works best with documents that are not too short, as longer documents provide more context for learning relationships between words.\n",
    "\n",
    "- Corpus: A collection of documents. The corpus is the entire dataset that you wish to analyze using LDA.\n",
    "\n",
    "- Topic: An abstract theme or subject area that is prevalent across a collection of documents. In LDA, a topic is represented as a distribution over words, meaning that each topic is characterized by certain words that are more likely to appear in that topic.\n",
    "\n",
    "- Word: The basic unit of text analysis in LDA. Words are considered tokens and are the elements that are distributed across topics.\n",
    "\n",
    "Link of the original paper: https://www.jmlr.org/papers/volume3/blei03a/blei03a.pdf"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Run the following codes to preprocess the data, you don't need to modify any codes here."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# !pip install pyLDAvis # run this code if you don't have this package"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt to\n",
      "[nltk_data]     /Users/jaredmaksoud/nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n",
      "[nltk_data] Downloading package averaged_perceptron_tagger to\n",
      "[nltk_data]     /Users/jaredmaksoud/nltk_data...\n",
      "[nltk_data]   Package averaged_perceptron_tagger is already up-to-\n",
      "[nltk_data]       date!\n",
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     /Users/jaredmaksoud/nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n",
      "[nltk_data] Downloading package wordnet to\n",
      "[nltk_data]     /Users/jaredmaksoud/nltk_data...\n",
      "[nltk_data]   Package wordnet is already up-to-date!\n",
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     /Users/jaredmaksoud/nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import re\n",
    "from nltk.corpus import wordnet\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "import gensim\n",
    "from gensim import corpora\n",
    "import pyLDAvis\n",
    "import pyLDAvis.gensim as gensimvis # package for LDA visualization\n",
    "\n",
    "# Download necessary NLTK resources\n",
    "nltk.download('punkt')\n",
    "nltk.download('averaged_perceptron_tagger')\n",
    "nltk.download('stopwords')\n",
    "nltk.download('wordnet')\n",
    "nltk.download('stopwords')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_wordnet_pos(treebank_tag):\n",
    "    \"\"\"\n",
    "    Convert treebank tag to wordnet tag.\n",
    "    \n",
    "    Parameters:\n",
    "    - treebank_tag (str): The part-of-speech tag in Penn Treebank notation.\n",
    "    \"\"\"\n",
    "    \n",
    "    if treebank_tag.startswith('J'):\n",
    "        return wordnet.ADJ  # Adjective\n",
    "    elif treebank_tag.startswith('V'):\n",
    "        return wordnet.VERB  # Verb\n",
    "    elif treebank_tag.startswith('N'):\n",
    "        return wordnet.NOUN  # Noun\n",
    "    elif treebank_tag.startswith('R'):\n",
    "        return wordnet.ADV   # Adverb\n",
    "    else:\n",
    "        return wordnet.VERB  # Default to verb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def normalizeText(input):\n",
    "    \"\"\"\n",
    "    Cleans and normalizes the input text by removing various types of characters and patterns.\n",
    "\n",
    "    Parameters:\n",
    "    - input (str): The text to be normalized.\n",
    "    \"\"\"\n",
    "    \n",
    "    text = re.sub(r'\\n+', \" \", input)  # change \\n to \" \"\n",
    "    text = re.sub(r'\\[[0-9]*\\]', \"\", text)  # Delete [1]\n",
    "    text = re.sub(r' +', \" \", text)  # Change several \" \" to one \" \"\n",
    "    text = re.sub(r'\\(end\\)', \"\", text)  # Delete (end)\n",
    "\n",
    "    text = re.sub(r'@[^\\s]+', '', text)\n",
    "    text = re.sub(r'#([^\\s]+)', '', text)\n",
    "    text = re.sub(r'[:;>?<=*+()&,\\-#!$%\\{˜|\\}\\[^_\\\\@\\]1234567890’‘]', ' ', text)  # Special char\n",
    "    text = re.sub(r'[\\d]', '', text)  # decimal digit\n",
    "    text = text.replace(\".\", '')  # Delete .\n",
    "    text = text.replace(\"`\", '')  # Delete `\n",
    "    text = text.replace(\"'s\", '')  # Delete 's\n",
    "    text = text.replace(\"'\", '')  # Delete '\n",
    "    text = text.replace(\"/\", ' ')\n",
    "    text = text.replace(\"\\\"\", ' ')\n",
    "    text = text.replace(\"\\\\\", '')\n",
    "    text = re.sub(r\"\\b[a-z]\\b\", \"\", text)\n",
    "    text = re.sub(r'\\s+', ' ', text)  # Delete \\s\n",
    "\n",
    "    text = text.strip()  # delete spaces at beginning and ending\n",
    "\n",
    "    return text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def clean_word(text):\n",
    "    \"\"\"\n",
    "    The function leverages NLTK for tokenization, stopword removal, part-of-speech tagging, and lemmatization.\n",
    "    \n",
    "    Parameters:\n",
    "    - text (str): The text to be cleaned and processed.\n",
    "    \"\"\"\n",
    "\n",
    "    text = text.lower()\n",
    "    text = normalizeText(text)\n",
    "    tokenized_text = nltk.word_tokenize(text)\n",
    "    word = [w for w in tokenized_text if w.isalpha()]\n",
    "    \n",
    "    # delete stop words\n",
    "    stop_words = set(stopwords.words('english'))  # Stopwords_set\n",
    "    stop_words.add('could')\n",
    "    stop_words.add('would')\n",
    "    stop_words.add('shall')\n",
    "    tokens = [w for w in word if not w in stop_words]\n",
    "        \n",
    "    # lemmatize\n",
    "    res    = []\n",
    "    for w, pos in nltk.tag.pos_tag(tokens):\n",
    "        wordnet_pos = get_wordnet_pos(pos)\n",
    "        res.append(WordNetLemmatizer().lemmatize(w, pos=wordnet_pos))\n",
    "    return res"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>president</th>\n",
       "      <th>text</th>\n",
       "      <th>year</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>James Monroe</td>\n",
       "      <td>Fellow-Citizens of the Senate and House of Re...</td>\n",
       "      <td>1821</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>William McKinley</td>\n",
       "      <td>To the Senate and House of Representatives:\\r...</td>\n",
       "      <td>1897</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Dwight D. Eisenhower</td>\n",
       "      <td>[Delivered in person before a joint session] \\...</td>\n",
       "      <td>1960</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Calvin Coolidge</td>\n",
       "      <td>Since the close of the last Congress the Natio...</td>\n",
       "      <td>1923</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>James Madison</td>\n",
       "      <td>Fellow-Citizens of the Senate and House of Re...</td>\n",
       "      <td>1816</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "              president                                               text  \\\n",
       "0          James Monroe   Fellow-Citizens of the Senate and House of Re...   \n",
       "1      William McKinley   To the Senate and House of Representatives:\\r...   \n",
       "2  Dwight D. Eisenhower  [Delivered in person before a joint session] \\...   \n",
       "3       Calvin Coolidge  Since the close of the last Congress the Natio...   \n",
       "4         James Madison   Fellow-Citizens of the Senate and House of Re...   \n",
       "\n",
       "   year  \n",
       "0  1821  \n",
       "1  1897  \n",
       "2  1960  \n",
       "3  1923  \n",
       "4  1816  "
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_speeches = pd.DataFrame(speeches)\n",
    "df_speeches.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 54.2 s, sys: 736 ms, total: 54.9 s\n",
      "Wall time: 57.7 s\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>president</th>\n",
       "      <th>text</th>\n",
       "      <th>year</th>\n",
       "      <th>word</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>James Monroe</td>\n",
       "      <td>Fellow-Citizens of the Senate and House of Re...</td>\n",
       "      <td>1821</td>\n",
       "      <td>[fellow, citizen, senate, house, representativ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>William McKinley</td>\n",
       "      <td>To the Senate and House of Representatives:\\r...</td>\n",
       "      <td>1897</td>\n",
       "      <td>[senate, house, representative, give, pleasure...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Dwight D. Eisenhower</td>\n",
       "      <td>[Delivered in person before a joint session] \\...</td>\n",
       "      <td>1960</td>\n",
       "      <td>[deliver, person, joint, session, mr, presiden...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Calvin Coolidge</td>\n",
       "      <td>Since the close of the last Congress the Natio...</td>\n",
       "      <td>1923</td>\n",
       "      <td>[since, close, last, congress, nation, lose, p...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>James Madison</td>\n",
       "      <td>Fellow-Citizens of the Senate and House of Re...</td>\n",
       "      <td>1816</td>\n",
       "      <td>[fellow, citizen, senate, house, representativ...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "              president                                               text  \\\n",
       "0          James Monroe   Fellow-Citizens of the Senate and House of Re...   \n",
       "1      William McKinley   To the Senate and House of Representatives:\\r...   \n",
       "2  Dwight D. Eisenhower  [Delivered in person before a joint session] \\...   \n",
       "3       Calvin Coolidge  Since the close of the last Congress the Natio...   \n",
       "4         James Madison   Fellow-Citizens of the Senate and House of Re...   \n",
       "\n",
       "   year                                               word  \n",
       "0  1821  [fellow, citizen, senate, house, representativ...  \n",
       "1  1897  [senate, house, representative, give, pleasure...  \n",
       "2  1960  [deliver, person, joint, session, mr, presiden...  \n",
       "3  1923  [since, close, last, congress, nation, lose, p...  \n",
       "4  1816  [fellow, citizen, senate, house, representativ...  "
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%%time\n",
    "cleaned_word = df_speeches['text'].map(clean_word)\n",
    "df_speeches['word'] = cleaned_word\n",
    "\n",
    "df_speeches.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Exercise 1:** Perform LDA on these speeches and visualize the topic models. What's your conclusion?\n",
    "\n",
    "(You can try different parameters to see the difference.)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Your Answer here:**\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: bottleneck in /Applications/anaconda3/lib/python3.11/site-packages (1.3.8)\n",
      "Requirement already satisfied: numpy in /Applications/anaconda3/lib/python3.11/site-packages (from bottleneck) (1.26.4)\n"
     ]
    }
   ],
   "source": [
    "# To avoid warnings during visualization, you need to run the below codes.\n",
    "!pip install --upgrade bottleneck"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "<link rel=\"stylesheet\" type=\"text/css\" href=\"https://cdn.jsdelivr.net/gh/bmabey/pyLDAvis@3.4.0/pyLDAvis/js/ldavis.v1.0.0.css\">\n",
       "\n",
       "\n",
       "<div id=\"ldavis_el1266658096501765502406605\" style=\"background-color:white;\"></div>\n",
       "<script type=\"text/javascript\">\n",
       "\n",
       "var ldavis_el1266658096501765502406605_data = {\"mdsDat\": {\"x\": [0.08081156055249744, 0.06891976685759628, -0.116331451192931, -0.14002628699054073, 0.006952791907786669, 0.02710003580048254, 0.07257358306510873], \"y\": [0.05338885665981372, 0.03873040144398869, 0.008251155167086636, -0.023844250490335322, 0.04622797059530748, 0.01705136897415206, -0.13980550235001304], \"topics\": [1, 2, 3, 4, 5, 6, 7], \"cluster\": [1, 1, 1, 1, 1, 1, 1], \"Freq\": [39.34845426399057, 14.713960494784873, 14.359546719595157, 11.762054669192008, 10.398226836919964, 9.373559015986098, 0.04419799953133212]}, \"tinfo\": {\"Term\": [\"state\", \"government\", \"make\", \"upon\", \"congress\", \"year\", \"law\", \"country\", \"work\", \"american\", \"public\", \"nation\", \"must\", \"department\", \"america\", \"great\", \"people\", \"new\", \"increase\", \"world\", \"present\", \"court\", \"united\", \"one\", \"program\", \"us\", \"need\", \"may\", \"time\", \"war\", \"whilst\", \"confederacy\", \"emigrant\", \"commencement\", \"augmentation\", \"frigate\", \"barbary\", \"vicinity\", \"paredes\", \"burthen\", \"privateer\", \"amicably\", \"ghent\", \"incursion\", \"overture\", \"adventurer\", \"apprehend\", \"functionary\", \"superintendence\", \"approbation\", \"interposition\", \"unquestionable\", \"indebted\", \"nueces\", \"emigrate\", \"texan\", \"redress\", \"virtuous\", \"ere\", \"commence\", \"specie\", \"indulge\", \"impost\", \"slave\", \"exertion\", \"entertain\", \"plenipotentiary\", \"object\", \"mexico\", \"article\", \"minister\", \"tribe\", \"mode\", \"blockade\", \"texas\", \"intercourse\", \"british\", \"communicate\", \"constitution\", \"stipulation\", \"portion\", \"deem\", \"paper\", \"colony\", \"territory\", \"subject\", \"france\", \"state\", \"may\", \"treasury\", \"duty\", \"spain\", \"th\", \"treaty\", \"united\", \"claim\", \"public\", \"upon\", \"government\", \"citizen\", \"receive\", \"power\", \"present\", \"effect\", \"interest\", \"general\", \"country\", \"congress\", \"act\", \"part\", \"make\", \"great\", \"last\", \"law\", \"amount\", \"war\", \"year\", \"time\", \"without\", \"people\", \"nation\", \"right\", \"one\", \"ounce\", \"armenian\", \"powder\", \"emplacement\", \"statistician\", \"guiana\", \"atua\", \"litigant\", \"mortar\", \"registry\", \"mora\", \"miantonomoh\", \"arapahoe\", \"extraditable\", \"shipowner\", \"allotment\", \"apia\", \"intimacy\", \"monrovia\", \"mataafa\", \"gerrymander\", \"cheyenne\", \"bluefields\", \"valparaiso\", \"samoa\", \"allottees\", \"columbian\", \"liberian\", \"kongo\", \"abrogation\", \"bering\", \"dutiable\", \"severalty\", \"meat\", \"colombian\", \"pound\", \"pork\", \"missionary\", \"hon\", \"chilean\", \"malietoa\", \"samoan\", \"ottoman\", \"inch\", \"pension\", \"silver\", \"per\", \"cent\", \"bullion\", \"arbitration\", \"gold\", \"postal\", \"cattle\", \"patent\", \"consular\", \"total\", \"armor\", \"ton\", \"secretary\", \"product\", \"sugar\", \"canal\", \"bureau\", \"department\", \"commission\", \"court\", \"report\", \"office\", \"method\", \"year\", \"bond\", \"statute\", \"june\", \"government\", \"upon\", \"export\", \"united\", \"state\", \"increase\", \"service\", \"recommendation\", \"law\", \"make\", \"fiscal\", \"result\", \"number\", \"congress\", \"american\", \"work\", \"general\", \"last\", \"country\", \"great\", \"interest\", \"amount\", \"land\", \"may\", \"time\", \"present\", \"people\", \"new\", \"one\", \"public\", \"fy\", \"deregulation\", \"communist\", \"baghdad\", \"ryan\", \"operational\", \"overall\", \"iraqis\", \"kremlin\", \"bilateral\", \"vietnamese\", \"initiatives\", \"kayla\", \"atomic\", \"atom\", \"soviet\", \"ideological\", \"fighter\", \"environmentally\", \"creative\", \"confrontation\", \"implementation\", \"pd\", \"dialogue\", \"freshman\", \"cheney\", \"shia\", \"evaluation\", \"communists\", \"bicentennial\", \"cultural\", \"iraqi\", \"lebanon\", \"capability\", \"vietnam\", \"satellite\", \"concept\", \"planning\", \"inflation\", \"realistic\", \"ballistic\", \"urban\", \"program\", \"compassion\", \"strategic\", \"goal\", \"regional\", \"soar\", \"nuclear\", \"achieve\", \"role\", \"percent\", \"billion\", \"spending\", \"basic\", \"significant\", \"economic\", \"freedom\", \"major\", \"area\", \"help\", \"iraq\", \"world\", \"energy\", \"budget\", \"security\", \"level\", \"commitment\", \"must\", \"america\", \"us\", \"nation\", \"federal\", \"new\", \"defense\", \"free\", \"today\", \"strength\", \"year\", \"continue\", \"need\", \"american\", \"people\", \"tax\", \"effort\", \"congress\", \"million\", \"peace\", \"make\", \"work\", \"government\", \"great\", \"increase\", \"state\", \"one\", \"country\", \"time\", \"well\", \"internet\", \"couldnt\", \"tech\", \"pandemic\", \"bosnia\", \"vaccine\", \"hitler\", \"americorps\", \"teen\", \"kid\", \"gore\", \"hillary\", \"cant\", \"arent\", \"smarter\", \"michelle\", \"rebekah\", \"biden\", \"doesnt\", \"smart\", \"empowerment\", \"tv\", \"automaker\", \"havent\", \"shouldnt\", \"hat\", \"jack\", \"gay\", \"folk\", \"wont\", \"dont\", \"id\", \"youre\", \"tuition\", \"millennium\", \"republicans\", \"theyre\", \"workforce\", \"paycheck\", \"im\", \"bet\", \"democrat\", \"thank\", \"get\", \"job\", \"tonight\", \"parent\", \"tell\", \"weve\", \"ive\", \"college\", \"medicare\", \"child\", \"let\", \"back\", \"america\", \"clean\", \"family\", \"win\", \"teacher\", \"know\", \"cut\", \"help\", \"challenge\", \"american\", \"go\", \"today\", \"ask\", \"want\", \"work\", \"century\", \"say\", \"us\", \"people\", \"world\", \"new\", \"year\", \"must\", \"every\", \"school\", \"tax\", \"one\", \"make\", \"time\", \"nation\", \"need\", \"right\", \"war\", \"congress\", \"country\", \"state\", \"demobilization\", \"nitrate\", \"acreage\", \"tile\", \"reconversion\", \"deflation\", \"prewar\", \"vj\", \"bituminous\", \"hospitalization\", \"aviation\", \"axiomatic\", \"seasonal\", \"herbert\", \"marketing\", \"inescapable\", \"dike\", \"vogue\", \"taper\", \"furlough\", \"reveals\", \"clarification\", \"nitrogen\", \"substandard\", \"monopolistic\", \"unjustified\", \"renegotiation\", \"muscle\", \"rumania\", \"kellogg\", \"electrification\", \"readjustment\", \"reproductive\", \"shoal\", \"authorization\", \"cooperative\", \"stabilization\", \"rehabilitation\", \"wartime\", \"fertilizer\", \"veteran\", \"agriculture\", \"consolidation\", \"earner\", \"liquidation\", \"helpful\", \"dollar\", \"flood\", \"depression\", \"farmer\", \"activity\", \"lease\", \"employment\", \"farm\", \"problem\", \"wage\", \"relief\", \"federal\", \"committee\", \"agricultural\", \"production\", \"price\", \"industry\", \"national\", \"economic\", \"expenditure\", \"government\", \"method\", \"policy\", \"war\", \"legislation\", \"make\", \"fiscal\", \"need\", \"year\", \"congress\", \"increase\", \"public\", \"provide\", \"service\", \"country\", \"present\", \"large\", \"nation\", \"must\", \"great\", \"law\", \"upon\", \"system\", \"people\", \"state\", \"time\", \"power\", \"work\", \"many\", \"may\", \"world\", \"wageworkers\", \"thru\", \"unhealthy\", \"tho\", \"practise\", \"deforestation\", \"employes\", \"employe\", \"marksmanship\", \"coolie\", \"bird\", \"wrongdoing\", \"scour\", \"wageworker\", \"photograph\", \"overcapitalization\", \"yosemite\", \"demagogue\", \"finely\", \"standpoint\", \"sin\", \"anarchist\", \"outsider\", \"yarn\", \"vegetation\", \"maker\", \"bent\", \"pribilof\", \"industrialism\", \"tenement\", \"rebate\", \"tiller\", \"publicity\", \"wrongdoer\", \"shipper\", \"defendant\", \"maneuver\", \"interstate\", \"battleship\", \"corporation\", \"righteousness\", \"forest\", \"man\", \"combination\", \"fashion\", \"men\", \"hague\", \"wool\", \"injunction\", \"moreover\", \"merely\", \"foolish\", \"improper\", \"accident\", \"philippine\", \"employer\", \"industrial\", \"law\", \"business\", \"railroad\", \"type\", \"matter\", \"great\", \"labor\", \"judge\", \"kind\", \"possible\", \"good\", \"need\", \"work\", \"make\", \"far\", \"upon\", \"show\", \"court\", \"government\", \"one\", \"do\", \"must\", \"nation\", \"condition\", \"country\", \"state\", \"people\", \"national\", \"power\", \"case\", \"public\", \"take\", \"time\", \"american\", \"give\", \"congress\", \"interest\", \"well\", \"every\", \"year\", \"may\", \"united\", \"sedimentary\", \"judson\", \"tsai\", \"phosphorous\", \"identic\", \"yardage\", \"gillett\", \"pribiloff\", \"peary\", \"internationalization\", \"montenegro\", \"transferring\", \"griswold\", \"tokugawa\", \"transacts\", \"filth\", \"woeful\", \"elli\", \"indifferently\", \"fushimi\", \"hadley\", \"pelt\", \"crypt\", \"counteragitation\", \"endowed\", \"disadavantage\", \"undecomposed\", \"bachelor\", \"appreciating\", \"aide\", \"lade\", \"ottawa\", \"measurement\", \"unnoticed\", \"suez\", \"slide\", \"envelope\", \"zoological\", \"offered\", \"subcontractor\", \"willow\", \"park\", \"geodetic\", \"make\", \"court\", \"bill\", \"state\", \"congress\", \"paul\", \"canal\", \"government\", \"upon\", \"country\", \"law\", \"department\", \"work\", \"increase\", \"public\", \"great\", \"district\", \"year\", \"united\", \"present\", \"appeal\", \"one\", \"tariff\", \"officer\", \"nation\", \"time\", \"give\", \"proper\", \"part\", \"war\", \"interest\", \"may\"], \"Freq\": [8953.0, 8186.0, 6080.0, 4162.0, 5224.0, 6644.0, 3604.0, 4592.0, 2807.0, 3576.0, 3228.0, 3881.0, 3249.0, 1895.0, 1802.0, 4271.0, 4340.0, 3058.0, 2624.0, 2486.0, 2657.0, 937.0, 4204.0, 3038.0, 1252.0, 2632.0, 2030.0, 3472.0, 3419.0, 2968.0, 108.49452895131266, 45.77663797046783, 42.81020843831605, 94.95307363608366, 36.06254157565046, 28.549618928203646, 24.793158908823848, 29.419402200859032, 21.077908321322763, 26.614116495130748, 20.108624501049608, 22.851961711568432, 23.76273528637677, 29.273560933617695, 27.43049994056848, 21.879925726287233, 64.2149748324802, 19.09553821380959, 23.693336380491512, 41.028120291459224, 43.78156616492228, 18.142377384846583, 18.15565299406547, 16.315501991600588, 18.130756987663336, 17.205426938215304, 113.25232573073225, 19.023769315592762, 21.764676533974153, 137.7499542914366, 156.58924637784338, 53.244782501930715, 39.77317217810013, 155.0685799938168, 68.11246309119628, 140.4794132859907, 81.08989414444535, 616.33123708147, 720.8446380446943, 429.4964746540313, 474.32519916986195, 226.8495616498089, 136.9202769759695, 54.360460631134025, 240.6383309474288, 335.769515311559, 408.7673452041875, 170.08227402367967, 780.7670598097874, 117.13205926428745, 405.5923433034215, 312.4561577015949, 185.28603700376618, 125.86761360791836, 820.2926362672777, 1373.6614753329516, 287.40510136636345, 5418.090573384725, 2239.9527384176395, 851.0878340165647, 1355.0044783088783, 379.7530669098867, 613.5930337673833, 1046.4605583834928, 2359.466842148414, 752.9413411480024, 1858.7805456647434, 2287.474922044507, 3937.5299378514737, 1195.1446268613452, 731.1861419746673, 1595.134344814556, 1483.1332602526554, 694.7732510978367, 1428.5358160404876, 1130.5587071421505, 2157.333235309407, 2358.558601608888, 1298.2568914885696, 1068.8799919293472, 2348.89402070603, 1826.5572064494445, 1343.9257802424572, 1556.7346360185168, 869.8783958258622, 1302.9365006948888, 1900.0141652912819, 1333.5583146573563, 957.4459733587149, 1334.3751467969944, 1212.0761338163002, 977.8564255788125, 1014.4522584724051, 35.493777116785935, 8.95486961058994, 9.76392257420332, 5.7969312713813625, 5.757906207645923, 9.553985865711546, 4.683502710677803, 6.604918997224959, 13.214204298715078, 16.021135086870217, 4.624774650171209, 4.618805611789058, 4.580969673366225, 5.523242716197657, 5.519111993362354, 43.338652387888914, 8.345236571222872, 11.151621083598636, 4.50580505260141, 7.2701141363093935, 8.16371351945215, 6.305851542373132, 3.5564075005651987, 6.295001139705266, 21.931895598286694, 3.5501350840270005, 4.458678523959324, 7.166006166416024, 15.418843603780985, 5.3397150274151155, 24.18370289042437, 15.928414528245689, 20.290426626566955, 28.8289258136086, 22.880696636681673, 67.86803859150272, 17.283186265039088, 30.653469357861734, 27.744303057596284, 19.293510397918464, 10.513389531688746, 16.08830359591441, 24.765597801601132, 25.429137529975563, 193.70466217944156, 206.93027973997576, 357.99524548927076, 328.97517192750354, 44.65038539720715, 114.24516660959029, 239.39891425754968, 150.10711018985685, 43.798167867590855, 74.23932324182806, 88.0741085318244, 266.365474733123, 38.443038108272695, 56.578168765038384, 453.7551420793341, 224.7432403538843, 46.58733493799163, 168.66370821829094, 138.50560173716778, 572.765222586355, 338.8411310133547, 324.88141245261494, 480.09524909899795, 345.0440456645365, 212.5628980853679, 1322.744930126184, 171.0654487020182, 136.50031699835316, 232.259433194446, 1430.7266079045994, 864.2942511734001, 159.81725581555042, 844.0399684935786, 1351.1922257293352, 577.9539684491846, 503.8035554924199, 241.5600124565219, 671.2737291721703, 917.9925359709325, 280.047591550663, 375.574431285365, 312.2189583969797, 748.9435316415077, 589.3266809975914, 491.4683674522694, 405.0131081729287, 478.6221774402107, 604.6750950210238, 543.004617578065, 437.3695844690569, 342.52512122219326, 350.4754940522034, 450.0648462872136, 444.0069912672754, 395.1203659660087, 409.42455042534385, 369.1985501145532, 366.4993234492569, 363.79766195477254, 15.976072889683202, 15.95608954440862, 143.09993678675139, 12.15633036292595, 12.146374390133724, 10.318162476362923, 17.2387678417325, 9.403004088044954, 10.26055815835903, 8.509957707763416, 10.219777511342343, 9.35329371978223, 8.487961843222935, 65.07336533308724, 9.273228963254052, 268.189878646807, 7.5507014428251535, 20.302886495810355, 7.52848995122047, 24.435963230733226, 11.739724594947013, 14.255300373637786, 6.646498146963344, 6.646254436021022, 7.479284140768021, 7.4601580677729755, 6.6162341983053965, 7.4367380174132975, 7.435369523352405, 6.600060740496342, 16.5618111956464, 52.8137986341951, 14.810836610674484, 45.96376567454941, 71.25260296390742, 25.97668857616263, 22.03314089070551, 26.719407192849353, 181.89788104814065, 22.623740087573, 21.837827514343076, 45.05553115218266, 831.6632860370994, 33.96226220769256, 83.64159540510674, 225.54823202664346, 35.268183484144586, 16.339251697528994, 175.10212327694688, 222.2994433100124, 77.0226956183697, 243.34993025732288, 322.61287778525724, 138.5938280867443, 140.81382152422842, 54.74509742058075, 484.4545516030279, 393.9502693091921, 196.0136797551996, 236.65185487819878, 523.1546002252729, 90.78775619959173, 1010.4738216359638, 291.58390524742526, 315.09576608865643, 483.85721608339526, 172.55916714508368, 128.990885826408, 1038.349844785233, 651.7690897331976, 856.2047951457756, 1117.0805428470687, 536.8775978210435, 891.2945403323218, 338.15350205273734, 468.973910691227, 245.0269052514445, 253.83745184668675, 1338.5783294761789, 489.1592390252262, 568.6784638409466, 800.2580238043213, 871.1558521799096, 414.0267197797087, 391.9073927990409, 752.9281402505662, 367.0184128143482, 461.6238933094561, 697.734252937682, 517.0332515592213, 740.7701933986556, 583.3618653326748, 483.87585997048296, 687.450138593554, 457.05504427373484, 486.3314609614574, 457.3166679703181, 408.40960905332247, 32.995521600230575, 13.392171672794943, 19.664229673357305, 11.559036453114585, 11.547274104417452, 11.536831939779207, 10.641554539784124, 13.315992451837625, 12.346714563466751, 74.42289112977159, 9.622690600544654, 9.588517874016253, 102.77909723795368, 25.387159726921503, 8.671098343866367, 8.670096314028404, 7.780267305066659, 10.40101591254934, 43.57911202799509, 16.49426266326463, 9.507030624181885, 10.373058110385573, 7.759493705935687, 13.85369803847278, 19.95776905080733, 7.752930995339355, 7.73580447290266, 8.598362674476704, 20.76560628596182, 51.80103431635765, 142.73350318022466, 30.16480056441461, 41.054102887738544, 26.361101537830002, 15.400860180716924, 38.373909347487384, 76.00056800479325, 16.142490146328768, 25.753166526084723, 122.38465864914065, 14.426840390832707, 58.59990268106801, 118.92760736120779, 426.64236483948986, 543.3818571888102, 365.16793253404813, 137.61935499008203, 160.57146212313395, 191.68468665844347, 90.90115250721911, 147.48131238076752, 74.69333469419378, 486.79961371703064, 411.6234394435161, 247.74080286190232, 826.4564685742661, 97.47493611810225, 369.7353794829169, 81.69256535827007, 94.95298999201187, 514.8845216112167, 237.97701164416728, 482.7977576365134, 186.18169162715014, 1094.511805217937, 401.7136965365113, 250.26325429175535, 320.1439948523807, 306.8923350555095, 807.7895744045323, 195.22392154846386, 387.39206537971575, 691.0548231769355, 936.446799477157, 635.5475666727984, 704.6338948587287, 1102.1488040902884, 711.9910677362996, 555.549172540953, 279.2778961559365, 393.27904136407506, 581.3367823806118, 806.8784306223481, 531.5070940002848, 554.3434304268285, 421.2194698120529, 391.68115857686564, 416.419333599645, 459.7238161518014, 436.9412290736399, 400.7401695737536, 15.289951770049003, 13.435756259011777, 15.964477423772232, 25.600925528024415, 29.43237220395247, 8.593169112149207, 10.311296384056643, 6.772987214034587, 5.826551196057423, 5.778126262134674, 16.523276826410264, 5.672930857239297, 4.876663492634303, 4.826603023716441, 25.314447355333503, 4.791517092696934, 3.9214841699814715, 5.138263265042331, 3.8960291100469924, 3.8735790225229234, 3.865834273143535, 3.826294309835967, 7.675068350190646, 6.1130038619855025, 9.917191391537681, 4.532619658405172, 4.527909524430837, 12.944810360482908, 4.527213258742717, 2.9802756596409536, 10.600386587135956, 47.27903777691222, 6.758438708012725, 12.448270897802155, 51.597693955300215, 54.94906750738557, 16.105991701452663, 34.35757920248809, 26.36526256179542, 8.742062427379771, 118.51292421059442, 206.43816049282324, 51.99462881974961, 27.675107906653018, 32.26761847824594, 26.169086601993804, 273.9594645228629, 47.65068647755939, 58.26775931319133, 153.77109068018297, 121.10622022638216, 42.47407103711111, 143.9480033879405, 142.73026365304162, 242.52622051289313, 151.31840448605305, 139.91618109817912, 382.19267247927473, 96.49632481022905, 133.16050125678407, 187.5361326158978, 227.80743409985197, 218.600204149331, 458.21418656900795, 249.34879701010516, 229.70769620330793, 1079.2997252991215, 170.37286629263897, 323.61209271173465, 473.7641239470009, 288.6155787515097, 729.5351543348568, 227.623233909886, 356.4909001047318, 688.2774884085136, 581.8308237556447, 393.38948508045786, 439.39792759490734, 313.227261019805, 342.1914724475293, 485.5578775230917, 370.1112136483892, 281.27377831762357, 421.8701875544488, 384.3488515173169, 428.06262292275335, 387.1572977669655, 410.1036558986476, 298.0048249616006, 407.7414373666794, 524.3414370895017, 352.28575315717853, 323.8131466675849, 321.3200026113714, 281.65444400361787, 300.59304719970066, 286.2629342174391, 13.640988412981237, 10.788730278323381, 9.643504291335919, 7.870327988180581, 7.86591825352702, 8.753157362975264, 7.804234790734193, 7.796450639625045, 7.74934366161716, 6.871060116725353, 7.697635545591382, 22.38567244844786, 6.845948368188743, 5.937164572902796, 5.916319627935994, 5.883978052319405, 5.875868266915095, 7.558067692381947, 5.848545436656758, 42.84444497028384, 7.501487490718636, 12.531140976420392, 4.939872257600848, 4.947390121886567, 6.596021560894269, 16.4794331905535, 4.871818107829302, 4.8404145951297854, 4.8082572763233395, 11.908040995507738, 20.182746498648, 7.957205850962797, 21.37642488014912, 16.201720580577224, 25.36406788595822, 14.611877007037338, 19.360477645479435, 142.48565581046597, 29.23774634573471, 209.36167313090695, 11.405065268898003, 123.61654540183747, 260.5704749515776, 97.08962004755146, 36.26004992089373, 410.62689446329983, 35.170268765612974, 33.62394087124177, 32.6699591600753, 60.64970565086156, 95.23986810555512, 16.467187103873243, 34.16119022885676, 28.83417856643647, 77.71838652729978, 55.795358382263224, 122.03588173251157, 603.2072353685478, 304.61735065720427, 118.80986502823163, 48.871647425798805, 203.27578192952353, 538.1062282192107, 203.5702348766049, 92.70572733393234, 106.51346660649507, 177.71399685396875, 297.83268305901584, 298.9210075601213, 364.0298697046699, 577.8752536465739, 210.22104937917607, 452.841587564321, 180.51874718214472, 184.8647867732698, 649.3272332281039, 364.98388373069014, 160.60265539910637, 373.718558861657, 395.27314298762917, 244.6971801723716, 420.46747337579495, 570.6245163704801, 381.37620477577195, 272.8213243441192, 307.6572934622581, 198.01661405960587, 313.00930936418246, 259.0614011120277, 300.15219354375745, 302.1073714531309, 260.05266173559517, 320.80132541157417, 263.0369036758706, 246.0604096198168, 242.1404289461779, 291.77618345996825, 252.66049477356614, 247.50648440916385, 0.23308350232596234, 0.15908512967904653, 0.15822174102168168, 0.15772177894345304, 0.15698399028679846, 0.15658227188213775, 0.15622267800179138, 0.15607689479827938, 0.15604370151701663, 0.15549202730710324, 0.2756421881956044, 0.08384715441220533, 0.08374356605775614, 0.08356102645239388, 0.08341050804915372, 0.08335308789205409, 0.08318474802548059, 0.08311174507620624, 0.08304272719601004, 0.08305101965593001, 0.08301847687859032, 0.08302225097342317, 0.08295543074161565, 0.08295592887525041, 0.0829660556390255, 0.08293543507147644, 0.08286938841190174, 0.08267954675349333, 0.08263540039266137, 0.08268585839966565, 0.4758583175846701, 0.15518089889922207, 0.1545891044203248, 0.15178528014168413, 0.26114680416439595, 0.3861512011385792, 0.2651099084794544, 0.13220703426762156, 0.1492776285410901, 0.1269020985899916, 0.12545554195620454, 0.6304254572418995, 0.13541665578633238, 1.5118590699906351, 0.7779402904762682, 0.692297733515649, 1.5121572469240123, 1.230498190459966, 0.16354197233209689, 0.5440936708634222, 1.3061840288872346, 1.0319501406622669, 0.9740750293234026, 0.8933083684709846, 0.7411940153897761, 0.7480930138610419, 0.6997986649503786, 0.7279028254676546, 0.746412064840711, 0.5052027722485646, 0.7540673825398447, 0.6652914360878215, 0.5702505390964497, 0.37045640508117766, 0.5713369626934858, 0.41680282878485664, 0.4683684505770282, 0.5572100803440925, 0.5434694215131207, 0.5132659734886388, 0.43710070780968535, 0.4724154054338076, 0.4799226192127309, 0.47645401508710566, 0.4807740643836527], \"Total\": [8953.0, 8186.0, 6080.0, 4162.0, 5224.0, 6644.0, 3604.0, 4592.0, 2807.0, 3576.0, 3228.0, 3881.0, 3249.0, 1895.0, 1802.0, 4271.0, 4340.0, 3058.0, 2624.0, 2486.0, 2657.0, 937.0, 4204.0, 3038.0, 1252.0, 2632.0, 2030.0, 3472.0, 3419.0, 2968.0, 110.4093287641284, 46.95270049418323, 44.061836853031096, 97.90842170677483, 37.35251846327706, 29.646208917285662, 25.803664147218814, 30.6367473256422, 21.95651472778226, 27.729562132120492, 20.999263614613206, 23.885031405667227, 24.84252679520434, 30.63613343079446, 28.711713355747584, 22.93495698664471, 67.32073798580893, 20.034580750710514, 24.858501243853706, 43.08424000713983, 46.00763447524388, 19.069636977803295, 19.085403810501916, 17.151579119995127, 19.076048039425253, 18.11153710953829, 119.29820105710016, 20.04035662389647, 22.955446896004247, 145.35248896118273, 168.1332247646643, 56.568470264503915, 42.17729565808855, 168.12400439005597, 72.9092555523661, 153.3171701180043, 87.68607325229785, 712.6290468558086, 841.3702265089951, 493.74078959109414, 553.8338564803132, 258.1755280795458, 152.70835115174077, 58.589575437121084, 276.95099513974424, 393.5148362924775, 484.4902757731233, 193.21354855907904, 961.5478956403408, 130.80104196136645, 483.7436421464349, 368.983836461691, 213.48872800858123, 142.1189724397394, 1074.5267571195861, 1947.0620010645482, 353.8447155815453, 8953.951217988273, 3472.9287656493852, 1188.4212246141767, 2023.659714751518, 492.8712281950852, 854.8871812824931, 1574.4386280637377, 4204.815069621711, 1097.7479139023199, 3228.9241548477676, 4162.675027890446, 8186.092063189654, 2007.9286661856906, 1103.3771430291831, 2891.6338443963027, 2657.864786694858, 1070.1776723445378, 2679.651404606452, 1993.0690382621178, 4592.280446293737, 5224.016737010442, 2488.9276616572524, 1949.1700845233065, 6080.4215072884135, 4271.577333426443, 2812.3738115508645, 3604.512279255659, 1469.4046761604523, 2968.0840380099444, 6644.293968234954, 3419.370484017684, 1800.0817209398106, 4340.964525289992, 3881.340002444031, 2254.888915501449, 3038.5136129786238, 39.2300331183742, 9.971990457546003, 11.05228973438701, 6.573953713928578, 6.564200686903367, 11.022229138151836, 5.430658602203876, 7.663025951120558, 15.428023537667984, 18.76371712775673, 5.418466180723804, 5.416912200908157, 5.38826945042691, 6.520744740924062, 6.516562870174729, 51.18044675844595, 9.856133429826068, 13.19937614853023, 5.393757812758455, 8.722097349402738, 9.825479426611686, 7.592139012042307, 4.285317724404314, 7.592460654432172, 26.45282315838746, 4.2829929670613085, 5.379201091022169, 8.676666570790916, 18.686665504308476, 6.480099227772659, 29.803717397479684, 19.68772420430342, 25.26555471045984, 36.213388048810394, 28.58690908375385, 91.5343456751751, 21.841664794849134, 40.372011024494704, 37.05495928849221, 25.088046745287897, 13.091344921980962, 20.721857965828452, 33.625703484304964, 34.811442489977054, 338.8513356702976, 380.3115169315072, 712.5105852698962, 651.9149666901652, 67.6841429150242, 199.39788348804262, 470.4678599668815, 273.93870412745247, 66.54233088565066, 126.14443341117811, 157.5511787669217, 609.9245683789093, 57.97089133157976, 93.72655524080439, 1232.941695892829, 526.9177474409809, 74.78651364785534, 385.89146087169973, 303.3028104981884, 1895.7097359813129, 988.517164218205, 937.0084771444397, 1566.942926581372, 1043.315292268394, 547.3517690387746, 6644.293968234954, 418.9412560308294, 309.5522891973001, 653.5347814093833, 8186.092063189654, 4162.675027890446, 397.2805008786853, 4204.815069621711, 8953.951217988273, 2624.1395853763806, 2170.7435663791466, 725.8537379422783, 3604.512279255659, 6080.4215072884135, 963.2772275481046, 1573.1766115789785, 1156.5428382959758, 5224.016737010442, 3576.3928555798116, 2807.392088389532, 1993.0690382621178, 2812.3738115508645, 4592.280446293737, 4271.577333426443, 2679.651404606452, 1469.4046761604523, 1621.3616644595886, 3472.9287656493852, 3419.370484017684, 2657.864786694858, 4340.964525289992, 3058.0658994569867, 3038.5136129786238, 3228.9241548477676, 16.82460054657428, 16.822693958820704, 151.35568689802543, 13.058164329906003, 13.054370512155135, 11.178914249582528, 18.70996252103586, 10.239212691434352, 11.181171970685376, 9.303796511635701, 11.180815214955246, 10.240090912843813, 9.29661416376455, 71.4188362392274, 10.239953749730493, 296.5591113014213, 8.355872353208902, 22.47130746022149, 8.346322659240075, 27.194655675714085, 13.070171207975017, 15.887685336404655, 7.424353975536992, 7.424400622972383, 8.363950217544739, 8.35566519885328, 7.418322540898348, 8.35465622871542, 8.3603085523579, 7.421713816471669, 18.715510194321848, 61.14218893164649, 16.782037368661967, 53.576734764465456, 84.7625730755268, 29.973611163095033, 25.31851275622007, 30.98132284795478, 233.81721493534695, 26.264637267599394, 25.33089789447852, 54.88546450295921, 1252.019244379368, 40.73169485596237, 108.36841928098451, 328.74696492243623, 43.28321179123421, 18.722192511379934, 264.20954783408763, 345.91169999883584, 106.77220488592472, 392.5515817444227, 542.1434764370215, 208.33678977468333, 215.97396798585214, 73.029441959811, 934.1139879837652, 740.9044213442631, 340.4219687810129, 429.6567814398587, 1121.1728505952058, 136.3087910054839, 2486.6122536565786, 561.4807655799157, 632.8405198362168, 1110.4875177273368, 308.6158308406283, 218.2251501340753, 3249.759793029213, 1802.5213131100636, 2632.8213352486955, 3881.340002444031, 1460.9639635025612, 3058.0658994569867, 801.9974040189994, 1305.80615775257, 515.2176965254671, 543.5863226510952, 6644.293968234954, 1579.1474717786793, 2030.257943478062, 3576.3928555798116, 4340.964525289992, 1306.027511269585, 1231.9797624424505, 5224.016737010442, 1102.6056738871423, 1857.3924014169038, 6080.4215072884135, 2807.392088389532, 8186.092063189654, 4271.577333426443, 2624.1395853763806, 8953.951217988273, 3038.5136129786238, 4592.280446293737, 3419.370484017684, 2287.7914551071226, 34.54255700122552, 14.326171424754387, 21.057428406279673, 12.404471822194344, 12.40642922725207, 12.40282956464408, 11.442408240164646, 14.323060245918256, 13.35998693258552, 80.66210868318998, 10.477954284484856, 10.476008470847331, 112.37847348585942, 27.776078888718743, 9.513061503030121, 9.514559569076912, 8.550325449699201, 11.437132771715136, 47.959789446798545, 18.158876296731, 10.473159488651824, 11.43200249207389, 8.553532937143123, 15.272352990896525, 22.002551442464103, 8.550400596136376, 8.550670818594728, 9.510343427670456, 22.978438727445422, 57.54263687808209, 160.28352577582314, 33.53246524567362, 46.00650932333698, 29.662063441600914, 17.190316846759785, 44.06222977070648, 91.02257568883068, 18.14792537721679, 29.65857577919226, 153.25870655632903, 16.153438927101455, 71.81994933508297, 155.0957391787148, 614.1161882312141, 824.4694017913719, 545.4432242660052, 187.37802573975287, 222.22661930616783, 282.8153743728112, 123.3591569188855, 214.03749656503004, 101.31028038387784, 885.5429718752604, 753.3971630663345, 427.1783132552298, 1802.5213131100636, 144.43292759288164, 739.6353193476189, 118.11870586363017, 143.35028891986573, 1195.2441730416026, 456.57102406588575, 1121.1728505952058, 345.4771897438247, 3576.3928555798116, 961.5744018722941, 515.2176965254671, 751.7559478598229, 716.5235600214301, 2807.392088389532, 383.3300872638905, 1043.3243799388856, 2632.8213352486955, 4340.964525289992, 2486.6122536565786, 3058.0658994569867, 6644.293968234954, 3249.759793029213, 2273.5931813322964, 678.0733232133648, 1306.027511269585, 3038.5136129786238, 6080.4215072884135, 3419.370484017684, 3881.340002444031, 2030.257943478062, 2254.888915501449, 2968.0840380099444, 5224.016737010442, 4592.280446293737, 8953.951217988273, 16.267626395014034, 14.341571553252221, 17.215299391380864, 27.978432357716372, 32.59126997131366, 9.527512534846487, 11.44253557991435, 7.595046609345693, 6.634236413427763, 6.623603844603277, 19.100191279281336, 6.5734755332111465, 5.66803196975998, 5.662863357023049, 29.748751560203825, 5.6579558334406945, 4.700607280376628, 6.1647643830154415, 4.699494644680198, 4.70013166269109, 4.693329325645119, 4.691745389882527, 9.47907279863345, 7.560914749027114, 12.337838649698039, 5.645690711846739, 5.648854507803241, 16.151815725513774, 5.653242639227777, 3.73921765098716, 13.319980670201165, 63.290360193926816, 8.556661764828517, 16.207452463035033, 73.60560599916496, 82.79982867353914, 22.000451028958267, 50.18883639251748, 38.21643082669928, 11.377895244983424, 219.3418336097513, 438.04028158265464, 88.94156001418638, 42.97657090489965, 52.46025255446831, 41.397150374297595, 712.2793524753854, 85.7898800051047, 109.98365280175695, 365.3861438552522, 274.27212363123044, 76.98526041841225, 380.14084691972965, 381.18546953531614, 762.623893412979, 422.8020291362941, 382.44354823000396, 1460.9639635025612, 233.19638037426833, 361.6852232813876, 585.774800800825, 794.2167915910466, 771.7191931310182, 2221.6437757916133, 934.1139879837652, 839.6380315896541, 8186.092063189654, 547.3517690387746, 1598.3326993630128, 2968.0840380099444, 1384.2851052759816, 6080.4215072884135, 963.2772275481046, 2030.257943478062, 6644.293968234954, 5224.016737010442, 2624.1395853763806, 3228.9241548477676, 1818.48778232374, 2170.7435663791466, 4592.280446293737, 2657.864786694858, 1575.5766803541096, 3881.340002444031, 3249.759793029213, 4271.577333426443, 3604.512279255659, 4162.675027890446, 1885.4875176845933, 4340.964525289992, 8953.951217988273, 3419.370484017684, 2891.6338443963027, 2807.392088389532, 1790.742265736271, 3472.9287656493852, 2486.6122536565786, 14.617550211624804, 11.669910996546857, 10.666098880034488, 8.71533616490938, 8.712997671010868, 9.702792304001633, 8.69555173924523, 8.702984432136999, 8.706686700027637, 7.73173832734926, 8.676820436386498, 25.3198943635562, 7.745511922027244, 6.746322821537129, 6.754156011696849, 6.721254537537415, 6.7324497702773005, 8.684974638764109, 6.743634996362608, 49.41435538505693, 8.67152475977166, 14.599937037781825, 5.756134427027054, 5.76818132871604, 7.71855360158764, 19.3857509662268, 5.759009206808753, 5.731501982289165, 5.717543912719439, 14.202985707547192, 24.26681176498383, 9.596292608151536, 27.305325096315734, 20.427962835276126, 33.059034383781, 18.547819005331835, 25.443809964645602, 234.39745502474142, 40.99229158668084, 395.92714022288595, 14.50940003707542, 240.85314833482772, 593.2533542164833, 192.95404942736383, 58.24445478505699, 1295.43644181199, 59.634250866552335, 57.345297524456484, 55.906046718147984, 126.76115096262231, 232.61308562619243, 23.295918127108035, 61.9898038794154, 50.06065486342217, 194.92588175670696, 124.43473422206856, 370.1696484328759, 3604.512279255659, 1441.6386264498135, 384.95625272570715, 105.3976077048074, 867.2676819803595, 4271.577333426443, 998.2745542129292, 293.99159656536807, 369.9436529266991, 838.577581754913, 1963.0011860141562, 2030.257943478062, 2807.392088389532, 6080.4215072884135, 1144.124383094624, 4162.675027890446, 899.817471979476, 937.0084771444397, 8186.092063189654, 3038.5136129786238, 755.2035977006843, 3249.759793029213, 3881.340002444031, 1646.0260801693646, 4592.280446293737, 8953.951217988273, 4340.964525289992, 2221.6437757916133, 2891.6338443963027, 1112.8546501308772, 3228.9241548477676, 2262.7995588027948, 3419.370484017684, 3576.3928555798116, 2417.4315369125957, 5224.016737010442, 2679.651404606452, 2287.7914551071226, 2273.5931813322964, 6644.293968234954, 3472.9287656493852, 4204.815069621711, 1.1686211033735994, 1.0545172300797583, 1.064533255572818, 1.0686732851843548, 1.076742480213418, 1.0806838606551534, 1.085158960379414, 1.0855918357887866, 1.0869707118556604, 1.0930541280043182, 2.6481402934259726, 0.9519104387183699, 0.9527312466564644, 0.9539245113789987, 0.9547142292242174, 0.9542537235537031, 0.9546745250311874, 0.9562135133317368, 0.9564307817260198, 0.9570475868593153, 0.9568967035068537, 0.957336922049575, 0.9566331660114216, 0.9567517004782575, 0.9568700465243044, 0.9581098953471259, 0.958069875211437, 0.9589967584630452, 0.958545349406783, 0.9593450364503255, 6.440601072252202, 2.026308834699423, 2.0215738762675364, 2.0508002751888026, 5.65479875365275, 10.98200998120934, 6.6281791989496295, 2.3280066940396256, 3.0063044222343587, 2.381671815468117, 2.385454762694158, 99.8672314831656, 3.30428853373293, 6080.4215072884135, 937.0084771444397, 661.0869700607705, 8953.951217988273, 5224.016737010442, 7.857316497637695, 385.89146087169973, 8186.092063189654, 4162.675027890446, 4592.280446293737, 3604.512279255659, 1895.7097359813129, 2807.392088389532, 2624.1395853763806, 3228.9241548477676, 4271.577333426443, 595.0641289682145, 6644.293968234954, 4204.815069621711, 2657.864786694858, 188.9727249000679, 3038.5136129786238, 526.4191199989324, 1162.1934395833853, 3881.340002444031, 3419.370484017684, 2417.4315369125957, 816.7242305660893, 1949.1700845233065, 2968.0840380099444, 2679.651404606452, 3472.9287656493852], \"Category\": [\"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic6\", \"Topic6\", \"Topic6\", \"Topic6\", \"Topic6\", \"Topic6\", \"Topic6\", \"Topic6\", \"Topic6\", \"Topic6\", \"Topic6\", \"Topic6\", \"Topic6\", \"Topic6\", \"Topic6\", \"Topic6\", \"Topic6\", \"Topic6\", \"Topic6\", \"Topic6\", \"Topic6\", \"Topic6\", \"Topic6\", \"Topic6\", \"Topic6\", \"Topic6\", \"Topic6\", \"Topic6\", \"Topic6\", \"Topic6\", \"Topic6\", \"Topic6\", \"Topic6\", \"Topic6\", \"Topic6\", \"Topic6\", \"Topic6\", \"Topic6\", \"Topic6\", \"Topic6\", \"Topic6\", \"Topic6\", \"Topic6\", \"Topic6\", \"Topic6\", \"Topic6\", \"Topic6\", \"Topic6\", \"Topic6\", \"Topic6\", \"Topic6\", \"Topic6\", \"Topic6\", \"Topic6\", \"Topic6\", \"Topic6\", \"Topic6\", \"Topic6\", \"Topic6\", \"Topic6\", \"Topic6\", \"Topic6\", \"Topic6\", \"Topic6\", \"Topic6\", \"Topic6\", \"Topic6\", \"Topic6\", \"Topic6\", \"Topic6\", \"Topic6\", \"Topic6\", \"Topic6\", \"Topic6\", \"Topic6\", \"Topic6\", \"Topic6\", \"Topic6\", \"Topic6\", \"Topic6\", \"Topic6\", \"Topic6\", \"Topic6\", \"Topic6\", \"Topic6\", \"Topic6\", \"Topic6\", \"Topic6\", \"Topic6\", \"Topic6\", \"Topic6\", \"Topic6\", \"Topic6\", \"Topic6\", \"Topic6\", \"Topic6\", \"Topic6\", \"Topic6\", \"Topic6\", \"Topic7\", \"Topic7\", \"Topic7\", \"Topic7\", \"Topic7\", \"Topic7\", \"Topic7\", \"Topic7\", \"Topic7\", \"Topic7\", \"Topic7\", \"Topic7\", \"Topic7\", \"Topic7\", \"Topic7\", \"Topic7\", \"Topic7\", \"Topic7\", \"Topic7\", \"Topic7\", \"Topic7\", \"Topic7\", \"Topic7\", \"Topic7\", \"Topic7\", \"Topic7\", \"Topic7\", \"Topic7\", \"Topic7\", \"Topic7\", \"Topic7\", \"Topic7\", \"Topic7\", \"Topic7\", \"Topic7\", \"Topic7\", \"Topic7\", \"Topic7\", \"Topic7\", \"Topic7\", \"Topic7\", \"Topic7\", \"Topic7\", \"Topic7\", \"Topic7\", \"Topic7\", \"Topic7\", \"Topic7\", \"Topic7\", \"Topic7\", \"Topic7\", \"Topic7\", \"Topic7\", \"Topic7\", \"Topic7\", \"Topic7\", \"Topic7\", \"Topic7\", \"Topic7\", \"Topic7\", \"Topic7\", \"Topic7\", \"Topic7\", \"Topic7\", \"Topic7\", \"Topic7\", \"Topic7\", \"Topic7\", \"Topic7\", \"Topic7\", \"Topic7\", \"Topic7\", \"Topic7\", \"Topic7\", \"Topic7\"], \"logprob\": [30.0, 29.0, 28.0, 27.0, 26.0, 25.0, 24.0, 23.0, 22.0, 21.0, 20.0, 19.0, 18.0, 17.0, 16.0, 15.0, 14.0, 13.0, 12.0, 11.0, 10.0, 9.0, 8.0, 7.0, 6.0, 5.0, 4.0, 3.0, 2.0, 1.0, -8.1031, -8.966, -9.033, -8.2364, -9.2045, -9.4381, -9.5792, -9.4081, -9.7416, -9.5083, -9.7886, -9.6607, -9.6217, -9.4131, -9.4781, -9.7042, -8.6275, -9.8403, -9.6246, -9.0755, -9.0106, -9.8915, -9.8908, -9.9977, -9.8922, -9.9446, -8.0602, -9.8441, -9.7095, -7.8643, -7.7362, -8.8149, -9.1066, -7.7459, -8.5686, -7.8447, -8.3942, -6.366, -6.2094, -6.7272, -6.6279, -7.3655, -7.8704, -8.7941, -7.3065, -6.9734, -6.7766, -7.6535, -6.1295, -8.0265, -6.7844, -7.0453, -7.5679, -7.9546, -6.0801, -5.5645, -7.1289, -4.1923, -5.0756, -6.0433, -5.5782, -6.8503, -6.3705, -5.8366, -5.0236, -6.1658, -5.2621, -5.0546, -4.5115, -5.7038, -6.1951, -5.4151, -5.4879, -6.2462, -5.5254, -5.7593, -5.1132, -5.024, -5.621, -5.8154, -5.0281, -5.2796, -5.5864, -5.4394, -6.0214, -5.6174, -5.2402, -5.5942, -5.9255, -5.5936, -5.6897, -5.9044, -5.8677, -8.2368, -9.6139, -9.5274, -10.0488, -10.0555, -9.5492, -10.2621, -9.9183, -9.2248, -9.0322, -10.2747, -10.276, -10.2842, -10.0972, -10.0979, -8.0371, -9.6844, -9.3945, -10.3008, -9.8224, -9.7064, -9.9646, -10.5374, -9.9664, -8.7182, -10.5391, -10.3113, -9.8368, -9.0705, -10.1309, -8.6204, -9.038, -8.796, -8.4447, -8.6758, -7.5886, -8.9564, -8.3834, -8.4831, -8.8464, -9.4535, -9.028, -8.5967, -8.5702, -6.5398, -6.4737, -5.9256, -6.0101, -8.0073, -7.0678, -6.328, -6.7948, -8.0265, -7.4988, -7.3279, -6.2213, -8.1569, -7.7705, -5.6886, -6.3912, -7.9648, -6.6782, -6.8752, -5.4556, -5.9806, -6.0227, -5.6321, -5.9625, -6.4469, -4.6187, -6.6641, -6.8898, -6.3583, -4.5402, -5.0442, -6.7321, -5.0679, -4.5974, -5.4466, -5.5839, -6.319, -5.2969, -4.9839, -6.1712, -5.8777, -6.0624, -5.1875, -5.4271, -5.6087, -5.8022, -5.6352, -5.4014, -5.509, -5.7253, -5.9698, -5.9468, -5.6967, -5.7103, -5.8269, -5.7914, -5.8948, -5.9021, -5.9095, -9.0106, -9.0119, -6.8182, -9.2839, -9.2847, -9.4478, -8.9346, -9.5407, -9.4534, -9.6405, -9.4574, -9.546, -9.6431, -7.6062, -9.5546, -6.19, -9.7601, -8.771, -9.763, -8.5857, -9.3188, -9.1246, -9.8877, -9.8877, -9.7696, -9.7722, -9.8922, -9.7753, -9.7755, -9.8947, -8.9746, -7.815, -9.0864, -7.9539, -7.5155, -8.5245, -8.6892, -8.4964, -6.5783, -8.6627, -8.6981, -7.9738, -5.0583, -8.2565, -7.3552, -6.3632, -8.2188, -8.9882, -6.6164, -6.3777, -7.4376, -6.2872, -6.0053, -6.8502, -6.8343, -7.7791, -5.5987, -5.8055, -6.5036, -6.3152, -5.5219, -7.2732, -4.8636, -6.1064, -6.0289, -5.6, -6.631, -6.922, -4.8364, -5.3021, -5.0292, -4.7633, -5.496, -4.9891, -5.9582, -5.6312, -6.2804, -6.245, -4.5824, -5.5891, -5.4384, -5.0968, -5.0119, -5.7558, -5.8107, -5.1578, -5.8763, -5.647, -5.2339, -5.5336, -5.1741, -5.4129, -5.5999, -5.2488, -5.6569, -5.5949, -5.6564, -5.7695, -8.0858, -8.9875, -8.6034, -9.1347, -9.1358, -9.1367, -9.2174, -8.9932, -9.0688, -7.2724, -9.3181, -9.3216, -6.9496, -8.348, -9.4222, -9.4223, -9.5306, -9.2403, -7.8076, -8.7792, -9.3302, -9.243, -9.5333, -8.9537, -8.5886, -9.5341, -9.5363, -9.4306, -8.5489, -7.6348, -6.6212, -8.1755, -7.8673, -8.3103, -8.8478, -7.9348, -7.2515, -8.8007, -8.3336, -6.775, -8.9131, -7.5115, -6.8037, -5.5263, -5.2844, -5.6818, -6.6577, -6.5035, -6.3264, -7.0724, -6.5885, -7.2688, -5.3944, -5.5621, -6.0698, -4.8651, -7.0026, -5.6694, -7.1792, -7.0288, -5.3383, -6.11, -5.4026, -6.3555, -4.5841, -5.5865, -6.0597, -5.8134, -5.8557, -4.8879, -6.3081, -5.6228, -5.044, -4.7401, -5.1277, -5.0245, -4.5772, -5.0141, -5.2622, -5.95, -5.6077, -5.2169, -4.889, -5.3065, -5.2644, -5.5391, -5.6118, -5.5505, -5.4516, -5.5024, -5.5889, -8.7318, -8.861, -8.6886, -8.2163, -8.0769, -9.308, -9.1257, -9.546, -9.6965, -9.7049, -8.6542, -9.7233, -9.8745, -9.8848, -8.2276, -9.8921, -10.0925, -9.8222, -10.099, -10.1048, -10.1068, -10.1171, -9.421, -9.6485, -9.1647, -9.9477, -9.9487, -8.8983, -9.9489, -10.3669, -9.0981, -7.6029, -9.5482, -8.9374, -7.5155, -7.4526, -8.6798, -7.9221, -8.1869, -9.2908, -6.6839, -6.129, -7.5078, -8.1384, -7.9849, -8.1944, -5.846, -7.5951, -7.3939, -6.4235, -6.6623, -7.7101, -6.4895, -6.498, -5.9679, -6.4396, -6.5179, -5.513, -6.8895, -6.5674, -6.225, -6.0305, -6.0717, -5.3316, -5.9401, -6.0222, -4.4749, -6.321, -5.6794, -5.2983, -5.7939, -4.8666, -6.0313, -5.5827, -4.9248, -5.0928, -5.4842, -5.3736, -5.712, -5.6236, -5.2737, -5.5452, -5.8196, -5.4143, -5.5074, -5.3997, -5.5001, -5.4426, -5.7619, -5.4483, -5.1968, -5.5945, -5.6788, -5.6865, -5.8183, -5.7532, -5.8021, -8.7421, -8.9767, -9.0889, -9.2921, -9.2927, -9.1858, -9.3006, -9.3015, -9.3076, -9.4279, -9.3143, -8.2468, -9.4316, -9.574, -9.5775, -9.583, -9.5844, -9.3326, -9.589, -7.5976, -9.3401, -8.827, -9.7579, -9.7564, -9.4688, -8.5531, -9.7718, -9.7782, -9.7849, -8.878, -8.3504, -9.2811, -8.2929, -8.5701, -8.1219, -8.6734, -8.392, -6.396, -7.9798, -6.0112, -8.9212, -6.538, -5.7923, -6.7796, -7.7645, -5.3375, -7.795, -7.84, -7.8688, -7.2501, -6.7988, -8.5538, -7.8241, -7.9937, -7.0021, -7.3335, -6.5509, -4.953, -5.6362, -6.5777, -7.466, -6.0407, -5.0672, -6.0392, -6.8258, -6.6869, -6.175, -5.6587, -5.655, -5.458, -4.9959, -6.0071, -5.2397, -6.1594, -6.1356, -4.8793, -5.4554, -6.2763, -5.4317, -5.3756, -5.8552, -5.3139, -5.0085, -5.4114, -5.7464, -5.6262, -6.0669, -5.609, -5.7982, -5.6509, -5.6444, -5.7943, -5.5844, -5.7829, -5.8496, -5.8657, -5.6792, -5.8232, -5.8438, -7.4546, -7.8366, -7.842, -7.8452, -7.8499, -7.8524, -7.8547, -7.8557, -7.8559, -7.8594, -7.2869, -8.477, -8.4782, -8.4804, -8.4822, -8.4829, -8.4849, -8.4858, -8.4866, -8.4865, -8.4869, -8.4869, -8.4877, -8.4877, -8.4876, -8.4879, -8.4887, -8.491, -8.4916, -8.491, -6.7409, -7.8614, -7.8652, -7.8835, -7.3409, -6.9498, -7.3259, -8.0216, -7.9002, -8.0626, -8.0741, -6.4596, -7.9976, -5.5849, -6.2494, -6.366, -5.5847, -5.7908, -7.8089, -6.6069, -5.7311, -5.9668, -6.0245, -6.1111, -6.2977, -6.2885, -6.3552, -6.3158, -6.2907, -6.681, -6.2805, -6.4058, -6.5599, -6.9913, -6.558, -6.8734, -6.7567, -6.5831, -6.608, -6.6652, -6.8258, -6.7481, -6.7324, -6.7396, -6.7306], \"loglift\": [30.0, 29.0, 28.0, 27.0, 26.0, 25.0, 24.0, 23.0, 22.0, 21.0, 20.0, 19.0, 18.0, 17.0, 16.0, 15.0, 14.0, 13.0, 12.0, 11.0, 10.0, 9.0, 8.0, 7.0, 6.0, 5.0, 4.0, 3.0, 2.0, 1.0, 0.9152, 0.9073, 0.9039, 0.9021, 0.8976, 0.895, 0.8928, 0.8922, 0.8919, 0.8917, 0.8894, 0.8885, 0.8883, 0.8872, 0.8871, 0.8856, 0.8855, 0.8847, 0.8847, 0.8838, 0.8831, 0.8829, 0.8828, 0.8827, 0.8819, 0.8814, 0.8807, 0.8807, 0.8794, 0.879, 0.8616, 0.8722, 0.874, 0.8519, 0.8647, 0.8453, 0.8545, 0.7875, 0.7781, 0.7933, 0.7777, 0.8034, 0.8236, 0.8578, 0.7922, 0.774, 0.7628, 0.8052, 0.7244, 0.8223, 0.7565, 0.7664, 0.791, 0.8113, 0.6627, 0.5839, 0.7247, 0.4304, 0.4942, 0.5988, 0.5316, 0.672, 0.6011, 0.5242, 0.3549, 0.5557, 0.3805, 0.334, 0.2008, 0.4139, 0.5213, 0.3378, 0.3493, 0.5007, 0.3037, 0.3657, 0.1772, 0.1375, 0.2819, 0.3319, -0.0184, 0.0832, 0.1943, 0.0931, 0.4085, 0.1094, -0.3192, -0.0089, 0.3014, -0.2469, -0.2311, 0.0972, -0.1643, 1.8163, 1.8088, 1.7924, 1.7906, 1.7853, 1.7734, 1.7684, 1.7678, 1.7615, 1.7584, 1.758, 1.757, 1.7541, 1.7503, 1.7502, 1.7501, 1.75, 1.7478, 1.7365, 1.7343, 1.7311, 1.7307, 1.7299, 1.729, 1.729, 1.7287, 1.7287, 1.7251, 1.7242, 1.7228, 1.7074, 1.7045, 1.6971, 1.6883, 1.6937, 1.6172, 1.6823, 1.641, 1.627, 1.6538, 1.6971, 1.6633, 1.6105, 1.6023, 1.3571, 1.3078, 1.2281, 1.2324, 1.5004, 1.3594, 1.2408, 1.3148, 1.4981, 1.3862, 1.3348, 1.0879, 1.5056, 1.4116, 0.9168, 1.0643, 1.4431, 1.0887, 1.1326, 0.7195, 0.8457, 0.8571, 0.7335, 0.8099, 0.9705, 0.3023, 1.0207, 1.0976, 0.8818, 0.1721, 0.3444, 1.0058, 0.3106, 0.0253, 0.4034, 0.4557, 0.8161, 0.2356, 0.0257, 0.681, 0.484, 0.6069, -0.026, 0.1132, 0.1738, 0.3229, 0.1455, -0.1111, -0.1462, 0.1037, 0.4601, 0.3846, -0.127, -0.125, 0.0103, -0.4447, -0.1978, -0.1988, -0.2669, 1.889, 1.8879, 1.8847, 1.8692, 1.8687, 1.8606, 1.8589, 1.8556, 1.8548, 1.8516, 1.8509, 1.8502, 1.8498, 1.8477, 1.8416, 1.8402, 1.8394, 1.8393, 1.8376, 1.8338, 1.8334, 1.8323, 1.8301, 1.83, 1.829, 1.8274, 1.8263, 1.8244, 1.8235, 1.8234, 1.8185, 1.7943, 1.8158, 1.7875, 1.7671, 1.7976, 1.8018, 1.7928, 1.6897, 1.7915, 1.7924, 1.7434, 1.5317, 1.759, 1.6818, 1.564, 1.736, 1.8046, 1.5294, 1.4986, 1.6142, 1.4626, 1.4217, 1.5331, 1.513, 1.6526, 1.2842, 1.3091, 1.3888, 1.3444, 1.1785, 1.5344, 1.0403, 1.2855, 1.2434, 1.11, 1.3594, 1.415, 0.7998, 0.9235, 0.8175, 0.6953, 0.9397, 0.7079, 1.0771, 0.9167, 1.1975, 1.1793, 0.3386, 0.7688, 0.6682, 0.4436, 0.3347, 0.7919, 0.7954, 0.0037, 0.8407, 0.5486, -0.2242, 0.2489, -0.4617, -0.0502, 0.2501, -0.6261, 0.0464, -0.3045, -0.0711, 0.2177, 2.0945, 2.0729, 2.0718, 2.0697, 2.0685, 2.0679, 2.0677, 2.0674, 2.0614, 2.0598, 2.0551, 2.0518, 2.051, 2.0504, 2.0476, 2.0473, 2.0459, 2.0453, 2.0445, 2.0441, 2.0435, 2.0431, 2.0429, 2.0428, 2.0428, 2.0424, 2.0401, 2.0395, 2.039, 2.0352, 2.0243, 2.0345, 2.0264, 2.0223, 2.0304, 2.0021, 1.9599, 2.0232, 1.9991, 1.9153, 2.0272, 1.9369, 1.8748, 1.7761, 1.7234, 1.7391, 1.8317, 1.8153, 1.7513, 1.835, 1.7678, 1.8355, 1.5419, 1.5358, 1.5955, 1.3605, 1.7471, 1.4469, 1.7716, 1.7284, 1.2981, 1.4887, 1.2978, 1.5221, 0.9562, 1.2675, 1.4182, 1.2867, 1.2924, 0.8946, 1.4655, 1.1496, 0.8027, 0.6065, 0.7761, 0.6724, 0.3438, 0.622, 0.7311, 1.2532, 0.9401, 0.4865, 0.1206, 0.2788, 0.1941, 0.5675, 0.3899, 0.1763, -0.2901, -0.212, -0.9662, 2.2016, 2.1983, 2.1881, 2.1747, 2.1616, 2.1603, 2.1594, 2.149, 2.1337, 2.127, 2.1186, 2.1162, 2.1132, 2.1037, 2.1021, 2.0973, 2.0823, 2.0814, 2.076, 2.0701, 2.0696, 2.0596, 2.0524, 2.051, 2.0451, 2.0439, 2.0423, 2.0422, 2.0414, 2.0367, 2.0352, 1.9719, 2.0276, 1.9996, 1.9083, 1.8535, 1.9517, 1.8846, 1.8923, 2.0, 1.6479, 1.5112, 1.7267, 1.8234, 1.7775, 1.8049, 1.308, 1.6755, 1.6283, 1.398, 1.4461, 1.6688, 1.2924, 1.2812, 1.1179, 1.236, 1.258, 0.9226, 1.3812, 1.2643, 1.1246, 1.0147, 1.0022, 0.6849, 0.9428, 0.9674, 0.2374, 1.0964, 0.6664, 0.4286, 0.6957, 0.1431, 0.8209, 0.5239, -0.0038, 0.0687, 0.3658, 0.269, 0.5047, 0.4161, 0.0167, 0.2921, 0.5405, 0.0443, 0.1287, -0.0369, 0.0324, -0.054, 0.4187, -0.1017, -0.5742, -0.0092, 0.0741, 0.096, 0.4138, -0.1835, 0.1018, 2.2981, 2.2888, 2.2665, 2.2653, 2.265, 2.2643, 2.2591, 2.2573, 2.2508, 2.2493, 2.2475, 2.2441, 2.2438, 2.2395, 2.2348, 2.2342, 2.2312, 2.2283, 2.2249, 2.2246, 2.2223, 2.2145, 2.2144, 2.2138, 2.2101, 2.2049, 2.2, 2.1983, 2.1941, 2.191, 2.183, 2.18, 2.1225, 2.1355, 2.1023, 2.1288, 2.094, 1.8695, 2.0294, 1.7301, 2.1265, 1.7003, 1.5445, 1.6805, 1.8933, 1.2184, 1.8392, 1.8334, 1.8301, 1.6301, 1.4743, 2.0204, 1.7714, 1.8156, 1.4477, 1.5652, 1.2576, 0.5796, 0.8128, 1.1917, 1.5987, 0.9165, 0.2956, 0.7773, 1.2132, 1.1222, 0.8157, 0.4816, 0.4515, 0.3245, 0.0138, 0.673, 0.1489, 0.7609, 0.7442, -0.167, 0.248, 0.8192, 0.2044, 0.0829, 0.4612, -0.0235, -0.3858, -0.0648, 0.2701, 0.1267, 0.6409, 0.0336, 0.2, -0.0656, -0.1041, 0.1377, -0.4229, 0.0461, 0.1375, 0.1277, -0.7582, -0.2534, -0.4653, 6.1121, 5.8328, 5.818, 5.8109, 5.7987, 5.7925, 5.786, 5.7847, 5.7832, 5.7741, 5.4617, 5.2948, 5.2927, 5.2892, 5.2866, 5.2864, 5.2839, 5.2815, 5.2804, 5.2798, 5.2796, 5.2792, 5.2791, 5.279, 5.279, 5.2773, 5.2766, 5.2733, 5.2733, 5.273, 5.119, 5.1549, 5.1534, 5.1207, 4.6491, 4.3765, 4.5053, 4.8558, 4.7216, 4.7921, 4.7791, 2.659, 4.5296, -0.5752, 0.6304, 0.8626, -0.9621, -0.6294, 3.8521, 1.1601, -1.0188, -0.5782, -0.7342, -0.5785, -0.1226, -0.506, -0.5052, -0.6732, -0.928, 0.6528, -1.3595, -1.0273, -0.7227, 1.4896, -0.8547, 0.583, -0.0923, -1.1245, -1.0227, -0.7332, 0.1914, -0.6008, -1.0056, -0.9106, -1.1609]}, \"token.table\": {\"Topic\": [1, 2, 1, 2, 3, 4, 5, 6, 1, 2, 3, 4, 5, 6, 5, 1, 2, 3, 4, 5, 6, 1, 2, 3, 4, 5, 6, 1, 1, 2, 3, 4, 5, 6, 1, 2, 3, 4, 5, 6, 1, 2, 6, 2, 1, 2, 3, 4, 5, 6, 1, 2, 3, 4, 5, 6, 4, 1, 1, 2, 3, 4, 5, 6, 5, 6, 1, 2, 1, 2, 3, 4, 5, 6, 1, 2, 1, 5, 2, 1, 2, 4, 5, 6, 1, 2, 3, 4, 5, 6, 3, 4, 2, 1, 2, 3, 4, 5, 6, 1, 2, 3, 4, 5, 6, 1, 2, 3, 4, 5, 6, 3, 3, 4, 5, 2, 1, 1, 2, 3, 4, 5, 4, 3, 5, 5, 1, 2, 3, 4, 5, 6, 3, 3, 4, 1, 2, 3, 4, 5, 2, 5, 6, 6, 1, 2, 6, 1, 4, 3, 4, 3, 1, 2, 3, 4, 5, 6, 7, 1, 2, 3, 4, 5, 6, 6, 5, 1, 2, 3, 2, 1, 2, 3, 4, 5, 6, 4, 1, 2, 3, 4, 5, 6, 1, 2, 3, 4, 5, 6, 1, 2, 5, 6, 1, 2, 3, 4, 5, 6, 1, 1, 2, 3, 4, 5, 6, 1, 2, 3, 4, 5, 6, 7, 3, 4, 1, 3, 4, 6, 1, 2, 3, 4, 5, 6, 1, 2, 4, 5, 6, 1, 2, 3, 4, 5, 6, 1, 2, 3, 4, 5, 6, 1, 2, 3, 4, 5, 6, 3, 1, 2, 1, 2, 3, 4, 5, 6, 1, 2, 4, 1, 2, 3, 4, 5, 6, 1, 2, 3, 4, 5, 6, 5, 2, 3, 4, 5, 6, 1, 2, 3, 4, 5, 6, 1, 2, 1, 2, 3, 4, 6, 2, 1, 2, 3, 4, 5, 6, 1, 2, 5, 6, 1, 2, 3, 1, 2, 3, 4, 5, 6, 2, 3, 4, 5, 1, 2, 3, 4, 5, 6, 1, 2, 3, 4, 5, 6, 3, 4, 5, 3, 1, 2, 3, 4, 3, 4, 1, 2, 3, 4, 5, 6, 1, 3, 4, 1, 2, 3, 4, 5, 6, 7, 1, 2, 3, 4, 5, 6, 1, 2, 3, 4, 5, 6, 1, 2, 3, 4, 5, 6, 1, 2, 3, 4, 5, 6, 6, 1, 2, 3, 4, 5, 6, 1, 2, 3, 4, 5, 6, 4, 1, 2, 3, 4, 5, 6, 7, 1, 2, 3, 4, 5, 6, 7, 3, 4, 3, 4, 1, 2, 3, 4, 5, 6, 1, 2, 3, 4, 5, 6, 2, 3, 6, 1, 2, 3, 4, 5, 6, 5, 6, 6, 5, 3, 4, 5, 1, 2, 3, 4, 5, 6, 7, 1, 2, 3, 4, 5, 6, 3, 3, 5, 1, 2, 3, 4, 5, 6, 7, 1, 2, 3, 4, 5, 6, 3, 4, 1, 2, 3, 4, 5, 6, 3, 4, 1, 2, 5, 1, 2, 3, 4, 5, 6, 2, 3, 5, 6, 1, 2, 3, 4, 5, 6, 1, 2, 3, 4, 5, 6, 1, 2, 3, 4, 5, 6, 3, 5, 1, 1, 2, 6, 1, 2, 3, 4, 5, 6, 6, 1, 2, 3, 4, 5, 6, 4, 1, 2, 3, 4, 5, 6, 1, 2, 5, 6, 1, 2, 4, 3, 1, 3, 1, 2, 3, 4, 5, 6, 1, 2, 3, 6, 1, 2, 3, 4, 5, 6, 1, 2, 3, 4, 5, 6, 2, 1, 2, 3, 4, 5, 6, 1, 2, 3, 4, 5, 6, 1, 2, 3, 4, 5, 6, 1, 2, 3, 4, 5, 6, 1, 2, 3, 4, 5, 6, 1, 2, 3, 4, 5, 6, 3, 5, 3, 4, 6, 1, 2, 3, 4, 5, 6, 1, 2, 3, 4, 5, 6, 3, 4, 6, 2, 3, 4, 5, 6, 1, 2, 3, 4, 5, 6, 1, 2, 3, 4, 5, 6, 1, 2, 3, 4, 5, 6, 1, 2, 3, 4, 5, 6, 3, 1, 1, 5, 3, 4, 1, 2, 3, 4, 5, 6, 1, 2, 1, 2, 1, 2, 3, 4, 5, 6, 1, 1, 2, 3, 4, 5, 6, 7, 1, 2, 3, 4, 5, 6, 2, 3, 4, 5, 6, 1, 2, 3, 4, 5, 6, 1, 2, 3, 4, 5, 6, 4, 1, 2, 3, 4, 5, 6, 7, 1, 2, 3, 4, 5, 6, 7, 1, 2, 1, 2, 5, 6, 4, 3, 4, 1, 2, 3, 4, 5, 6, 2, 3, 4, 5, 6, 5, 4, 4, 1, 2, 5, 3, 4, 3, 3, 4, 3, 4, 1, 6, 1, 2, 3, 5, 6, 1, 2, 4, 6, 1, 2, 3, 4, 5, 6, 7, 1, 2, 1, 1, 6, 1, 2, 3, 4, 5, 6, 6, 1, 2, 3, 4, 5, 6, 5, 1, 2, 3, 4, 5, 6, 3, 1, 2, 5, 6, 1, 2, 3, 4, 5, 6, 1, 2, 3, 4, 5, 6, 3, 4, 1, 2, 6, 1, 2, 3, 4, 5, 6, 1, 2, 3, 4, 3, 4, 3, 3, 4, 4, 1, 2, 3, 4, 5, 6, 1, 2, 3, 4, 5, 6, 1, 2, 3, 4, 5, 6, 3, 5, 3, 4, 1, 2, 3, 4, 5, 6, 1, 2, 3, 4, 5, 6, 1, 2, 3, 1, 2, 3, 4, 5, 6, 1, 2, 3, 1, 2, 3, 4, 5, 6, 1, 2, 3, 4, 5, 6, 1, 2, 3, 4, 5, 6, 1, 2, 3, 4, 5, 6, 7, 1, 2, 3, 4, 5, 6, 1, 3, 1, 2, 3, 4, 5, 6, 1, 2, 3, 4, 5, 6, 1, 2, 3, 4, 5, 6, 1, 2, 1, 2, 4, 5, 2, 1, 2, 3, 4, 5, 6, 1, 2, 3, 4, 5, 6, 7, 4, 5, 6, 1, 2, 1, 2, 3, 4, 5, 6, 2, 5, 6, 1, 2, 3, 4, 5, 6, 4, 5, 6, 1, 2, 1, 2, 3, 4, 5, 6, 1, 2, 3, 4, 5, 6, 3, 1, 2, 5, 6, 3, 4, 1, 2, 3, 4, 5, 6, 1, 2, 3, 4, 5, 6, 1, 2, 3, 4, 5, 6, 1, 2, 3, 4, 5, 6, 2, 4, 3, 4, 1, 2, 3, 4, 5, 6, 1, 2, 3, 4, 5, 6, 1, 2, 3, 4, 5, 1, 2, 3, 4, 5, 6, 5, 6, 2, 2, 5, 2, 1, 2, 3, 4, 5, 6, 1, 2, 3, 1, 3, 5, 1, 2, 3, 4, 5, 6, 1, 2, 3, 4, 5, 6, 7, 1, 2, 3, 4, 5, 6, 1, 2, 3, 4, 5, 6, 1, 2, 3, 4, 5, 6, 5, 3, 5, 2, 3, 4, 5, 1, 1, 2, 3, 4, 5, 6, 1, 2, 3, 4, 5, 6, 1, 4, 1, 2, 3, 4, 5, 6, 1, 2, 3, 4, 5, 6, 1, 2, 3, 4, 5, 6, 7, 3, 4, 1, 2, 1, 2, 3, 6, 3, 4, 6, 1, 2, 4, 1, 2, 3, 4, 5, 6, 1, 1, 2, 3, 4, 5, 6, 1, 2, 3, 4, 5, 6, 7, 1, 2, 3, 4, 5, 6, 1, 2, 3, 4, 5, 6, 1, 2, 4, 6, 3, 4, 3, 1, 2, 3, 4, 5, 6, 1, 2, 3, 4, 5, 6, 1, 2, 3, 4, 5, 6, 1, 2, 3, 4, 5, 6, 1, 2, 3, 4, 5, 6, 1, 2, 3, 4, 5, 6, 6, 3, 4, 5, 1, 2, 6, 1, 2, 3, 4, 5, 6, 1, 2, 4, 1, 2, 3, 4, 5, 6, 1, 2, 3, 4, 5, 6, 1, 2, 3, 4, 5, 6, 1, 2, 3, 4, 5, 6, 2, 1, 2, 3, 4, 5, 6, 6, 1, 2, 3, 4, 5, 6, 7, 5, 6, 1, 2, 3, 4, 5, 6, 1, 1, 2, 3, 4, 5, 6, 1, 2, 3, 4, 5, 6, 1, 2, 3, 4, 5, 6, 1, 2, 3, 4, 5, 6, 1, 2, 3, 4, 5, 6, 1, 2, 3, 4, 5, 6, 1, 2, 3, 4, 5, 6, 7, 1, 2, 5, 6, 1, 2, 3, 4, 5, 6, 1, 2, 3, 4, 5, 6, 3, 4, 5, 3, 4, 6, 4, 1, 2, 3, 4, 5, 6, 1, 2, 3, 4, 5, 6, 3, 5, 1, 2, 3, 5, 6, 3, 4, 5, 1, 2, 3, 2, 3, 5, 1, 2, 3, 4, 5, 6, 5, 1, 2, 3, 4, 5, 6, 5, 6, 3, 4, 1, 2, 3, 4, 5, 6, 5, 1, 2, 3, 4, 5, 6, 3, 4, 5, 6, 3, 4, 5, 5, 3, 1, 2, 3, 1, 2, 6, 1, 3, 4, 1, 2, 3, 4, 5, 6, 1, 2, 3, 4, 5, 6, 6, 5, 1, 2, 3, 4, 5, 6, 1, 2, 3, 4, 5, 6, 1, 2, 3, 4, 5, 6, 1, 2, 6, 3, 2, 2, 3, 5, 6, 1, 5, 3, 4, 1, 2, 3, 4, 5, 6, 1, 2, 3, 4, 5, 1, 2, 3, 4, 5, 6, 6, 1, 2, 3, 4, 6, 1, 2, 3, 5, 3, 4, 4, 3, 4, 2, 3, 4, 5, 6, 1, 2, 3, 4, 5, 6, 1, 2, 3, 4, 6, 2, 3, 4, 5, 6, 3, 4, 5, 1, 2, 5, 6, 1, 2, 3, 4, 5, 6, 7, 2, 1, 2, 3, 4, 5, 6, 1, 2, 5, 6, 1, 2, 3, 4, 5, 6, 1, 2, 3, 4, 5, 6, 5, 6, 1, 2, 3, 4, 5, 6, 4, 5, 1, 2, 3, 6, 1, 2, 3, 5, 6, 1, 1, 2, 3, 4, 5, 6, 1, 2, 3, 4, 5, 6, 5, 1, 2, 3, 4, 5, 6, 1, 2, 3, 4, 5, 6, 1, 2, 3, 4, 5, 6, 3, 4, 4, 1, 2, 3, 4, 5, 6, 5, 6, 1, 2, 3, 4, 5, 6, 1, 1, 2, 3, 4, 5, 6, 1, 2, 3, 4, 5, 6, 3, 4, 5, 6, 3, 4, 6, 6, 2, 5, 1, 6, 1, 2, 3, 4, 5, 6, 7, 1, 2, 3, 4, 5, 6, 1, 2, 3, 4, 5, 6, 1, 2, 3, 4, 5, 6, 1, 2, 3, 4, 5, 6, 1, 2, 3, 4, 5, 6, 1, 2, 3, 4, 5, 6, 1, 2, 4, 5, 6, 3, 4, 4, 1, 2, 3, 4, 5, 6, 6, 1, 2, 3, 4, 5, 6, 7, 5, 1, 1, 1, 2, 3, 4, 5, 6, 7, 2, 3, 4, 1, 2, 3, 4, 5, 6, 4, 1, 2, 6, 1, 2, 3, 4, 5, 6, 1, 3, 4, 3, 1, 5, 5, 1, 2, 3, 4, 5, 6, 6, 6, 1, 2, 3, 4, 5, 6, 1, 2, 3, 4, 5, 6, 3, 4, 5, 1, 2, 3, 4, 5, 6, 2, 3, 4, 6, 1, 2, 6, 5, 1, 2, 3, 4, 5, 6, 1, 2, 3, 4, 5, 6, 3, 4, 1, 2, 5, 6, 1, 2, 3, 4, 5, 6, 7, 3, 4, 1, 2, 3, 4, 5, 6, 1, 2, 6, 5, 6, 6, 1, 2, 3, 4, 5, 6, 7, 6, 3, 4, 6], \"Freq\": [0.15431862458435228, 0.7715931229217614, 0.11985460470642027, 0.03995153490214009, 0.07990306980428018, 0.059927302353210136, 0.09987883725535023, 0.5792972560810313, 0.060709134730252474, 0.011563644710524281, 0.6417822814340975, 0.16767284830260207, 0.03180002295394177, 0.08383642415130103, 0.9294058520998291, 0.5215097328846138, 0.14022102987421434, 0.11731960092627675, 0.064686492291543, 0.07673987594835226, 0.0791505526797141, 0.1312565036627762, 0.08385832178455145, 0.2296988814098583, 0.029168111925061375, 0.4411676928665533, 0.08385832178455145, 0.9592344129012692, 0.20183296220317717, 0.2709538396700187, 0.08294505296020979, 0.0055296701973473195, 0.3677230681235968, 0.06635604236816783, 0.21459213673312133, 0.19176318601683184, 0.061638166933981664, 0.018263160573031605, 0.47027638475556377, 0.04337500636095006, 0.058616135458116746, 0.8401646082330066, 0.07815484727748899, 0.9339263526142377, 0.0848811045324143, 0.03495104304275883, 0.3617155565695041, 0.458247008782838, 0.036615378425747344, 0.02330069536183922, 0.15965807534514503, 0.16469107947161196, 0.22368907228741863, 0.30617441769340425, 0.06123488353868085, 0.08444262478850054, 0.9076272651792204, 0.9629461904137486, 0.5920765151457841, 0.23342786746552177, 0.025180265586659784, 0.006805477185583725, 0.0796240830713296, 0.06329093782592865, 0.06849344606159552, 0.8904147988007417, 0.1014596654073145, 0.811677323258516, 0.3810073651532244, 0.2910472928253798, 0.021167075841845802, 0.05291768960461451, 0.11112714816969047, 0.14816953089292062, 0.9506728820098654, 0.029708527562808295, 0.9516240739817057, 0.02321034326784648, 0.9279417159815295, 0.12537745919203394, 0.5717212139156748, 0.0050150983676813575, 0.140422754295078, 0.16048314776580344, 0.04422134322267069, 0.13266402966801208, 0.5516030707248923, 0.10938963849818541, 0.13266402966801208, 0.027929269403792017, 0.07200440378977682, 0.9000550473722103, 0.9025279394636325, 0.15525032983402193, 0.655501392632537, 0.034500073296449316, 0.017250036648224658, 0.017250036648224658, 0.12075025653757261, 0.8688769675182981, 0.08709023217549376, 0.006076062709918169, 0.0020253542366393896, 0.012152125419836337, 0.022278896603033286, 0.1755889000623026, 0.0651807280534305, 0.2407696281157331, 0.4256700607570972, 0.02394394091758672, 0.06651094699329643, 0.8789102197104037, 0.9101240432184219, 0.014001908357206492, 0.05600763342882597, 0.9206986419604603, 0.9637904345163023, 0.04075776510873417, 0.06792960851455694, 0.14944513873202528, 0.013585921702911388, 0.7064679285513922, 0.9352860459869811, 0.10471099324379395, 0.8900434425722485, 0.9127591590911417, 0.10300148353671446, 0.028091313691831214, 0.2083439098810815, 0.5805538162978451, 0.03979602773009422, 0.037455084922441616, 0.9189653075905486, 0.8685045469626022, 0.11843243822217302, 0.9688546501522561, 0.004630187653289341, 0.6528564591137971, 0.24539994562433506, 0.09723394071907616, 0.02439483037647299, 0.2439483037647299, 0.7074500809177167, 0.8682048978301002, 0.06710572286426014, 0.8052686743711216, 0.1006585842963902, 0.06190632251825019, 0.8666885152555027, 0.9431783780808521, 0.8743450128279292, 0.9673470382487664, 0.2843801322883706, 0.16034198948174086, 0.1316014441972779, 0.22084840060692612, 0.12403814280662974, 0.08017099474087043, 0.001512660278129631, 0.0018445301722931748, 0.005533590516879524, 0.5957832456506954, 0.2416334525704059, 0.14940694395574716, 0.005533590516879524, 0.9219967220310067, 0.9043994856523259, 0.9216656648750312, 0.034135765365741894, 0.034135765365741894, 0.9334197035660932, 0.4105587538204705, 0.4081717843215143, 0.02864363398747469, 0.03580454248434336, 0.07638302396659917, 0.04057848148225581, 0.9672404347933324, 0.8441861900062699, 0.09081709623539334, 0.0020640249144407577, 0.030960373716611367, 0.014448174401085305, 0.018576224229966822, 0.0015801769460950547, 0.004740530838285164, 0.4977557380199423, 0.3223560970033912, 0.1674987562860758, 0.006320707784380219, 0.31026469562250336, 0.6648529191910787, 0.014774509315357303, 0.014774509315357303, 0.16814878805847602, 0.4582878733358464, 0.003297035059970118, 0.003297035059970118, 0.1846339633583266, 0.1846339633583266, 0.9736900954784495, 0.1602343304083505, 0.14011833221855757, 0.10543557671891461, 0.20046632678793633, 0.18312494903811485, 0.2115648085478221, 0.215086386758881, 0.437946980268083, 0.028505424751177, 0.007774206750320999, 0.08551627425353099, 0.22286059350920198, 0.002591402250107, 0.07118801094060634, 0.9165456408603067, 0.037329635872593185, 0.8585816250696432, 0.055994453808889774, 0.018664817936296593, 0.46636818198941166, 0.21835735688521588, 0.02336333859677207, 0.02695769838089085, 0.0871632247648804, 0.1779208093138796, 0.09016816694189253, 0.6612332242405452, 0.030056055647297512, 0.060112111294595025, 0.15028027823648754, 0.2132179917661905, 0.5046670452595444, 0.007669711934035629, 0.013805481481264132, 0.1840730864168551, 0.07669711934035629, 0.15130562908324982, 0.0652179435703663, 0.15391434682606447, 0.5086999598488572, 0.020869741942517214, 0.10173999196977143, 0.011578188426755601, 0.028945471066889005, 0.40813114204313494, 0.5383857618441354, 0.0057890942133778005, 0.0057890942133778005, 0.8377549642559482, 0.13171518572221153, 0.7902911143332692, 0.049687029763020855, 0.0429115257044271, 0.2518229008444011, 0.5499450794225262, 0.03274826961653647, 0.0722720432916667, 0.15943847843600223, 0.7573327725710105, 0.03985961960900056, 0.5951406641701324, 0.11404787623009231, 0.12301233811717381, 0.06673543849271778, 0.04781046339776796, 0.05328874566209554, 0.6859498346238749, 0.224095165096246, 0.011842427423785357, 0.012753383379461154, 0.03643823822703187, 0.028239634625949698, 0.8525611830142711, 0.013847257916404444, 0.27694515832808886, 0.6715920089456154, 0.013847257916404444, 0.020770886874606664, 0.03270454996128784, 0.08409741418616874, 0.12147404271335485, 0.6867955491870447, 0.03737662852718611, 0.03737662852718611, 0.1749052332083547, 0.8045640727584316, 0.8865811357693704, 0.0492545075427428, 0.021109074661175484, 0.007036358220391828, 0.028145432881567314, 0.7436048462058723, 0.28504195772633606, 0.10883420204096468, 0.03627806734698823, 0.010365162099139494, 0.05700839154526721, 0.5027103618082654, 0.949416146818468, 0.020639481452575388, 0.020639481452575388, 0.0068798271508584636, 0.9702944684831583, 0.010213625984033244, 0.010213625984033244, 0.2670666828620941, 0.34293789958428, 0.06272020582367363, 0.02326717312813699, 0.16995152545769626, 0.13454495765400956, 0.004582423242168055, 0.5911325982396791, 0.3665938593734444, 0.03665938593734444, 0.18868217392303532, 0.15866455534437063, 0.12435870554018237, 0.021441156127617652, 0.4116701976502589, 0.09005285573599414, 0.8798554825363035, 0.051756204855076676, 0.015526861456523003, 0.02070248194203067, 0.010351240971015335, 0.025878102427538338, 0.9447943643924328, 0.039641721582899275, 0.0066069535971498795, 0.8372896713274721, 0.024550905714487314, 0.04910181142897463, 0.8347307942925687, 0.07365271714346194, 0.8689293961232063, 0.07899358146574602, 0.4562503650748519, 0.20655808804986636, 0.029768665630716035, 0.020048285016604675, 0.13851542375108686, 0.14884332815358017, 0.9797093567748832, 0.9181211025512787, 0.07651009187927323, 0.4515682316419969, 0.14337626345903165, 0.144141957789921, 0.08805484805227579, 0.1114085251444011, 0.06144697005387071, 0.00019142358272233867, 0.1574067286178359, 0.11243337758416849, 0.0449733510336674, 0.01124333775841685, 0.5846535634376762, 0.10119003982575164, 0.8122320308130826, 0.03951961225466983, 0.03951961225466983, 0.024959755108212526, 0.047839530624074006, 0.036399642866143264, 0.3300514817279015, 0.5585486613856794, 0.006347143879382721, 0.006347143879382721, 0.019041431638148164, 0.07616572655259266, 0.333724373067204, 0.09498796197358748, 0.3096607560338952, 0.08295615345693307, 0.13551615908231815, 0.043061209428026326, 0.9053591448172913, 0.012077319675898994, 0.04830927870359598, 0.20531443449028292, 0.036231959027696985, 0.6642525821744447, 0.02415463935179799, 0.11113155813271688, 0.0884001030601157, 0.03283432399375726, 0.04798862737549138, 0.1894287922716765, 0.5278749011304052, 0.9074301580349041, 0.4697012791849061, 0.13174282517703673, 0.105829773613289, 0.09515969355762817, 0.105829773613289, 0.09145782904852136, 0.00021775673582981276, 0.2838821702132756, 0.3468485162380247, 0.035218464725707124, 0.011739488241902376, 0.1237982396418796, 0.19743684770472178, 0.0010672262038093068, 0.8825263421677724, 0.07354386184731436, 0.9083375138315855, 0.0534316184606815, 0.03942431527893566, 0.050375513967528894, 0.311014042756048, 0.5212770575770381, 0.021902397377186477, 0.054755993442966194, 0.8455654941199376, 0.08130437443460939, 0.008130437443460939, 0.005420291628973959, 0.016260874886921878, 0.040652187217304694, 0.05391469475265721, 0.10782938950531443, 0.8087204212898582, 0.2718213287319264, 0.06109745462323116, 0.4214477482173904, 0.11221981461409804, 0.11346670144314357, 0.01995018926472854, 0.9446327115375465, 0.927568035882641, 0.9211310720808757, 0.9220767452956409, 0.15316078752267603, 0.8214987694398078, 0.013923707956606912, 0.4082903544298882, 0.3022614639384056, 0.04009052575797352, 0.018462742125382542, 0.13767930556356694, 0.09231371062691271, 0.0005275069178680726, 0.18184520599665432, 0.09092260299832716, 0.07273808239866174, 0.1091071235979926, 0.5273510973902975, 0.018184520599665435, 0.9510961822859925, 0.9428370525077521, 0.850953879235686, 0.45205211825895275, 0.27223956564293805, 0.031929331772937185, 0.026887858335104996, 0.11091241563230811, 0.10587094219447592, 0.0016804911459440623, 0.27409827049320007, 0.16154584058053337, 0.10990413744413335, 0.16286998681480003, 0.07812462782173335, 0.21318754371693338, 0.08340320185177567, 0.9174352203695324, 0.12495097561188342, 0.13337463688908904, 0.21199547547634154, 0.11512337078847687, 0.38468053165905686, 0.030886758016420622, 0.09982310984584923, 0.8921690442472775, 0.1523792170627953, 0.8126891576682416, 0.0507930723542651, 0.6695789762096332, 0.13095086988601684, 0.026190173977203367, 0.0128480098756092, 0.06424004937804599, 0.09586591984108403, 0.1163424604318527, 0.1163424604318527, 0.6515177784183751, 0.09307396834548216, 0.002141066321377857, 0.01391693108895607, 0.5181380497734414, 0.16057997410333927, 0.2665627570115432, 0.0374686606241125, 0.6494248739813445, 0.1261472776798295, 0.027098304094185597, 0.017754061303087116, 0.07662279088700755, 0.10185224642297346, 0.2159126376172317, 0.13474247309947543, 0.3181870449096046, 0.10957972209897097, 0.1201318434862793, 0.10146270564719535, 0.150150368046277, 0.8258270242545234, 0.9759012122764453, 0.9435916686096963, 0.9126927661944877, 0.9192249006511916, 0.016072682699918517, 0.04821804809975555, 0.12054512024938888, 0.18483585104906294, 0.17679950969910369, 0.45003511559771847, 0.920010626110586, 0.19992589750832043, 0.08944053309582757, 0.2025565014229036, 0.06313449394999593, 0.3788069636999756, 0.06839570177916225, 0.9548217050294598, 0.156728432022263, 0.028496078549502365, 0.5200534335284182, 0.2404356627614262, 0.01602904418409508, 0.03918210800556575, 0.9131397343966471, 0.032612133371308825, 0.032612133371308825, 0.01304485334852353, 0.4526129891713566, 0.1508709963904522, 0.3017419927809044, 0.958505958446662, 0.9583782053848597, 0.8378561377475483, 0.3558244309678728, 0.08488765782051848, 0.13502855414973666, 0.2445468277109237, 0.07345201479806522, 0.10643944659360348, 0.9326662230306261, 0.013715679750450384, 0.027431359500900768, 0.013715679750450384, 0.4609128998924786, 0.17983940021644512, 0.046448586810869934, 0.00952791524325537, 0.2739275632435919, 0.029774735135173033, 0.23660864248835636, 0.40273811487379807, 0.15606101951359674, 0.07803050975679837, 0.10068452871844952, 0.02517113217961238, 0.9201402966050981, 0.09464123490173801, 0.032448423394881604, 0.29609186347829464, 0.500246527337758, 0.040560529243602005, 0.0351524586777884, 0.39855806478541494, 0.1389709041685986, 0.10663176294697504, 0.0882771152265941, 0.08390696100745577, 0.1835464772038095, 0.0367275279854363, 0.13116974280512964, 0.2885734341712852, 0.07607845082697519, 0.37514546442267077, 0.09444221481969334, 0.049262951818804336, 0.09852590363760867, 0.17242033136581517, 0.09852590363760867, 0.4214719211164371, 0.15873617808281398, 0.051507049230198484, 0.01716901641006616, 0.12018311487046313, 0.06867606564026464, 0.13735213128052928, 0.6180845907623819, 0.1423717526210121, 0.08419098832877157, 0.36756553441097833, 0.08692890664840643, 0.261471199525128, 0.0568118051324231, 0.17577943520633227, 0.7910074584284953, 0.8900238686780386, 0.04450119343390193, 0.8897278697966734, 0.3467329969485036, 0.2906743686993444, 0.09654541531799651, 0.02283870039780563, 0.2366919859408947, 0.007266859217483609, 0.034969159530488826, 0.034969159530488826, 0.11656386510162942, 0.18650218416260708, 0.5595065524878212, 0.06993831906097765, 0.04351905766363496, 0.9139002109363341, 0.04351905766363496, 0.04292597503750501, 0.12877792511251504, 0.08585195007501002, 0.04292597503750501, 0.6868156006000802, 0.08303815058375955, 0.1660763011675191, 0.05397479787944371, 0.020759537645939886, 0.1619243936383311, 0.5148365336193093, 0.8110902533285378, 0.07630465797864293, 0.01695659066192065, 0.03673927976749475, 0.04239147665480163, 0.01413049221826721, 0.3017293169134043, 0.1363142599253451, 0.35916510058981377, 0.10261860016851822, 0.05284092098229669, 0.04748024783916514, 0.14171868459023743, 0.033742543950056526, 0.5317824926528909, 0.20380496545834142, 0.05938687735209949, 0.029693438676049747, 0.8369251152782291, 0.9782026457720575, 0.9483602495313598, 0.8510399893159108, 0.9509884027087834, 0.9463380653336234, 0.5674665444535679, 0.20320420026851901, 0.029602587199611414, 0.018062595579423912, 0.0978390593885462, 0.08429211270397827, 0.6052740187735829, 0.30263700938679144, 0.10177620415056425, 0.814209633204514, 0.01139849450990943, 0.01302685086846792, 0.16934906129008295, 0.6953081651044752, 0.00977013815135094, 0.10258645058918488, 0.966085301944125, 0.3876014628305389, 0.14436810088351984, 0.1261669649555116, 0.1435407765231558, 0.09017835527967714, 0.10755216684732136, 0.00041366218018200525, 0.13415498556203495, 0.05199805641939339, 0.2007124977788585, 0.41806437361192283, 0.08735673478458089, 0.10711599622395039, 0.006083706355956397, 0.6874588182230729, 0.28289234555197246, 0.009125559533934596, 0.012167412711912793, 0.4314853729100435, 0.5080049464310364, 0.021255437089164705, 0.006376631126749411, 0.014878805962415293, 0.017004349671331763, 0.29903191306363625, 0.12582773854636822, 0.17167590238917446, 0.14620470025428212, 0.10545077683845434, 0.15180836472395842, 0.954384770966926, 0.4810598231246358, 0.17480868636144078, 0.09051938266514858, 0.0423889686704542, 0.13180892563521637, 0.07928080883897629, 0.00012215841115404666, 0.4277108565267325, 0.1271193186064673, 0.13648354097158458, 0.0824051568130322, 0.10019717930675506, 0.12594879081082763, 0.0002341055591279324, 0.09072574952544274, 0.9072574952544273, 0.01676888676337645, 0.3018399617407761, 0.0670755470535058, 0.5869110367181757, 0.9356286772826665, 0.06547779511094823, 0.9166891315532751, 0.005351538789772454, 0.01516269323768862, 0.46647579784183224, 0.43079887257668253, 0.032109232738634724, 0.04994769537120957, 0.16909376458786682, 0.0966250083359239, 0.024156252083980975, 0.6280625541835053, 0.07246875625194292, 0.8829455497630947, 0.954562038378265, 0.9613360901936951, 0.2158955279836046, 0.7556343479426161, 0.90585127685265, 0.08946553669766531, 0.8946553669766532, 0.9574105086619429, 0.19574744348356962, 0.7960396034998498, 0.881185629219427, 0.0629418306585305, 0.9483775423692675, 0.023709438559231688, 0.37102875893494286, 0.016131685171084473, 0.016131685171084473, 0.04839505551325341, 0.548477295816872, 0.02872618680733845, 0.7181546701834612, 0.1149047472293538, 0.1149047472293538, 0.310577990798117, 0.22026267322860318, 0.18444140803225595, 0.06287775273826908, 0.14976337470387727, 0.07164253039269447, 0.0003810772893228429, 0.9465946499257027, 0.032641194825024235, 0.9431291147266865, 0.9369176813900324, 0.03535538420339745, 0.04862635301463405, 0.13237173876205935, 0.11616295442384801, 0.037820496789159816, 0.3376830070460698, 0.3295786148769641, 0.8745013726745209, 0.25916162482438754, 0.10496045805387695, 0.11143949867448665, 0.13476404490868152, 0.28378197918270437, 0.1062562661779989, 0.8837113875028995, 0.02993791540086378, 0.017107380229065015, 0.7783858004224583, 0.0940905912598576, 0.06415267585899381, 0.017107380229065015, 0.8788984469573011, 0.17887152798364192, 0.19675868078200612, 0.03577430559672839, 0.5902760423460184, 0.8538432836882166, 0.104189210211955, 0.0025412002490720733, 0.0025412002490720733, 0.010164800996288293, 0.027953202739792807, 0.533278320285795, 0.16308091390125432, 0.07351702525983318, 0.04739422440608535, 0.08433932847067156, 0.098147094636224, 0.028949796622309155, 0.9553432885362022, 0.9563630145704586, 0.021735523058419515, 0.021735523058419515, 0.012798773773731205, 0.1322539956618891, 0.03839632132119361, 0.02133128962288534, 0.187715348681391, 0.6058086252899437, 0.07576115634157084, 0.8333727197572792, 0.6676018423223997, 0.3227964951888526, 0.8668319032419824, 0.11448723250365807, 0.8789738304321953, 0.2512987343159614, 0.7376833813791125, 0.9355991090901066, 0.003638703866367543, 0.0024258025775783618, 0.3250575453955005, 0.6586053998125253, 0.008490309021524266, 0.0024258025775783618, 0.3571530656885752, 0.10884664859080387, 0.09183935974849076, 0.023810204379238347, 0.10544519082234124, 0.31633557246702376, 0.4682229755853152, 0.3549925827967096, 0.01683154487398192, 0.01683154487398192, 0.10251940968698078, 0.0397836515203209, 0.8605283449518246, 0.8023068673758519, 0.061986973581834984, 0.9174072090111578, 0.23517094917489567, 0.07028097331663549, 0.16759309021659233, 0.16759309021659233, 0.07028097331663549, 0.28923323634153836, 0.2334251078505688, 0.059402088377743315, 0.17402301947282547, 0.43087430302165924, 0.058565439245662425, 0.04350575486820637, 0.16054228611885343, 0.8027114305942672, 0.8943606292987752, 0.29550988628833397, 0.16428346220775178, 0.08614864481626008, 0.03906740869574585, 0.21036296990016995, 0.20435259933159367, 0.1552650115698459, 0.4657950347095377, 0.1552650115698459, 0.46195738829784594, 0.21586793845693736, 0.06969450584466835, 0.0493412430758714, 0.09374836184415565, 0.10916750030536547, 0.3928720243948268, 0.196753356320511, 0.05204443618800614, 0.06791164234288606, 0.1783473971808503, 0.11233981957654983, 0.4778881080743887, 0.17031875280329775, 0.10951602476704742, 0.12409445663538814, 0.06080272803625035, 0.057247012946411144, 0.4319585784075965, 0.18615555948073043, 0.05964745944613568, 0.04744053751297303, 0.10736542700304422, 0.1672903164931154, 0.0002774300439355148, 0.10391599582206093, 0.14288449425533378, 0.11690549529981854, 0.025978998955515233, 0.5455589780658199, 0.06494749738878808, 0.0595875207540269, 0.8938128113104036, 0.26367400661096535, 0.23405583052589798, 0.12786383334285167, 0.05201240678353289, 0.20877202167279174, 0.1134159425696481, 0.09158516036769937, 0.015927853976991195, 0.2920106562448386, 0.5468563198766977, 0.01725517514174046, 0.03716499261297945, 0.016201372387089373, 0.019441646864507247, 0.5605674845932923, 0.1393318025289686, 0.2268192134192512, 0.04212356820643237, 0.11525163400497544, 0.8067614380348281, 0.2859307622361489, 0.07624820326297303, 0.019062050815743258, 0.6099856261037843, 0.9134772666372605, 0.07637579940302065, 0.032312838208970275, 0.575756026268925, 0.1410014758209612, 0.15862666029858136, 0.0117501229850801, 0.3863219017274257, 0.15097637538772957, 0.11479467322509286, 0.13272106202385378, 0.12005746626693092, 0.0950591993182001, 0.00032892456511487923, 0.051584279698122924, 0.051584279698122924, 0.8253484751699668, 0.1527726915698256, 0.8402498036340408, 0.19216073400977418, 0.04045489137047877, 0.17024766785076484, 0.10787971032127673, 0.05056861421309847, 0.4399469436539567, 0.0786045801622877, 0.1572091603245754, 0.7467435115417332, 0.2970835112227979, 0.11447766879825859, 0.2032676655734933, 0.1284383601151194, 0.15747659805418987, 0.09940012217604892, 0.10084456801250201, 0.8403714001041834, 0.9188340267227723, 0.11465132294911579, 0.8025592606438104, 0.2871085884711186, 0.23060930800893062, 0.0761010716429471, 0.07494802510290245, 0.09685590936375085, 0.23406844762906456, 0.644988754781198, 0.12957363377300854, 0.0322494377390599, 0.033689144780982214, 0.08667036392372349, 0.07284917632126924, 0.49466408907416026, 0.055228193432337515, 0.8008088047688939, 0.055228193432337515, 0.08284229014850628, 0.25663733138910105, 0.7402999943916376, 0.2416174116286181, 0.0910889922433768, 0.11810691367149703, 0.1404931914262252, 0.0910889922433768, 0.31726759162735474, 0.3009289000726705, 0.04298984286752435, 0.06878374858803896, 0.06448476430128652, 0.11177359145556331, 0.40840350724148133, 0.07307914628694, 0.38914645397795544, 0.04567446642933749, 0.031058637171949496, 0.310586371719495, 0.14981224988822697, 0.8569354812940861, 0.047541496881780096, 0.016639523908623034, 0.011885374220445024, 0.023770748440890048, 0.04397588461564659, 0.9230350824519067, 0.9459187190598636, 0.05817228436883004, 0.8725842655324506, 0.15236634816845293, 0.035370759396248, 0.3328479153441799, 0.26936193694065785, 0.17776073952986177, 0.03174298920176103, 0.855852336316765, 0.08486299537318134, 0.018055956462379008, 0.012639169523665306, 0.019861552108616908, 0.009027978231189504, 0.19815708449961042, 0.7678587024359903, 0.024769635562451302, 0.024769635562451302, 0.024769635562451302, 0.8971349567114902, 0.045839012386718475, 0.019645291022879346, 0.006548430340959782, 0.02619372136383913, 0.013096860681919564, 0.8105147330845297, 0.08105147330845297, 0.9269974985107682, 0.37762349769855746, 0.37762349769855746, 0.9227703621714023, 0.18933245570700766, 0.05522196624787724, 0.11833278481687978, 0.015777704642250638, 0.13411048945913043, 0.4812199915886445, 0.06481711656444326, 0.8426225153377623, 0.06481711656444326, 0.06191254388943884, 0.06191254388943884, 0.8048630705627049, 0.17293585858422492, 0.05508099410422822, 0.3194082227943513, 0.21909311621346642, 0.11816257953085829, 0.1150854290222422, 0.31226329031644195, 0.04637573618561019, 0.2877872073295921, 0.1427342102601558, 0.108725337057375, 0.10176897662953348, 0.0002576429788089455, 0.30247873548519444, 0.11207917430924615, 0.1660932342173166, 0.0900234331801174, 0.20615366198246882, 0.12288198629086024, 0.07634497897073483, 0.11328609782754201, 0.28025995506031043, 0.2073628138495443, 0.17534717750697806, 0.14727192717580462, 0.2550631757603728, 0.1206645023789456, 0.2913606276955028, 0.2305378703987985, 0.06180376951116726, 0.04054850486446952, 0.9064557501058527, 0.10549555017070499, 0.8439644013656399, 0.0037848745747370094, 0.6623530505789766, 0.32928408800211983, 0.0037848745747370094, 0.9328587116125868, 0.3787148953733001, 0.26976951451248776, 0.085599942104924, 0.06657773274827422, 0.0907878173840103, 0.10808073498096464, 0.864404843891579, 0.04490414773462748, 0.0014032546167071088, 0.004209763850121327, 0.016839055400485307, 0.06595296698523412, 0.33263431095137586, 0.33263431095137586, 0.3920195582590812, 0.33067664449726897, 0.07955409128485022, 0.06325987981686886, 0.06325987981686886, 0.06996926100956706, 0.5111025237011602, 0.2503886100960229, 0.012906629386392933, 0.024952816813693005, 0.040440772077364524, 0.15918176243217952, 0.3337157996162427, 0.12045363181414677, 0.15040248562586087, 0.19121191279786687, 0.08359350404588328, 0.12012452353050156, 0.00032910828364520974, 0.8945412565780658, 0.49350818733825297, 0.2379132381195848, 0.7434788691237025, 0.05098134875301082, 0.8921736031776895, 0.02549067437650541, 0.8686385044315956, 0.9086068441284516, 0.053447461419320684, 0.8926904890286043, 0.9403827512994821, 0.03482899078886971, 0.9673930637279812, 0.8665562895318946, 0.04215679246371379, 0.014052264154571262, 0.028104528309142524, 0.02342044025761877, 0.02342044025761877, 0.9564359489818322, 0.08538888131003265, 0.01601041524563112, 0.13342012704692602, 0.7364791012990316, 0.010673610163754082, 0.021347220327508163, 0.020026589005194717, 0.13017282853376566, 0.22029247905714192, 0.16021271204155774, 0.19025259554934984, 0.28037224607272604, 0.010013294502597359, 0.5484385423765813, 0.1154337437181766, 0.07746886800642075, 0.07592975142351173, 0.095938267001329, 0.08670356750387487, 0.33295167185933255, 0.5866291361331097, 0.015854841517111074, 0.02378226227566661, 0.02378226227566661, 0.015854841517111074, 0.3818097439376346, 0.1272699146458782, 0.1272699146458782, 0.3818097439376346, 0.10115118211794671, 0.8766435783555382, 0.9428429763808105, 0.3693349878446191, 0.055992476291312515, 0.24873580814025367, 0.145365082679369, 0.10175555787555832, 0.07860482248588103, 0.2478963225387195, 0.5725224591965664, 0.03541376036267421, 0.05312064054401132, 0.07082752072534843, 0.017706880181337106, 0.3073049761702174, 0.0942186920941671, 0.200646652357016, 0.21562028312992765, 0.09398832854381461, 0.08776851268429747, 0.20490923646375833, 0.5024486757125033, 0.047718589313477965, 0.015438367130831108, 0.15438367130831107, 0.07578834773317089, 0.005094871841077266, 0.01783205144377043, 0.6190269286908878, 0.32097692598786776, 0.03311666696700223, 0.005094871841077266, 0.05643170573792474, 0.2718982185554556, 0.030780930402504406, 0.051301550670840676, 0.1898157374821105, 0.4001520952325573, 0.8883419319318652, 0.8714928065695037, 0.09683253406327819, 0.03227751135442607, 0.9237498840544484, 0.022808639112455516, 0.03421295866868327, 0.34848814656797206, 0.10573518271092867, 0.22022949298370945, 0.05568302521463108, 0.20271123786000528, 0.06757041262000175, 0.09156811162451568, 0.7783289488083833, 0.09156811162451568, 0.8392875164178365, 0.031008159473565385, 0.01860489568413923, 0.020672106315710256, 0.03720979136827846, 0.05168026578927564, 0.24207658828080839, 0.17052685775446108, 0.11805705536847305, 0.10255461375443113, 0.15502441614041915, 0.212264200561497, 0.20807574519838654, 0.5475677505220699, 0.03285406503132419, 0.0036504516701471325, 0.10586309843426683, 0.09856219509397257, 0.04369944385897145, 0.7428905456025146, 0.06554916578845717, 0.021849721929485724, 0.07647402675320003, 0.054624304823714304, 0.904789888821588, 0.5515912753237934, 0.08299806023680903, 0.09026039050752982, 0.056715341161819505, 0.11204738131969219, 0.10651417730390492, 0.9181684997594924, 0.5579666834158855, 0.14861553604131814, 0.04326781429051034, 0.01956457689657859, 0.13920948945642458, 0.09142677280516533, 0.0003762418633957421, 0.873932174399658, 0.8723716776946829, 0.26692963715272566, 0.09443265465308691, 0.25811592271843753, 0.0642142051640991, 0.2870752701453842, 0.027700245364905493, 0.9524143497147287, 0.017046410573134496, 0.06294059288541967, 0.3619084090911632, 0.16128526926888792, 0.31863675148243714, 0.0786757411067746, 0.17649813552810112, 0.42701161821314787, 0.08730015305691023, 0.10248278837115549, 0.13474588841392668, 0.07211751774266498, 0.2014426018986814, 0.12462127066613342, 0.1843711949581152, 0.13657125552452978, 0.32094245048264497, 0.030728532493019198, 0.0007987097678324464, 0.0031948390713297855, 0.6645265268365954, 0.16613163170914885, 0.1605406633343217, 0.004792258606994678, 0.5852648692309371, 0.14937722603802162, 0.01836605238172397, 0.00979522793691945, 0.08815705143227505, 0.14815282254590667, 0.28650178739955257, 0.17157112796287985, 0.18971807418972292, 0.07478741475305019, 0.17212103542429935, 0.10558223259254144, 0.5757335604210392, 0.11273104679572794, 0.04707450305755673, 0.0312797684790344, 0.13595859764649607, 0.09693631221720563, 0.00030970067801024164, 0.03662289302444264, 0.03662289302444264, 0.10986867907332791, 0.7690807535132954, 0.2675628705098358, 0.2285974039307335, 0.04675855989492276, 0.025976977719401533, 0.1220917952811872, 0.30912603486087825, 0.031600388967163995, 0.07900097241790997, 0.047400583450745985, 0.015800194483581997, 0.7426091407283538, 0.07900097241790997, 0.8757021757301511, 0.0761480152808827, 0.03807400764044135, 0.08241708961891445, 0.04120854480945722, 0.8241708961891445, 0.9356369002634207, 0.6625114582246389, 0.13775888050635446, 0.04350280437042772, 0.03172079485343688, 0.059816356009338115, 0.06525420655564158, 0.29069217250043183, 0.3334005011616327, 0.11021504170632487, 0.01790994427727779, 0.18461019485809416, 0.0633736489811368, 0.06136612662717254, 0.8898088360940019, 0.9472062361268496, 0.02514706821575707, 0.008382356071919023, 0.016764712143838047, 0.008382356071919023, 0.808627607600235, 0.04620729186287057, 0.11551822965717642, 0.05329434424913192, 0.8527095079861107, 0.05329434424913192, 0.07969899857244647, 0.21917224607422778, 0.677441487865795, 0.27716508878390317, 0.14904160434606115, 0.10720536452962293, 0.07321341967876688, 0.3660670983938344, 0.026147649885273884, 0.8851352062782067, 0.4869354122965098, 0.3063289618641215, 0.06190397771004122, 0.02425104281424295, 0.06956220175664425, 0.0516930123145705, 0.8180760432500613, 0.11686800617858019, 0.11347587323699419, 0.8624166366011559, 0.4150837199038903, 0.23900685862766122, 0.06928656274046562, 0.031782826945167715, 0.130945247014091, 0.11441817700260377, 0.8522734550382701, 0.4337242483550501, 0.0886961653077812, 0.1330442479616718, 0.17384448400325117, 0.06386123902160247, 0.10687887919587635, 0.06892083734990634, 0.06892083734990634, 0.06892083734990634, 0.7581292108489698, 0.7211614678395627, 0.21541186701701223, 0.04682866674282875, 0.8844481511027079, 0.9192323742325689, 0.11340944526175395, 0.8316692652528623, 0.03780314842058465, 0.1447746628196745, 0.7721315350382639, 0.048258220939891495, 0.033362680077442544, 0.8674296820135061, 0.06672536015488509, 0.23866019503405603, 0.1159754361410473, 0.1447296765065962, 0.370929700715581, 0.03258813908095544, 0.09680594256401469, 0.07078880462739597, 0.16222434393778243, 0.23743744885439064, 0.41145992689673905, 0.03981870260291023, 0.07816263844274972, 0.9037491737754474, 0.8821404019377349, 0.49475169996442636, 0.3682250357112288, 0.023520982457325187, 0.021898845736130348, 0.04298662311166328, 0.04866410163584522, 0.21341977844562474, 0.03962223734855481, 0.43584461083410286, 0.19901169213705935, 0.09275205561138966, 0.019811118674277404, 0.37544738707181335, 0.2321785068517717, 0.08338156694478309, 0.04284246257383882, 0.15754970107798794, 0.10825783553604434, 0.11873873478653575, 0.7915915652435718, 0.03957957826217859, 0.9436095507317089, 0.9207307777940799, 0.030248917387938206, 0.09074675216381461, 0.09074675216381461, 0.7562229346984551, 0.1851000338789959, 0.7404001355159836, 0.04544927449050465, 0.908985489810093, 0.27116610601395996, 0.2700547695139027, 0.0866842470044626, 0.0777935550040049, 0.09224092950474867, 0.20115190651035553, 0.08215864504759429, 0.041079322523797146, 0.7531209129362809, 0.08215864504759429, 0.041079322523797146, 0.428596013381724, 0.5442906427608396, 0.0026294233949799017, 0.007888270184939705, 0.007888270184939705, 0.007888270184939705, 0.9225597829245726, 0.9219385450776699, 0.04758392490723458, 0.005947990613404322, 0.011895981226808645, 0.005947990613404322, 0.1821160246095278, 0.0910580123047639, 0.1821160246095278, 0.3642320492190556, 0.055069486881191114, 0.8811117900990578, 0.9460676772806841, 0.8546007627191473, 0.10682509533989341, 0.0033720090258282593, 0.9036984189219736, 0.08767223467153475, 0.0033720090258282593, 0.0033720090258282593, 0.7709924586013586, 0.20492167978615056, 0.004057855045270308, 0.002028927522635154, 0.004057855045270308, 0.01420249265844608, 0.9337833151047483, 0.041633650991931455, 0.005947664427418779, 0.005947664427418779, 0.011895328854837559, 0.004799920364912515, 0.6671889307228397, 0.31199482371931353, 0.004799920364912515, 0.014399761094737546, 0.04545361359563684, 0.18181445438254737, 0.7272578175301895, 0.02023703420205707, 0.08094813680822828, 0.02023703420205707, 0.870192470688454, 0.6050959926066347, 0.15088310926754586, 0.07672590382442931, 0.04478469786549659, 0.05852165007860402, 0.06377072937954752, 0.00022336507663589322, 0.9140488364365462, 0.22936351136058486, 0.44257466276619895, 0.02261330393695907, 0.009691415972982459, 0.10014463172081875, 0.2002892634416375, 0.8944882872917577, 0.06116159229345351, 0.007645199036681689, 0.03822599518340845, 0.018455561253636756, 0.055366683760910265, 0.7751335726527437, 0.1291889287754573, 0.018455561253636756, 0.009227780626818378, 0.2023597640638289, 0.08094390562553157, 0.46726709156556856, 0.12877439531334567, 0.09198171093810405, 0.031273781718955375, 0.4198731300867539, 0.4198731300867539, 0.7056786066641797, 0.15459189272628682, 0.00975829223189186, 0.01283985819985771, 0.05341381011140807, 0.06368569667129424, 0.13225912911247587, 0.7935547746748551, 0.35368190578101266, 0.17684095289050633, 0.17684095289050633, 0.17684095289050633, 0.1470853428439694, 0.6284555557878693, 0.05348557921598887, 0.0802283688239833, 0.09359976362798053, 0.9654644809261793, 0.37921226913134415, 0.12357546672392054, 0.17502104729138962, 0.07796392106616447, 0.15804930937222456, 0.08538905640579918, 0.3451476720338467, 0.1378822966383613, 0.17014321860823428, 0.15290793152843912, 0.07866361795393689, 0.11445998342735761, 0.8511553480602384, 0.27544592225353454, 0.35902951245460707, 0.013297389350170634, 0.013297389350170634, 0.18806307795241323, 0.1500705369519257, 0.13552547589747088, 0.04134675535855044, 0.31699179108222003, 0.30091249733167263, 0.13935387917141073, 0.06508285565697754, 0.02092775691353528, 0.0767351086829627, 0.21625348810653122, 0.6627123022619505, 0.006975918971178427, 0.013951837942356854, 0.04748917962374662, 0.9497835924749325, 0.8982044713480626, 0.03149937672568336, 0.017999643843247634, 0.1529969726676049, 0.7244856646907173, 0.022499554804059546, 0.049499020568931, 0.07040773120461702, 0.8448927744554042, 0.7631266458158014, 0.1368044108962473, 0.013959633764923195, 0.005583853505969278, 0.020474129521887353, 0.06049174631466718, 0.9386282289120061, 0.870190048887154, 0.028885976726544534, 0.014442988363272267, 0.0433289650898168, 0.007221494181636133, 0.036107470908180665, 0.7182234257845386, 0.0889006194782165, 0.09708883443015749, 0.06901495459493122, 0.008188214951940992, 0.01871591989015084, 0.20632417221421417, 0.7672680154216089, 0.012895260763388386, 0.006447630381694193, 0.15380799646738552, 0.8349576951086641, 0.917922137325059, 0.9425950209264591, 0.035741816668445434, 0.9292872333795812, 0.1042069099842322, 0.8336552798738576, 0.3901302904248562, 0.129848462480237, 0.13365033187718087, 0.1555841937826263, 0.10294292520955725, 0.08773544762178175, 0.0002924514920726058, 0.0019409271202130967, 0.00582278136063929, 0.47552714445220867, 0.48523178005327416, 0.021350198322344062, 0.01164556272127858, 0.13870135274469553, 0.6081520851113573, 0.06401600895909024, 0.0533466741325752, 0.1066933482651504, 0.02133866965303008, 0.0018333713858957271, 0.0018333713858957271, 0.32450673530354374, 0.6691805558519405, 0.0018333713858957271, 0.0018333713858957271, 0.15411741856839498, 0.4361195036084368, 0.10657055539303907, 0.05902369221768318, 0.20822246976793787, 0.03607003413302861, 0.716076069977864, 0.15987597332055717, 0.010097429893929926, 0.010938882385090753, 0.0740478192221528, 0.028609384699468127, 0.6643637810680385, 0.19308469354176264, 0.03874396811199842, 0.017148969492196024, 0.047636026367211176, 0.03874396811199842, 0.8792467732652787, 0.06584667464982263, 0.003873333802930743, 0.007746667605861486, 0.04260667183223817, 0.06742619251481367, 0.8765405026925778, 0.8747373880414446, 0.009487881383425252, 0.056927288300551514, 0.11385457660110303, 0.03795152553370101, 0.3131000856530333, 0.4649061877878373, 0.9375499057784533, 0.5610234840154883, 0.200722263886847, 0.08537830892817308, 0.041143307645052765, 0.052558791847148324, 0.05898000171082708, 0.00023782258754365758, 0.8856312283469865, 0.4876145239974366, 0.9439088966901503, 0.5494063275842608, 0.20755883997936217, 0.02017933166466021, 0.01513449874849516, 0.09849435693465104, 0.10882425290584614, 0.00024023013886500253, 0.03643952033770558, 0.8198892075983757, 0.12753832118196953, 0.24422469971334473, 0.056213461209292416, 0.32512650537266424, 0.26245609253798013, 0.05203543368698014, 0.05963184736391155, 0.9675211561567855, 0.13170960582011582, 0.7902576349206949, 0.9069056666990251, 0.045590938287640125, 0.05470912594516815, 0.1823637531505605, 0.16412737783550446, 0.5425321656229175, 0.013677281486292037, 0.9465756821948169, 0.8376338450312993, 0.153369577259252, 0.8943891664200112, 0.9480869206361362, 0.9216533301305236, 0.8110610056364057, 0.059129328331442375, 0.11352831039636936, 0.17029246559455405, 0.16083177306152327, 0.357141143121912, 0.13718004172894632, 0.8893733903224214, 0.957752824332104, 0.31122493724188277, 0.020934412818960725, 0.18282720528559032, 0.4284576490280628, 0.04186882563792145, 0.015351902733904532, 0.43900374225038513, 0.07782798500371371, 0.10747674119560466, 0.14015775654348445, 0.15969898221541257, 0.07580647889972116, 0.2093340436807859, 0.07850026638029471, 0.6803356419625541, 0.3461853999987581, 0.10927569444405243, 0.17833793333269354, 0.14992625277723992, 0.10883859166627621, 0.10752728333294759, 0.0035358756652380074, 0.31469293420618266, 0.6788881277256974, 0.0035358756652380074, 0.9781782138239827, 0.009057205683555395, 0.009057205683555395, 0.4192072788966199, 0.059262416979759376, 0.016932119137074108, 0.18625331050781518, 0.6942168846200384, 0.016932119137074108, 0.033864238274148216, 0.5316425298182333, 0.13332728020519957, 0.08944038380432139, 0.08555167146500306, 0.08388508046243807, 0.07610765578380142, 0.08689209030503245, 0.9036777391723375, 0.13950577197002387, 0.1046293289775179, 0.1743822149625298, 0.5928995308726014, 0.10864175376905193, 0.1748954134446049, 0.18415667770032737, 0.2878115968701441, 0.11434099331103498, 0.12965769958011442, 0.0003562024713739407, 0.05510271720950632, 0.8816434753521011, 0.10858146444141556, 0.06514887866484934, 0.40617510772529525, 0.25576967179533444, 0.11501592159349945, 0.049464889356644864, 0.14685752192673052, 0.048952507308910174, 0.7832401169425628, 0.07898927109580162, 0.8688819820538177, 0.8668243446349783, 0.28595965336324997, 0.19911822178925245, 0.20152630308073247, 0.16585659895068497, 0.10354749553363998, 0.04394748356950999, 0.00015050508071749998, 0.8912060549621996, 0.08694421852107316, 0.8911782398409999, 0.4295520294508993], \"Term\": [\"abrogation\", \"abrogation\", \"accident\", \"accident\", \"accident\", \"accident\", \"accident\", \"accident\", \"achieve\", \"achieve\", \"achieve\", \"achieve\", \"achieve\", \"achieve\", \"acreage\", \"act\", \"act\", \"act\", \"act\", \"act\", \"act\", \"activity\", \"activity\", \"activity\", \"activity\", \"activity\", \"activity\", \"adventurer\", \"agricultural\", \"agricultural\", \"agricultural\", \"agricultural\", \"agricultural\", \"agricultural\", \"agriculture\", \"agriculture\", \"agriculture\", \"agriculture\", \"agriculture\", \"agriculture\", \"allotment\", \"allotment\", \"allotment\", \"allottees\", \"america\", \"america\", \"america\", \"america\", \"america\", \"america\", \"american\", \"american\", \"american\", \"american\", \"american\", \"american\", \"americorps\", \"amicably\", \"amount\", \"amount\", \"amount\", \"amount\", \"amount\", \"amount\", \"anarchist\", \"anarchist\", \"apia\", \"apia\", \"appeal\", \"appeal\", \"appeal\", \"appeal\", \"appeal\", \"appeal\", \"apprehend\", \"apprehend\", \"approbation\", \"approbation\", \"arapahoe\", \"arbitration\", \"arbitration\", \"arbitration\", \"arbitration\", \"arbitration\", \"area\", \"area\", \"area\", \"area\", \"area\", \"area\", \"arent\", \"arent\", \"armenian\", \"armor\", \"armor\", \"armor\", \"armor\", \"armor\", \"armor\", \"article\", \"article\", \"article\", \"article\", \"article\", \"article\", \"ask\", \"ask\", \"ask\", \"ask\", \"ask\", \"ask\", \"atom\", \"atomic\", \"atomic\", \"atomic\", \"atua\", \"augmentation\", \"authorization\", \"authorization\", \"authorization\", \"authorization\", \"authorization\", \"automaker\", \"aviation\", \"aviation\", \"axiomatic\", \"back\", \"back\", \"back\", \"back\", \"back\", \"back\", \"baghdad\", \"ballistic\", \"ballistic\", \"barbary\", \"basic\", \"basic\", \"basic\", \"basic\", \"battleship\", \"battleship\", \"battleship\", \"bent\", \"bering\", \"bering\", \"bering\", \"bet\", \"bet\", \"bicentennial\", \"biden\", \"bilateral\", \"bill\", \"bill\", \"bill\", \"bill\", \"bill\", \"bill\", \"bill\", \"billion\", \"billion\", \"billion\", \"billion\", \"billion\", \"billion\", \"bird\", \"bituminous\", \"blockade\", \"blockade\", \"blockade\", \"bluefields\", \"bond\", \"bond\", \"bond\", \"bond\", \"bond\", \"bond\", \"bosnia\", \"british\", \"british\", \"british\", \"british\", \"british\", \"british\", \"budget\", \"budget\", \"budget\", \"budget\", \"budget\", \"budget\", \"bullion\", \"bullion\", \"bullion\", \"bullion\", \"bureau\", \"bureau\", \"bureau\", \"bureau\", \"bureau\", \"bureau\", \"burthen\", \"business\", \"business\", \"business\", \"business\", \"business\", \"business\", \"canal\", \"canal\", \"canal\", \"canal\", \"canal\", \"canal\", \"canal\", \"cant\", \"cant\", \"capability\", \"capability\", \"capability\", \"capability\", \"case\", \"case\", \"case\", \"case\", \"case\", \"case\", \"cattle\", \"cattle\", \"cattle\", \"cattle\", \"cattle\", \"cent\", \"cent\", \"cent\", \"cent\", \"cent\", \"cent\", \"century\", \"century\", \"century\", \"century\", \"century\", \"century\", \"challenge\", \"challenge\", \"challenge\", \"challenge\", \"challenge\", \"challenge\", \"cheney\", \"cheyenne\", \"cheyenne\", \"child\", \"child\", \"child\", \"child\", \"child\", \"child\", \"chilean\", \"chilean\", \"chilean\", \"citizen\", \"citizen\", \"citizen\", \"citizen\", \"citizen\", \"citizen\", \"claim\", \"claim\", \"claim\", \"claim\", \"claim\", \"claim\", \"clarification\", \"clean\", \"clean\", \"clean\", \"clean\", \"clean\", \"college\", \"college\", \"college\", \"college\", \"college\", \"college\", \"colombian\", \"colombian\", \"colony\", \"colony\", \"colony\", \"colony\", \"colony\", \"columbian\", \"combination\", \"combination\", \"combination\", \"combination\", \"combination\", \"combination\", \"commence\", \"commence\", \"commence\", \"commence\", \"commencement\", \"commencement\", \"commencement\", \"commission\", \"commission\", \"commission\", \"commission\", \"commission\", \"commission\", \"commitment\", \"commitment\", \"commitment\", \"commitment\", \"committee\", \"committee\", \"committee\", \"committee\", \"committee\", \"committee\", \"communicate\", \"communicate\", \"communicate\", \"communicate\", \"communicate\", \"communicate\", \"communist\", \"communist\", \"communist\", \"communists\", \"compassion\", \"compassion\", \"compassion\", \"compassion\", \"concept\", \"concept\", \"condition\", \"condition\", \"condition\", \"condition\", \"condition\", \"condition\", \"confederacy\", \"confrontation\", \"confrontation\", \"congress\", \"congress\", \"congress\", \"congress\", \"congress\", \"congress\", \"congress\", \"consolidation\", \"consolidation\", \"consolidation\", \"consolidation\", \"consolidation\", \"consolidation\", \"constitution\", \"constitution\", \"constitution\", \"constitution\", \"constitution\", \"constitution\", \"consular\", \"consular\", \"consular\", \"consular\", \"consular\", \"consular\", \"continue\", \"continue\", \"continue\", \"continue\", \"continue\", \"continue\", \"coolie\", \"cooperative\", \"cooperative\", \"cooperative\", \"cooperative\", \"cooperative\", \"cooperative\", \"corporation\", \"corporation\", \"corporation\", \"corporation\", \"corporation\", \"corporation\", \"couldnt\", \"country\", \"country\", \"country\", \"country\", \"country\", \"country\", \"country\", \"court\", \"court\", \"court\", \"court\", \"court\", \"court\", \"court\", \"creative\", \"creative\", \"cultural\", \"cultural\", \"cut\", \"cut\", \"cut\", \"cut\", \"cut\", \"cut\", \"deem\", \"deem\", \"deem\", \"deem\", \"deem\", \"deem\", \"defendant\", \"defendant\", \"defendant\", \"defense\", \"defense\", \"defense\", \"defense\", \"defense\", \"defense\", \"deflation\", \"deforestation\", \"demagogue\", \"demobilization\", \"democrat\", \"democrat\", \"democrat\", \"department\", \"department\", \"department\", \"department\", \"department\", \"department\", \"department\", \"depression\", \"depression\", \"depression\", \"depression\", \"depression\", \"depression\", \"deregulation\", \"dialogue\", \"dike\", \"district\", \"district\", \"district\", \"district\", \"district\", \"district\", \"district\", \"do\", \"do\", \"do\", \"do\", \"do\", \"do\", \"doesnt\", \"doesnt\", \"dollar\", \"dollar\", \"dollar\", \"dollar\", \"dollar\", \"dollar\", \"dont\", \"dont\", \"dutiable\", \"dutiable\", \"dutiable\", \"duty\", \"duty\", \"duty\", \"duty\", \"duty\", \"duty\", \"earner\", \"earner\", \"earner\", \"earner\", \"economic\", \"economic\", \"economic\", \"economic\", \"economic\", \"economic\", \"effect\", \"effect\", \"effect\", \"effect\", \"effect\", \"effect\", \"effort\", \"effort\", \"effort\", \"effort\", \"effort\", \"effort\", \"electrification\", \"electrification\", \"emigrant\", \"emigrate\", \"emplacement\", \"employe\", \"employer\", \"employer\", \"employer\", \"employer\", \"employer\", \"employer\", \"employes\", \"employment\", \"employment\", \"employment\", \"employment\", \"employment\", \"employment\", \"empowerment\", \"energy\", \"energy\", \"energy\", \"energy\", \"energy\", \"energy\", \"entertain\", \"entertain\", \"entertain\", \"entertain\", \"envelope\", \"envelope\", \"envelope\", \"environmentally\", \"ere\", \"evaluation\", \"every\", \"every\", \"every\", \"every\", \"every\", \"every\", \"exertion\", \"exertion\", \"exertion\", \"exertion\", \"expenditure\", \"expenditure\", \"expenditure\", \"expenditure\", \"expenditure\", \"expenditure\", \"export\", \"export\", \"export\", \"export\", \"export\", \"export\", \"extraditable\", \"family\", \"family\", \"family\", \"family\", \"family\", \"family\", \"far\", \"far\", \"far\", \"far\", \"far\", \"far\", \"farm\", \"farm\", \"farm\", \"farm\", \"farm\", \"farm\", \"farmer\", \"farmer\", \"farmer\", \"farmer\", \"farmer\", \"farmer\", \"fashion\", \"fashion\", \"fashion\", \"fashion\", \"fashion\", \"fashion\", \"federal\", \"federal\", \"federal\", \"federal\", \"federal\", \"federal\", \"fertilizer\", \"fertilizer\", \"fighter\", \"fighter\", \"finely\", \"fiscal\", \"fiscal\", \"fiscal\", \"fiscal\", \"fiscal\", \"fiscal\", \"flood\", \"flood\", \"flood\", \"flood\", \"flood\", \"flood\", \"folk\", \"folk\", \"folk\", \"foolish\", \"foolish\", \"foolish\", \"foolish\", \"foolish\", \"forest\", \"forest\", \"forest\", \"forest\", \"forest\", \"forest\", \"france\", \"france\", \"france\", \"france\", \"france\", \"france\", \"free\", \"free\", \"free\", \"free\", \"free\", \"free\", \"freedom\", \"freedom\", \"freedom\", \"freedom\", \"freedom\", \"freedom\", \"freshman\", \"frigate\", \"functionary\", \"furlough\", \"fy\", \"gay\", \"general\", \"general\", \"general\", \"general\", \"general\", \"general\", \"geodetic\", \"geodetic\", \"gerrymander\", \"gerrymander\", \"get\", \"get\", \"get\", \"get\", \"get\", \"get\", \"ghent\", \"give\", \"give\", \"give\", \"give\", \"give\", \"give\", \"give\", \"go\", \"go\", \"go\", \"go\", \"go\", \"go\", \"goal\", \"goal\", \"goal\", \"goal\", \"goal\", \"gold\", \"gold\", \"gold\", \"gold\", \"gold\", \"gold\", \"good\", \"good\", \"good\", \"good\", \"good\", \"good\", \"gore\", \"government\", \"government\", \"government\", \"government\", \"government\", \"government\", \"government\", \"great\", \"great\", \"great\", \"great\", \"great\", \"great\", \"great\", \"guiana\", \"guiana\", \"hague\", \"hague\", \"hague\", \"hague\", \"hat\", \"havent\", \"havent\", \"help\", \"help\", \"help\", \"help\", \"help\", \"help\", \"helpful\", \"helpful\", \"helpful\", \"helpful\", \"helpful\", \"herbert\", \"hillary\", \"hitler\", \"hon\", \"hon\", \"hospitalization\", \"id\", \"id\", \"ideological\", \"im\", \"im\", \"implementation\", \"implementation\", \"impost\", \"impost\", \"improper\", \"improper\", \"improper\", \"improper\", \"improper\", \"inch\", \"inch\", \"inch\", \"inch\", \"increase\", \"increase\", \"increase\", \"increase\", \"increase\", \"increase\", \"increase\", \"incursion\", \"incursion\", \"indebted\", \"indulge\", \"indulge\", \"industrial\", \"industrial\", \"industrial\", \"industrial\", \"industrial\", \"industrial\", \"industrialism\", \"industry\", \"industry\", \"industry\", \"industry\", \"industry\", \"industry\", \"inescapable\", \"inflation\", \"inflation\", \"inflation\", \"inflation\", \"inflation\", \"inflation\", \"initiatives\", \"injunction\", \"injunction\", \"injunction\", \"injunction\", \"intercourse\", \"intercourse\", \"intercourse\", \"intercourse\", \"intercourse\", \"intercourse\", \"interest\", \"interest\", \"interest\", \"interest\", \"interest\", \"interest\", \"internet\", \"internet\", \"interposition\", \"interposition\", \"interposition\", \"interstate\", \"interstate\", \"interstate\", \"interstate\", \"interstate\", \"interstate\", \"intimacy\", \"intimacy\", \"iraq\", \"iraq\", \"iraqi\", \"iraqi\", \"iraqis\", \"ive\", \"ive\", \"jack\", \"job\", \"job\", \"job\", \"job\", \"job\", \"job\", \"judge\", \"judge\", \"judge\", \"judge\", \"judge\", \"judge\", \"june\", \"june\", \"june\", \"june\", \"june\", \"june\", \"kayla\", \"kellogg\", \"kid\", \"kid\", \"kind\", \"kind\", \"kind\", \"kind\", \"kind\", \"kind\", \"know\", \"know\", \"know\", \"know\", \"know\", \"know\", \"kongo\", \"kongo\", \"kremlin\", \"labor\", \"labor\", \"labor\", \"labor\", \"labor\", \"labor\", \"lade\", \"lade\", \"lade\", \"land\", \"land\", \"land\", \"land\", \"land\", \"land\", \"large\", \"large\", \"large\", \"large\", \"large\", \"large\", \"last\", \"last\", \"last\", \"last\", \"last\", \"last\", \"law\", \"law\", \"law\", \"law\", \"law\", \"law\", \"law\", \"lease\", \"lease\", \"lease\", \"lease\", \"lease\", \"lease\", \"lebanon\", \"lebanon\", \"legislation\", \"legislation\", \"legislation\", \"legislation\", \"legislation\", \"legislation\", \"let\", \"let\", \"let\", \"let\", \"let\", \"let\", \"level\", \"level\", \"level\", \"level\", \"level\", \"level\", \"liberian\", \"liberian\", \"liquidation\", \"liquidation\", \"liquidation\", \"liquidation\", \"litigant\", \"major\", \"major\", \"major\", \"major\", \"major\", \"major\", \"make\", \"make\", \"make\", \"make\", \"make\", \"make\", \"make\", \"maker\", \"maker\", \"maker\", \"malietoa\", \"malietoa\", \"man\", \"man\", \"man\", \"man\", \"man\", \"man\", \"maneuver\", \"maneuver\", \"maneuver\", \"many\", \"many\", \"many\", \"many\", \"many\", \"many\", \"marketing\", \"marketing\", \"marksmanship\", \"mataafa\", \"mataafa\", \"matter\", \"matter\", \"matter\", \"matter\", \"matter\", \"matter\", \"may\", \"may\", \"may\", \"may\", \"may\", \"may\", \"measurement\", \"meat\", \"meat\", \"meat\", \"meat\", \"medicare\", \"medicare\", \"men\", \"men\", \"men\", \"men\", \"men\", \"men\", \"merely\", \"merely\", \"merely\", \"merely\", \"merely\", \"merely\", \"method\", \"method\", \"method\", \"method\", \"method\", \"method\", \"mexico\", \"mexico\", \"mexico\", \"mexico\", \"mexico\", \"mexico\", \"miantonomoh\", \"michelle\", \"millennium\", \"millennium\", \"million\", \"million\", \"million\", \"million\", \"million\", \"million\", \"minister\", \"minister\", \"minister\", \"minister\", \"minister\", \"minister\", \"missionary\", \"missionary\", \"missionary\", \"missionary\", \"missionary\", \"mode\", \"mode\", \"mode\", \"mode\", \"mode\", \"mode\", \"monopolistic\", \"monopolistic\", \"monrovia\", \"montenegro\", \"montenegro\", \"mora\", \"moreover\", \"moreover\", \"moreover\", \"moreover\", \"moreover\", \"moreover\", \"mortar\", \"mortar\", \"mortar\", \"muscle\", \"muscle\", \"muscle\", \"must\", \"must\", \"must\", \"must\", \"must\", \"must\", \"nation\", \"nation\", \"nation\", \"nation\", \"nation\", \"nation\", \"nation\", \"national\", \"national\", \"national\", \"national\", \"national\", \"national\", \"need\", \"need\", \"need\", \"need\", \"need\", \"need\", \"new\", \"new\", \"new\", \"new\", \"new\", \"new\", \"nitrate\", \"nitrogen\", \"nitrogen\", \"nuclear\", \"nuclear\", \"nuclear\", \"nuclear\", \"nueces\", \"number\", \"number\", \"number\", \"number\", \"number\", \"number\", \"object\", \"object\", \"object\", \"object\", \"object\", \"object\", \"offered\", \"offered\", \"office\", \"office\", \"office\", \"office\", \"office\", \"office\", \"officer\", \"officer\", \"officer\", \"officer\", \"officer\", \"officer\", \"one\", \"one\", \"one\", \"one\", \"one\", \"one\", \"one\", \"operational\", \"ottawa\", \"ottoman\", \"ottoman\", \"ounce\", \"ounce\", \"ounce\", \"outsider\", \"overall\", \"overall\", \"overcapitalization\", \"overture\", \"overture\", \"pandemic\", \"paper\", \"paper\", \"paper\", \"paper\", \"paper\", \"paper\", \"paredes\", \"parent\", \"parent\", \"parent\", \"parent\", \"parent\", \"parent\", \"park\", \"park\", \"park\", \"park\", \"park\", \"park\", \"park\", \"part\", \"part\", \"part\", \"part\", \"part\", \"part\", \"patent\", \"patent\", \"patent\", \"patent\", \"patent\", \"patent\", \"paul\", \"paul\", \"paul\", \"paul\", \"paycheck\", \"paycheck\", \"pd\", \"peace\", \"peace\", \"peace\", \"peace\", \"peace\", \"peace\", \"pension\", \"pension\", \"pension\", \"pension\", \"pension\", \"pension\", \"people\", \"people\", \"people\", \"people\", \"people\", \"people\", \"per\", \"per\", \"per\", \"per\", \"per\", \"per\", \"percent\", \"percent\", \"percent\", \"percent\", \"percent\", \"percent\", \"philippine\", \"philippine\", \"philippine\", \"philippine\", \"philippine\", \"philippine\", \"photograph\", \"planning\", \"planning\", \"planning\", \"plenipotentiary\", \"plenipotentiary\", \"plenipotentiary\", \"policy\", \"policy\", \"policy\", \"policy\", \"policy\", \"policy\", \"pork\", \"pork\", \"pork\", \"portion\", \"portion\", \"portion\", \"portion\", \"portion\", \"portion\", \"possible\", \"possible\", \"possible\", \"possible\", \"possible\", \"possible\", \"postal\", \"postal\", \"postal\", \"postal\", \"postal\", \"postal\", \"pound\", \"pound\", \"pound\", \"pound\", \"pound\", \"pound\", \"powder\", \"power\", \"power\", \"power\", \"power\", \"power\", \"power\", \"practise\", \"present\", \"present\", \"present\", \"present\", \"present\", \"present\", \"present\", \"prewar\", \"pribilof\", \"price\", \"price\", \"price\", \"price\", \"price\", \"price\", \"privateer\", \"problem\", \"problem\", \"problem\", \"problem\", \"problem\", \"problem\", \"product\", \"product\", \"product\", \"product\", \"product\", \"product\", \"production\", \"production\", \"production\", \"production\", \"production\", \"production\", \"program\", \"program\", \"program\", \"program\", \"program\", \"program\", \"proper\", \"proper\", \"proper\", \"proper\", \"proper\", \"proper\", \"provide\", \"provide\", \"provide\", \"provide\", \"provide\", \"provide\", \"public\", \"public\", \"public\", \"public\", \"public\", \"public\", \"public\", \"publicity\", \"publicity\", \"publicity\", \"publicity\", \"railroad\", \"railroad\", \"railroad\", \"railroad\", \"railroad\", \"railroad\", \"readjustment\", \"readjustment\", \"readjustment\", \"readjustment\", \"readjustment\", \"readjustment\", \"realistic\", \"realistic\", \"realistic\", \"rebate\", \"rebate\", \"rebate\", \"rebekah\", \"receive\", \"receive\", \"receive\", \"receive\", \"receive\", \"receive\", \"recommendation\", \"recommendation\", \"recommendation\", \"recommendation\", \"recommendation\", \"recommendation\", \"reconversion\", \"reconversion\", \"redress\", \"redress\", \"redress\", \"redress\", \"redress\", \"regional\", \"regional\", \"regional\", \"registry\", \"registry\", \"registry\", \"rehabilitation\", \"rehabilitation\", \"rehabilitation\", \"relief\", \"relief\", \"relief\", \"relief\", \"relief\", \"relief\", \"renegotiation\", \"report\", \"report\", \"report\", \"report\", \"report\", \"report\", \"reproductive\", \"reproductive\", \"republicans\", \"republicans\", \"result\", \"result\", \"result\", \"result\", \"result\", \"result\", \"reveals\", \"right\", \"right\", \"right\", \"right\", \"right\", \"right\", \"righteousness\", \"righteousness\", \"righteousness\", \"righteousness\", \"role\", \"role\", \"role\", \"rumania\", \"ryan\", \"samoa\", \"samoa\", \"samoa\", \"samoan\", \"samoan\", \"samoan\", \"satellite\", \"satellite\", \"satellite\", \"say\", \"say\", \"say\", \"say\", \"say\", \"say\", \"school\", \"school\", \"school\", \"school\", \"school\", \"school\", \"scour\", \"seasonal\", \"secretary\", \"secretary\", \"secretary\", \"secretary\", \"secretary\", \"secretary\", \"security\", \"security\", \"security\", \"security\", \"security\", \"security\", \"service\", \"service\", \"service\", \"service\", \"service\", \"service\", \"severalty\", \"severalty\", \"severalty\", \"shia\", \"shipowner\", \"shipper\", \"shipper\", \"shipper\", \"shipper\", \"shoal\", \"shoal\", \"shouldnt\", \"shouldnt\", \"show\", \"show\", \"show\", \"show\", \"show\", \"show\", \"significant\", \"significant\", \"significant\", \"significant\", \"significant\", \"silver\", \"silver\", \"silver\", \"silver\", \"silver\", \"silver\", \"sin\", \"slave\", \"slave\", \"slave\", \"slave\", \"slave\", \"slide\", \"slide\", \"slide\", \"slide\", \"smart\", \"smart\", \"smarter\", \"soar\", \"soar\", \"soviet\", \"soviet\", \"soviet\", \"soviet\", \"soviet\", \"spain\", \"spain\", \"spain\", \"spain\", \"spain\", \"spain\", \"specie\", \"specie\", \"specie\", \"specie\", \"specie\", \"spending\", \"spending\", \"spending\", \"spending\", \"spending\", \"stabilization\", \"stabilization\", \"stabilization\", \"standpoint\", \"standpoint\", \"standpoint\", \"standpoint\", \"state\", \"state\", \"state\", \"state\", \"state\", \"state\", \"state\", \"statistician\", \"statute\", \"statute\", \"statute\", \"statute\", \"statute\", \"statute\", \"stipulation\", \"stipulation\", \"stipulation\", \"stipulation\", \"strategic\", \"strategic\", \"strategic\", \"strategic\", \"strategic\", \"strategic\", \"strength\", \"strength\", \"strength\", \"strength\", \"strength\", \"strength\", \"subcontractor\", \"subcontractor\", \"subject\", \"subject\", \"subject\", \"subject\", \"subject\", \"subject\", \"substandard\", \"substandard\", \"suez\", \"suez\", \"suez\", \"suez\", \"sugar\", \"sugar\", \"sugar\", \"sugar\", \"sugar\", \"superintendence\", \"system\", \"system\", \"system\", \"system\", \"system\", \"system\", \"take\", \"take\", \"take\", \"take\", \"take\", \"take\", \"taper\", \"tariff\", \"tariff\", \"tariff\", \"tariff\", \"tariff\", \"tariff\", \"tax\", \"tax\", \"tax\", \"tax\", \"tax\", \"tax\", \"teacher\", \"teacher\", \"teacher\", \"teacher\", \"teacher\", \"teacher\", \"tech\", \"tech\", \"teen\", \"tell\", \"tell\", \"tell\", \"tell\", \"tell\", \"tell\", \"tenement\", \"tenement\", \"territory\", \"territory\", \"territory\", \"territory\", \"territory\", \"territory\", \"texan\", \"texas\", \"texas\", \"texas\", \"texas\", \"texas\", \"texas\", \"th\", \"th\", \"th\", \"th\", \"th\", \"th\", \"thank\", \"thank\", \"thank\", \"thank\", \"theyre\", \"theyre\", \"tho\", \"thru\", \"tile\", \"tile\", \"tiller\", \"tiller\", \"time\", \"time\", \"time\", \"time\", \"time\", \"time\", \"time\", \"today\", \"today\", \"today\", \"today\", \"today\", \"today\", \"ton\", \"ton\", \"ton\", \"ton\", \"ton\", \"ton\", \"tonight\", \"tonight\", \"tonight\", \"tonight\", \"tonight\", \"tonight\", \"total\", \"total\", \"total\", \"total\", \"total\", \"total\", \"treasury\", \"treasury\", \"treasury\", \"treasury\", \"treasury\", \"treasury\", \"treaty\", \"treaty\", \"treaty\", \"treaty\", \"treaty\", \"treaty\", \"tribe\", \"tribe\", \"tribe\", \"tribe\", \"tribe\", \"tuition\", \"tuition\", \"tv\", \"type\", \"type\", \"type\", \"type\", \"type\", \"type\", \"unhealthy\", \"united\", \"united\", \"united\", \"united\", \"united\", \"united\", \"united\", \"unjustified\", \"unnoticed\", \"unquestionable\", \"upon\", \"upon\", \"upon\", \"upon\", \"upon\", \"upon\", \"upon\", \"urban\", \"urban\", \"urban\", \"us\", \"us\", \"us\", \"us\", \"us\", \"us\", \"vaccine\", \"valparaiso\", \"valparaiso\", \"vegetation\", \"veteran\", \"veteran\", \"veteran\", \"veteran\", \"veteran\", \"veteran\", \"vicinity\", \"vietnam\", \"vietnam\", \"vietnamese\", \"virtuous\", \"vj\", \"vogue\", \"wage\", \"wage\", \"wage\", \"wage\", \"wage\", \"wage\", \"wageworker\", \"wageworkers\", \"want\", \"want\", \"want\", \"want\", \"want\", \"want\", \"war\", \"war\", \"war\", \"war\", \"war\", \"war\", \"wartime\", \"wartime\", \"wartime\", \"well\", \"well\", \"well\", \"well\", \"well\", \"well\", \"weve\", \"weve\", \"weve\", \"weve\", \"whilst\", \"whilst\", \"whilst\", \"willow\", \"win\", \"win\", \"win\", \"win\", \"win\", \"win\", \"without\", \"without\", \"without\", \"without\", \"without\", \"without\", \"wont\", \"wont\", \"wool\", \"wool\", \"wool\", \"wool\", \"work\", \"work\", \"work\", \"work\", \"work\", \"work\", \"work\", \"workforce\", \"workforce\", \"world\", \"world\", \"world\", \"world\", \"world\", \"world\", \"wrongdoer\", \"wrongdoer\", \"wrongdoer\", \"wrongdoing\", \"wrongdoing\", \"yarn\", \"year\", \"year\", \"year\", \"year\", \"year\", \"year\", \"year\", \"yosemite\", \"youre\", \"youre\", \"zoological\"]}, \"R\": 30, \"lambda.step\": 0.01, \"plot.opts\": {\"xlab\": \"PC1\", \"ylab\": \"PC2\"}, \"topic.order\": [2, 7, 3, 1, 6, 5, 4]};\n",
       "\n",
       "function LDAvis_load_lib(url, callback){\n",
       "  var s = document.createElement('script');\n",
       "  s.src = url;\n",
       "  s.async = true;\n",
       "  s.onreadystatechange = s.onload = callback;\n",
       "  s.onerror = function(){console.warn(\"failed to load library \" + url);};\n",
       "  document.getElementsByTagName(\"head\")[0].appendChild(s);\n",
       "}\n",
       "\n",
       "if(typeof(LDAvis) !== \"undefined\"){\n",
       "   // already loaded: just create the visualization\n",
       "   !function(LDAvis){\n",
       "       new LDAvis(\"#\" + \"ldavis_el1266658096501765502406605\", ldavis_el1266658096501765502406605_data);\n",
       "   }(LDAvis);\n",
       "}else if(typeof define === \"function\" && define.amd){\n",
       "   // require.js is available: use it to load d3/LDAvis\n",
       "   require.config({paths: {d3: \"https://d3js.org/d3.v5\"}});\n",
       "   require([\"d3\"], function(d3){\n",
       "      window.d3 = d3;\n",
       "      LDAvis_load_lib(\"https://cdn.jsdelivr.net/gh/bmabey/pyLDAvis@3.4.0/pyLDAvis/js/ldavis.v3.0.0.js\", function(){\n",
       "        new LDAvis(\"#\" + \"ldavis_el1266658096501765502406605\", ldavis_el1266658096501765502406605_data);\n",
       "      });\n",
       "    });\n",
       "}else{\n",
       "    // require.js not available: dynamically load d3 & LDAvis\n",
       "    LDAvis_load_lib(\"https://d3js.org/d3.v5.js\", function(){\n",
       "         LDAvis_load_lib(\"https://cdn.jsdelivr.net/gh/bmabey/pyLDAvis@3.4.0/pyLDAvis/js/ldavis.v3.0.0.js\", function(){\n",
       "                 new LDAvis(\"#\" + \"ldavis_el1266658096501765502406605\", ldavis_el1266658096501765502406605_data);\n",
       "            })\n",
       "         });\n",
       "}\n",
       "</script>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dictionary = corpora.Dictionary(df_speeches['word'])\n",
    "corpus = [dictionary.doc2bow(text) for text in df_speeches['word']]\n",
    "\n",
    "lda_model = gensim.models.LdaModel(corpus=corpus, \n",
    "                                   id2word=dictionary,\n",
    "                                   num_topics=7, \n",
    "                                   random_state=42,\n",
    "                                   passes=10)\n",
    "\n",
    "vis_data = gensimvis.prepare(lda_model, corpus, dictionary, n_jobs=1)\n",
    "pyLDAvis.display(vis_data)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For simplicity, I will analyze this model while lambda = 1. I chose 7 topics to represent the 7 parties in the dataset. The two largest topics, 1 and 4, are separated the furthest from each other in the Intertopic Distance Map, this suggests the words used in each topic have zero intersection and are clearly very different from each other. Each of the other topics, 2, 3, 5, and 6 appear in a range between topics 1 and 4. Topics 3 and 4 have overlap, but are distant from any other topics - this suggests, alongside the common words from these topics, that these two would topics would represent speeches coming from a particular class. Topics 1 and 2 overlap and their words from their associeted party are extremely similar. Topics 5 and 6 also overlap and are also extremely close to topics 1 and 2. Topic 7 seems to represent a speech from a party dissimilar from the other 6 parties. Based on the results from the Naive Bayes Classifier in the next question, these topic groups seem indicative of political parties - with  3 and 4 representing the republican party and 1, 2, 5, and 6 representing the democratic party and parties closely aligning with it. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#  Part II Prediction (40 points)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this part, you are asked to predict the president's political party (Republican/Democratic) using their speeches."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "def pres_to_party(name):\n",
    "    \"\"\"\n",
    "    Determines the political party affiliation of a U.S. President based on their name.\n",
    "\n",
    "    Parameters:\n",
    "    - name (str): The full name of a U.S. President.\n",
    "    \"\"\"\n",
    "    \n",
    "    republican = ['Abraham Lincoln', 'Ulysses S. Grant', 'Rutherford B. Hayes', 'Garfield', 'Chester A. Arthur', \n",
    "                  'Benjamin Harrison', 'William McKinley', 'Theodore Roosevelt', \n",
    "                  'William Howard Taft', 'Warren G. Harding', 'Calvin Coolidge', 'Herbert Hoover', 'Dwight D. Eisenhower', \n",
    "                  'Richard M. Nixon', 'Gerald R. Ford', 'Ronald Reagan', 'George Bush', \n",
    "                  'George W. Bush', 'Donald J. Trump']\n",
    "    if name in republican:\n",
    "        return 'Republican'\n",
    "    \n",
    "    democratic = ['Andrew Jackson', 'Martin Van Buren', 'James K. Polk', 'Franklin Pierce', \n",
    "                  'James Buchanan', 'Grover Cleveland', 'Woodrow Wilson', 'Franklin D. Roosevelt', \n",
    "                  'Harry S Truman', 'John F. Kennedy', 'Lyndon B. Johnson', 'Jimmy Carter', 'William J. Clinton', 'Barack Obama','Joseph R. Biden']\n",
    "    if name in democratic:\n",
    "        return 'Democratic'\n",
    "    \n",
    "    whig = ['William Henry Harrison', 'Zachary Taylor', 'Millard Fillmore']\n",
    "    if name in whig:\n",
    "        return 'Whig'\n",
    "    \n",
    "    national_union = ['Andrew Johnson']\n",
    "    if name in national_union:\n",
    "        return 'National Union'\n",
    "    \n",
    "    \n",
    "    unaffiliated = ['George Washington', 'John Tyler']\n",
    "    if name in unaffiliated:\n",
    "        return 'Unaffiliated'\n",
    "    \n",
    "    federalist = ['John Adams']\n",
    "    if name in federalist:\n",
    "        return 'Federalist'\n",
    "    \n",
    "    democratic_republican = ['Thomas Jefferson', 'James Madison', 'James Monroe', 'John Quincy Adams']\n",
    "    if name in democratic_republican:\n",
    "        return 'Democratic-Republican'\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>president</th>\n",
       "      <th>text</th>\n",
       "      <th>year</th>\n",
       "      <th>word</th>\n",
       "      <th>party</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>James Monroe</td>\n",
       "      <td>Fellow-Citizens of the Senate and House of Re...</td>\n",
       "      <td>1821</td>\n",
       "      <td>[fellow, citizen, senate, house, representativ...</td>\n",
       "      <td>Democratic-Republican</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>William McKinley</td>\n",
       "      <td>To the Senate and House of Representatives:\\r...</td>\n",
       "      <td>1897</td>\n",
       "      <td>[senate, house, representative, give, pleasure...</td>\n",
       "      <td>Republican</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Dwight D. Eisenhower</td>\n",
       "      <td>[Delivered in person before a joint session] \\...</td>\n",
       "      <td>1960</td>\n",
       "      <td>[deliver, person, joint, session, mr, presiden...</td>\n",
       "      <td>Republican</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Calvin Coolidge</td>\n",
       "      <td>Since the close of the last Congress the Natio...</td>\n",
       "      <td>1923</td>\n",
       "      <td>[since, close, last, congress, nation, lose, p...</td>\n",
       "      <td>Republican</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>James Madison</td>\n",
       "      <td>Fellow-Citizens of the Senate and House of Re...</td>\n",
       "      <td>1816</td>\n",
       "      <td>[fellow, citizen, senate, house, representativ...</td>\n",
       "      <td>Democratic-Republican</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>229</th>\n",
       "      <td>Donald J. Trump</td>\n",
       "      <td>Thank you very much. Mr. Speaker, Mr. Vice Pre...</td>\n",
       "      <td>2017</td>\n",
       "      <td>[thank, much, mr, speaker, mr, vice, president...</td>\n",
       "      <td>Republican</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>230</th>\n",
       "      <td>Donald J. Trump</td>\n",
       "      <td>Mr. Speaker, Mr. Vice President, Members of Co...</td>\n",
       "      <td>2018</td>\n",
       "      <td>[mr, speaker, mr, vice, president, member, con...</td>\n",
       "      <td>Republican</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>231</th>\n",
       "      <td>Donald J. Trump</td>\n",
       "      <td>Madam Speaker, Mr. Vice President, Members of ...</td>\n",
       "      <td>2019</td>\n",
       "      <td>[madam, speaker, mr, vice, president, member, ...</td>\n",
       "      <td>Republican</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>232</th>\n",
       "      <td>Donald J. Trump</td>\n",
       "      <td>Madam Speaker, Mr. Vice President, Members of ...</td>\n",
       "      <td>2020</td>\n",
       "      <td>[madam, speaker, mr, vice, president, member, ...</td>\n",
       "      <td>Republican</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>233</th>\n",
       "      <td>Joseph R. Biden</td>\n",
       "      <td>Madame Speaker.Madame Vice President.No presid...</td>\n",
       "      <td>2021</td>\n",
       "      <td>[madame, speakermadame, vice, presidentno, pre...</td>\n",
       "      <td>Democratic</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>234 rows × 5 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                president                                               text  \\\n",
       "0            James Monroe   Fellow-Citizens of the Senate and House of Re...   \n",
       "1        William McKinley   To the Senate and House of Representatives:\\r...   \n",
       "2    Dwight D. Eisenhower  [Delivered in person before a joint session] \\...   \n",
       "3         Calvin Coolidge  Since the close of the last Congress the Natio...   \n",
       "4           James Madison   Fellow-Citizens of the Senate and House of Re...   \n",
       "..                    ...                                                ...   \n",
       "229       Donald J. Trump  Thank you very much. Mr. Speaker, Mr. Vice Pre...   \n",
       "230       Donald J. Trump  Mr. Speaker, Mr. Vice President, Members of Co...   \n",
       "231       Donald J. Trump  Madam Speaker, Mr. Vice President, Members of ...   \n",
       "232       Donald J. Trump  Madam Speaker, Mr. Vice President, Members of ...   \n",
       "233       Joseph R. Biden  Madame Speaker.Madame Vice President.No presid...   \n",
       "\n",
       "     year                                               word  \\\n",
       "0    1821  [fellow, citizen, senate, house, representativ...   \n",
       "1    1897  [senate, house, representative, give, pleasure...   \n",
       "2    1960  [deliver, person, joint, session, mr, presiden...   \n",
       "3    1923  [since, close, last, congress, nation, lose, p...   \n",
       "4    1816  [fellow, citizen, senate, house, representativ...   \n",
       "..    ...                                                ...   \n",
       "229  2017  [thank, much, mr, speaker, mr, vice, president...   \n",
       "230  2018  [mr, speaker, mr, vice, president, member, con...   \n",
       "231  2019  [madam, speaker, mr, vice, president, member, ...   \n",
       "232  2020  [madam, speaker, mr, vice, president, member, ...   \n",
       "233  2021  [madame, speakermadame, vice, presidentno, pre...   \n",
       "\n",
       "                     party  \n",
       "0    Democratic-Republican  \n",
       "1               Republican  \n",
       "2               Republican  \n",
       "3               Republican  \n",
       "4    Democratic-Republican  \n",
       "..                     ...  \n",
       "229             Republican  \n",
       "230             Republican  \n",
       "231             Republican  \n",
       "232             Republican  \n",
       "233             Democratic  \n",
       "\n",
       "[234 rows x 5 columns]"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_speeches['party'] = df_speeches.president.apply(pres_to_party)\n",
    "df_speeches"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "party\n",
       "Democratic               90\n",
       "Democratic-Republican    28\n",
       "Federalist                4\n",
       "National Union            4\n",
       "Republican               93\n",
       "Unaffiliated             11\n",
       "Whig                      4\n",
       "dtype: int64"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_speeches.groupby('party').size()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We only consider Republican and Democratic here (df)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>president</th>\n",
       "      <th>text</th>\n",
       "      <th>year</th>\n",
       "      <th>word</th>\n",
       "      <th>party</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>William McKinley</td>\n",
       "      <td>To the Senate and House of Representatives:\\r...</td>\n",
       "      <td>1897</td>\n",
       "      <td>[senate, house, representative, give, pleasure...</td>\n",
       "      <td>Republican</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Dwight D. Eisenhower</td>\n",
       "      <td>[Delivered in person before a joint session] \\...</td>\n",
       "      <td>1960</td>\n",
       "      <td>[deliver, person, joint, session, mr, presiden...</td>\n",
       "      <td>Republican</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Calvin Coolidge</td>\n",
       "      <td>Since the close of the last Congress the Natio...</td>\n",
       "      <td>1923</td>\n",
       "      <td>[since, close, last, congress, nation, lose, p...</td>\n",
       "      <td>Republican</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Grover Cleveland</td>\n",
       "      <td>To the Congress of the United States:\\r\\n\\r\\n...</td>\n",
       "      <td>1886</td>\n",
       "      <td>[congress, united, state, discharge, constitut...</td>\n",
       "      <td>Democratic</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Theodore Roosevelt</td>\n",
       "      <td>To the Senate and House of Representatives:\\r...</td>\n",
       "      <td>1905</td>\n",
       "      <td>[senate, house, representative, people, countr...</td>\n",
       "      <td>Republican</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>178</th>\n",
       "      <td>Donald J. Trump</td>\n",
       "      <td>Thank you very much. Mr. Speaker, Mr. Vice Pre...</td>\n",
       "      <td>2017</td>\n",
       "      <td>[thank, much, mr, speaker, mr, vice, president...</td>\n",
       "      <td>Republican</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>179</th>\n",
       "      <td>Donald J. Trump</td>\n",
       "      <td>Mr. Speaker, Mr. Vice President, Members of Co...</td>\n",
       "      <td>2018</td>\n",
       "      <td>[mr, speaker, mr, vice, president, member, con...</td>\n",
       "      <td>Republican</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>180</th>\n",
       "      <td>Donald J. Trump</td>\n",
       "      <td>Madam Speaker, Mr. Vice President, Members of ...</td>\n",
       "      <td>2019</td>\n",
       "      <td>[madam, speaker, mr, vice, president, member, ...</td>\n",
       "      <td>Republican</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>181</th>\n",
       "      <td>Donald J. Trump</td>\n",
       "      <td>Madam Speaker, Mr. Vice President, Members of ...</td>\n",
       "      <td>2020</td>\n",
       "      <td>[madam, speaker, mr, vice, president, member, ...</td>\n",
       "      <td>Republican</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>182</th>\n",
       "      <td>Joseph R. Biden</td>\n",
       "      <td>Madame Speaker.Madame Vice President.No presid...</td>\n",
       "      <td>2021</td>\n",
       "      <td>[madame, speakermadame, vice, presidentno, pre...</td>\n",
       "      <td>Democratic</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>183 rows × 5 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                president                                               text  \\\n",
       "0        William McKinley   To the Senate and House of Representatives:\\r...   \n",
       "1    Dwight D. Eisenhower  [Delivered in person before a joint session] \\...   \n",
       "2         Calvin Coolidge  Since the close of the last Congress the Natio...   \n",
       "3        Grover Cleveland   To the Congress of the United States:\\r\\n\\r\\n...   \n",
       "4      Theodore Roosevelt   To the Senate and House of Representatives:\\r...   \n",
       "..                    ...                                                ...   \n",
       "178       Donald J. Trump  Thank you very much. Mr. Speaker, Mr. Vice Pre...   \n",
       "179       Donald J. Trump  Mr. Speaker, Mr. Vice President, Members of Co...   \n",
       "180       Donald J. Trump  Madam Speaker, Mr. Vice President, Members of ...   \n",
       "181       Donald J. Trump  Madam Speaker, Mr. Vice President, Members of ...   \n",
       "182       Joseph R. Biden  Madame Speaker.Madame Vice President.No presid...   \n",
       "\n",
       "     year                                               word       party  \n",
       "0    1897  [senate, house, representative, give, pleasure...  Republican  \n",
       "1    1960  [deliver, person, joint, session, mr, presiden...  Republican  \n",
       "2    1923  [since, close, last, congress, nation, lose, p...  Republican  \n",
       "3    1886  [congress, united, state, discharge, constitut...  Democratic  \n",
       "4    1905  [senate, house, representative, people, countr...  Republican  \n",
       "..    ...                                                ...         ...  \n",
       "178  2017  [thank, much, mr, speaker, mr, vice, president...  Republican  \n",
       "179  2018  [mr, speaker, mr, vice, president, member, con...  Republican  \n",
       "180  2019  [madam, speaker, mr, vice, president, member, ...  Republican  \n",
       "181  2020  [madam, speaker, mr, vice, president, member, ...  Republican  \n",
       "182  2021  [madame, speakermadame, vice, presidentno, pre...  Democratic  \n",
       "\n",
       "[183 rows x 5 columns]"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = df_speeches[df_speeches.party.isin(['Republican', 'Democratic'])]\n",
    "df.reset_index(inplace = True, drop = True)\n",
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Method 1: Naive Bayes Classifier (15 points)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Exercise 2:** Build a Naive Bayes Classifier. Use the first 140 speeches for training and the others for testing. Report the accuracy on test data and the most informative features."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Your Answer here:**\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy on test data: 0.6976744186046512\n",
      "\n",
      "Top 10 features for class 'Democratic':\n",
      "1. state\n",
      "2. government\n",
      "3. year\n",
      "4. make\n",
      "5. congress\n",
      "6. people\n",
      "7. country\n",
      "8. upon\n",
      "9. nation\n",
      "10. united\n",
      "\n",
      "Top 10 features for class 'Republican':\n",
      "1. government\n",
      "2. state\n",
      "3. make\n",
      "4. year\n",
      "5. congress\n",
      "6. country\n",
      "7. great\n",
      "8. law\n",
      "9. people\n",
      "10. upon\n"
     ]
    }
   ],
   "source": [
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "df['text_processed'] = df['word'].apply(lambda x: ' '.join(x))\n",
    "\n",
    "train_data = df.iloc[:140]\n",
    "test_data = df.iloc[140:]\n",
    "\n",
    "vectorizer = CountVectorizer()\n",
    "X_train = vectorizer.fit_transform(train_data['text_processed'])\n",
    "y_train = train_data['party']\n",
    "X_test = vectorizer.transform(test_data['text_processed'])\n",
    "y_test = test_data['party']\n",
    "\n",
    "nb_classifier = MultinomialNB()\n",
    "nb_classifier.fit(X_train, y_train)\n",
    "\n",
    "y_pred = nb_classifier.predict(X_test)\n",
    "\n",
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "print(\"Accuracy on test data:\", accuracy)\n",
    "\n",
    "feature_names = vectorizer.get_feature_names_out()\n",
    "class_labels = nb_classifier.classes_\n",
    "top_n = 10  \n",
    "\n",
    "log_probs = nb_classifier.feature_log_prob_\n",
    "\n",
    "for i, class_label in enumerate(class_labels):\n",
    "    print(f\"\\nTop {top_n} features for class '{class_label}':\")\n",
    "    class_log_probs = log_probs[i]\n",
    "    top_feature_indices = class_log_probs.argsort()[-top_n:][::-1]\n",
    "    top_features = [feature_names[idx] for idx in top_feature_indices]\n",
    "    for j, feature in enumerate(top_features, start=1):\n",
    "        print(f\"{j}. {feature}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Method 2: Word2Vec + Classification (25 points)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 1: Generate Word Vectors"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Exercise 3:** Build up a word2vec model to generate word vectors. Remember to choose the appropriate parameters for your model."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Your Answer here:**\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [],
   "source": [
    "from gensim.models import Word2Vec\n",
    "\n",
    "sentences = df_speeches['word'].tolist()\n",
    "model = Word2Vec(sentences, window=10, vector_size=3, epochs=50, negative=5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Run the following code to test your model. Is the output of your model correct?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'france'"
      ]
     },
     "execution_count": 65,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Which one is the odd one out in this list?\n",
    "model.wv.doesnt_match([\"cat\",\"dog\",\"france\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Run the following code, embedding word vectors into a 2D plane."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [],
   "source": [
    "def reduce_to_k_dim(M, k=2):  \n",
    "    \"\"\"\n",
    "    Reduces the dimensionality of a matrix M to k dimensions using Truncated Singular Value Decomposition (SVD).\n",
    "    \n",
    "    Parameters:\n",
    "    - M (array-like): The high-dimensional data matrix to be reduced. Each row represents a data point.\n",
    "    - k (int, optional): The target number of dimensions. Default is 2.\n",
    "    \"\"\"\n",
    "\n",
    "    n_iters = 10     # Use this parameter in your call to `TruncatedSVD`\n",
    "    M_reduced = None\n",
    "    print(\"Running Truncated SVD over %i words...\" % (M.shape[0]))\n",
    "\n",
    "    from sklearn.decomposition import TruncatedSVD\n",
    "    svd = TruncatedSVD(n_components = k, n_iter = n_iters,random_state = 1)\n",
    "    #a   = svd.fit(M)\n",
    "    M_reduced = svd.fit_transform(M)\n",
    "    print(\"Done.\")\n",
    "    return M_reduced"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_matrix_of_vectors(wv_from_bin):\n",
    "    \"\"\"\n",
    "    Creates a matrix of word vectors from a word2vec model and a corresponding dictionary to map words to their indices in the matrix.\n",
    "\n",
    "    Parameters:\n",
    "    - wv_from_bin: A word2vec model loaded, for example, using Gensim's KeyedVectors.\n",
    "    \"\"\"\n",
    "\n",
    "    import random\n",
    "    words = list(wv_from_bin.key_to_index.keys())\n",
    "    print(\"Shuffling words ...\")\n",
    "    random.shuffle(words)\n",
    "    print(f\"Putting {len(words)} words into word2Ind and matrix M...\")\n",
    "    word2Ind = {}\n",
    "    M = []\n",
    "    curInd = 0\n",
    "    for w in words:\n",
    "        try:\n",
    "            # Use get_vector method instead of deprecated word_vec\n",
    "            M.append(wv_from_bin.get_vector(w))\n",
    "            word2Ind[w] = curInd\n",
    "            curInd += 1\n",
    "        except KeyError:\n",
    "            continue\n",
    "    M = np.stack(M)\n",
    "    print(\"Done.\")\n",
    "    return M, word2Ind"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_embeddings(M_reduced, word2Ind, words):\n",
    "    \"\"\"\n",
    "    Plots a scatter plot of word embeddings for a subset of words.\n",
    "\n",
    "    Parameters:\n",
    "    - M_reduced (numpy.ndarray): A matrix of word embeddings reduced to 2 dimensions. Each row corresponds to a word.\n",
    "    - word2Ind (dict): A dictionary mapping words to their indices in the M_reduced matrix.\n",
    "    - words (list of str): A list of words to plot. These words should be keys in word2Ind.    \n",
    "    \"\"\"\n",
    "\n",
    "    plt.figure(figsize = (12,8))\n",
    "    for i,word in enumerate(words):\n",
    "        x = M_reduced[(word2Ind.get(word),0)]\n",
    "        y = M_reduced[(word2Ind.get(word),1)]\n",
    "        plt.scatter(x, y, marker='x', color='red')\n",
    "        plt.text(x+0.01, y+0.01, word, fontsize=18)\n",
    "\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shuffling words ...\n",
      "Putting 8507 words into word2Ind and matrix M...\n",
      "Done.\n"
     ]
    }
   ],
   "source": [
    "M, word2Ind = get_matrix_of_vectors(model.wv)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running Truncated SVD over 8507 words...\n",
      "Done.\n"
     ]
    }
   ],
   "source": [
    "# truncated 2D word2vec matrix\n",
    "M_reduced = reduce_to_k_dim(M, k=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 1200x800 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# 2D visualization\n",
    "words = [\"free\",\"wonderful\",\"quiet\",\"impressive\",\"good\",'government','sad','happy','serious','false','sovereign']\n",
    "plot_embeddings(M_reduced, word2Ind, words)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 2: Multi-layer Perceptron (MLP) Classifier"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Exercise 4:** Build a Multi-layer Perceptron (MLP) Classifier to predicte the political party of the president using mean word vectors (the average of word vectors for each review) as features. Use the first 140 speeches for training and the others for testing. Report the accuracy on test data."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Your Answer here:**\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [],
   "source": [
    "##############################################################################\n",
    "### TODO: Create Average Word Vectors for each Review                      ###\n",
    "##############################################################################\n",
    "def calculate_average_word_vectors(tokens_list, model):\n",
    "    num_features = model.vector_size\n",
    "    feature_vectors = np.zeros((len(tokens_list), num_features), dtype=\"float32\")\n",
    "    for i, tokens in enumerate(tokens_list):\n",
    "        feature_vectors[i] = np.mean([model.wv[token] for token in tokens if token in model.wv], axis=0)\n",
    "    return feature_vectors\n",
    "\n",
    "X_train_avg = calculate_average_word_vectors(train_data['word'], model)\n",
    "X_test_avg = calculate_average_word_vectors(test_data['word'], model)\n",
    "##############################################################################\n",
    "#                               END OF YOUR CODE                             #\n",
    "##############################################################################"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy of MLP Classifier on test data: 0.7209302325581395\n"
     ]
    }
   ],
   "source": [
    "with warnings.catch_warnings():\n",
    "    warnings.simplefilter(\"ignore\", category=DeprecationWarning) # ignore warning during model training\n",
    "    \n",
    "##############################################################################\n",
    "### TODO: Build an MLP Classifier and Report Accuracy on Test Data         ###\n",
    "##############################################################################\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "\n",
    "mlp_classifier = MLPClassifier(hidden_layer_sizes=(100,), max_iter=1000, random_state=42)\n",
    "mlp_classifier.fit(X_train_avg, y_train)\n",
    "\n",
    "y_pred_mlp = mlp_classifier.predict(X_test_avg)\n",
    "\n",
    "accuracy_mlp = accuracy_score(y_test, y_pred_mlp)\n",
    "print(\"Accuracy of MLP Classifier on test data:\", accuracy_mlp)\n",
    "##############################################################################\n",
    "#                               END OF YOUR CODE                             #\n",
    "##############################################################################"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Problem 2: BERT and Emotions Classification (50 points)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data\n",
    "\n",
    "Demszky et al. (2020) introduced the GoEmotions dataset, consisting of 58K Reddit comments, each labeled for one or more of 27 emotions or neutral (28 in total). Specifically, the dataset encompasses comments from Reddit's inception in 2005 up to January 2019. The subreddits with at least 10k comments were selected, and non-English comments are removed. Demszky et al. (2020) preprocess the comments data to reduce profanity and balance between categories. Te be specific, the following preprocessings are performed: Reducing profanity, manual review, sentiment balancing, emotion balancing, subreddit balancing, and masking. After preprocessing, the size of the total GoEmotions dataset is 54,263, including 43,410 for training (80%), 5,426 for validation (10%), and 5,427 for test (10%).\n",
    "\n",
    "There are 28 emotions: neutral, admiration, amusement, anger, annoyance, approval, caring, confusion, curiosity, desire, disappointment, disapproval, disgust, embarrassment, excitement, fear, gratitude, grief, joy, love, nervousness, optimism, pride, realization, relief, remorse, sadness, surprise. \n",
    "\n",
    "You can refer to the GoEmotions paper or HuggingFace: https://huggingface.co/datasets/go_emotions.\n",
    "\n",
    "We only have a subsample of this dataset for your final project for simplicity. We have provided with the data file `reddit.tsv`."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## BERT Embeddings\n",
    "\n",
    "**BERT** (Bidirectional Encoder Representations from Transformers) is a revolutionary model in the field of natural language processing (NLP) introduced by researchers at Google in 2018. BERT's breakthrough is its ability to train language models based on the entire set of words in a sentence or query (bidirectionally), rather than the traditional way of training on the order of words (left-to-right or right-to-left). This approach allows the model to capture the context of a word based on all of its surroundings, leading to a deeper understanding of language.\n",
    "\n",
    "Here are some key concepts that are good to know:\n",
    "\n",
    "- **Transformer**: BERT is built on the Transformer architecture, introduced in the paper \"Attention is All You Need\" by Vaswani et al. The Transformer model uses self-attention mechanisms to weigh the significance of different words in a sentence. Unlike previous models that processed words in sequence, the Transformer treats sentences as a whole, enabling parallel processing and significantly reducing training times.\n",
    "\n",
    "- **Bidirectional Context**: BERT's key innovation is its bidirectional training of the Transformer. Traditional language models were limited to unidirectional training, which could only consider the context from one direction (either from left to right or vice versa). BERT, however, uses a \"masked language model\" (MLM) pre-training objective, where some percentage of the input tokens are masked at random, and the goal is to predict these masked tokens based on the context provided by the non-masked tokens in the sequence.\n",
    "\n",
    "- **Pre-training** and **Fine-tuning**\n",
    "\n",
    "    - Pre-training: BERT is pre-trained on a large corpus of text from the BookCorpus and English Wikipedia. During pre-training, it learns language representations by optimizing two objectives: the Masked Language Model (MLM) and Next Sentence Prediction (NSP). MLM helps BERT understand the bidirectional context of words, while NSP enables it to understand the relationships between sentences.\n",
    "    \n",
    "    - Fine-tuning: After pre-training, BERT can be fine-tuned with just one additional output layer to create state-of-the-art models for a wide range of tasks, such as question answering, sentiment analysis, and language inference, without substantial modifications to the model architecture.\n",
    "\n",
    "Here are some technical details about BERT if you are interested:\n",
    "\n",
    "- **Model size**: BERT comes in several sizes, the two primary variants being BERT-Base and BERT-Large. BERT-Base consists of 12 layers (transformer blocks), 768 hidden units (size of the embeddings), and 12 self-attention heads, totaling about 110 million parameters. BERT-Large upscales this to 24 layers, 1024 hidden units, and 16 self-attention heads, totaling about 340 million parameters.\n",
    "\n",
    "- **Input representation**: BERT's input representation is designed to handle a wide variety of NLP tasks without modification. Each input embedding is a combination of three embeddings:\n",
    "\n",
    "    - Token Embeddings: WordPiece embeddings with a 30,000 token vocabulary.\n",
    "    \n",
    "    - Segment Embeddings: Differentiated embeddings to distinguish between sentences in tasks that involve multiple sentences (e.g., question answering).\n",
    "    \n",
    "    - Positional Embeddings: To encode the sequence order of words.\n",
    "\n",
    "- **Attention Mechanism**: The core of BERT's Transformer architecture is the attention mechanism, specifically \"multi-head self-attention\". This mechanism allows the model to focus on different parts of the input sequence when understanding each word, considering the entire context of the sentence or sequence, both to the left and the right of the target word.\n",
    "\n",
    "https://lilianweng.github.io/posts/2019-01-31-lm/ is a great article to read, introducing a list of methods and algorithm in Natural Language Processing and Language Models. You can read it for your own interest and know more about the progress in NLP (until 5 years ago)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "# !pip install transformers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import torch\n",
    "from transformers import (\n",
    "    BertModel,\n",
    "    BertTokenizer,\n",
    ")\n",
    "from tqdm import tqdm\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "import pickle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>emotion</th>\n",
       "      <th>id</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>I’m really sorry about your situation :( Altho...</td>\n",
       "      <td>25</td>\n",
       "      <td>eecwqtt</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>It's wonderful because it's awful. At not with.</td>\n",
       "      <td>0</td>\n",
       "      <td>ed5f85d</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Kings fan here, good luck to you guys! Will be...</td>\n",
       "      <td>13</td>\n",
       "      <td>een27c3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>I didn't know that, thank you for teaching me ...</td>\n",
       "      <td>15</td>\n",
       "      <td>eelgwd1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>They got bored from haunting earth for thousan...</td>\n",
       "      <td>27</td>\n",
       "      <td>eem5uti</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                text emotion       id\n",
       "0  I’m really sorry about your situation :( Altho...      25  eecwqtt\n",
       "1    It's wonderful because it's awful. At not with.       0  ed5f85d\n",
       "2  Kings fan here, good luck to you guys! Will be...      13  een27c3\n",
       "3  I didn't know that, thank you for teaching me ...      15  eelgwd1\n",
       "4  They got bored from haunting earth for thousan...      27  eem5uti"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Read data\n",
    "df = pd.read_csv(\"reddit.tsv\", sep=\"\\t\", header=None)\n",
    "df.columns = ['text', 'emotion', 'id']\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████| 5427/5427 [00:02<00:00, 2697.70it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tokenized texts: [[101, 1045, 1521, 1049, 2428, 3374, 2055, 2115, 3663, 1024, 1006, 2348, 1045, 2293, 1996, 3415, 20066, 21850, 2527, 1010, 25022, 24714, 2050, 1010, 1998, 20862, 999, 102], [101, 2009, 1005, 1055, 6919, 2138, 2009, 1005, 1055, 9643, 1012, 2012, 2025, 2007, 1012, 102], [101, 5465, 5470, 2182, 1010, 2204, 6735, 2000, 2017, 4364, 999, 2097, 2022, 2019, 5875, 2208, 2000, 3422, 999, 102], [101, 1045, 2134, 1005, 1056, 2113, 2008, 1010, 4067, 2017, 2005, 4252, 2033, 2242, 2651, 999, 102], [101, 2027, 2288, 11471, 2013, 20161, 3011, 2005, 5190, 1997, 2086, 1998, 4821, 2333, 2006, 2000, 1996, 25115, 1012, 102]]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "with warnings.catch_warnings():\n",
    "    warnings.simplefilter(\"ignore\", category=DeprecationWarning) \n",
    "    \n",
    "##############################################################################\n",
    "### TODO: Construct a BERT tokenizer and model based on the pre-trained model 'bert-base-uncased' ###\n",
    "### TODO: Encode the text into tokens ###\n",
    "##############################################################################\n",
    "import torch\n",
    "from transformers import BertModel, BertTokenizer\n",
    "from tqdm import tqdm\n",
    "\n",
    "tokenizer = BertTokenizer.from_pretrained('bert-base-uncased')\n",
    "model = BertModel.from_pretrained('bert-base-uncased')\n",
    "\n",
    "tokenized_texts = []\n",
    "for text in tqdm(df['text']):\n",
    "    tokenized_text = tokenizer.encode(text, add_special_tokens=True)\n",
    "    tokenized_texts.append(tokenized_text)\n",
    "\n",
    "print(\"Tokenized texts:\", tokenized_texts[:5])\n",
    "##############################################################################\n",
    "#                               END OF YOUR CODE                             #\n",
    "##############################################################################"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generate BERT embeddings for text data\n",
    "def get_bert_embeddings(text):\n",
    "    # Tokenize the text\n",
    "    tokens = tokenizer(text, return_tensors=\"pt\", truncation=True, max_length=50)\n",
    "    \n",
    "    # Forward pass through BERT model\n",
    "    with torch.no_grad():\n",
    "        outputs = model(**tokens)\n",
    "    \n",
    "    # Extract the output embeddings and mean pooling\n",
    "    embedding = outputs.last_hidden_state.mean(axis=(0, 1)).numpy()\n",
    "    \n",
    "    return embedding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Applying BERT embeddings: 100%|█████████████| 5427/5427 [10:00<00:00,  9.04it/s]\n"
     ]
    }
   ],
   "source": [
    "# ~5-10 minutes running time\n",
    "tqdm.pandas(desc=\"Applying BERT embeddings\")\n",
    "\n",
    "# Convert text to BERT embeddings\n",
    "df['embedding'] = df['text'].progress_apply(get_bert_embeddings)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>emotion</th>\n",
       "      <th>id</th>\n",
       "      <th>embedding</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>I’m really sorry about your situation :( Altho...</td>\n",
       "      <td>25</td>\n",
       "      <td>eecwqtt</td>\n",
       "      <td>[0.08825632, -0.06718819, 0.1527591, -0.310085...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>It's wonderful because it's awful. At not with.</td>\n",
       "      <td>0</td>\n",
       "      <td>ed5f85d</td>\n",
       "      <td>[0.06496311, 0.18670015, 0.26324463, 0.0971679...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Kings fan here, good luck to you guys! Will be...</td>\n",
       "      <td>13</td>\n",
       "      <td>een27c3</td>\n",
       "      <td>[0.30238152, -0.19871923, 0.5790955, 0.1019106...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>I didn't know that, thank you for teaching me ...</td>\n",
       "      <td>15</td>\n",
       "      <td>eelgwd1</td>\n",
       "      <td>[0.10757125, 0.11642991, 0.12003417, 0.1528351...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>They got bored from haunting earth for thousan...</td>\n",
       "      <td>27</td>\n",
       "      <td>eem5uti</td>\n",
       "      <td>[0.6161459, 0.041393895, 0.23162544, 0.3027191...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                text emotion       id  \\\n",
       "0  I’m really sorry about your situation :( Altho...      25  eecwqtt   \n",
       "1    It's wonderful because it's awful. At not with.       0  ed5f85d   \n",
       "2  Kings fan here, good luck to you guys! Will be...      13  een27c3   \n",
       "3  I didn't know that, thank you for teaching me ...      15  eelgwd1   \n",
       "4  They got bored from haunting earth for thousan...      27  eem5uti   \n",
       "\n",
       "                                           embedding  \n",
       "0  [0.08825632, -0.06718819, 0.1527591, -0.310085...  \n",
       "1  [0.06496311, 0.18670015, 0.26324463, 0.0971679...  \n",
       "2  [0.30238152, -0.19871923, 0.5790955, 0.1019106...  \n",
       "3  [0.10757125, 0.11642991, 0.12003417, 0.1528351...  \n",
       "4  [0.6161459, 0.041393895, 0.23162544, 0.3027191...  "
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save data with BERT embeddings to .pkl file so that we can use it later and avoid re-running the time-consuming codes above\n",
    "with open('data_with_embeddings.pkl', 'wb') as f:\n",
    "    pickle.dump(df, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>emotion</th>\n",
       "      <th>id</th>\n",
       "      <th>embedding</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>I’m really sorry about your situation :( Altho...</td>\n",
       "      <td>25</td>\n",
       "      <td>eecwqtt</td>\n",
       "      <td>[0.08825632, -0.06718819, 0.1527591, -0.310085...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>It's wonderful because it's awful. At not with.</td>\n",
       "      <td>0</td>\n",
       "      <td>ed5f85d</td>\n",
       "      <td>[0.06496311, 0.18670015, 0.26324463, 0.0971679...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Kings fan here, good luck to you guys! Will be...</td>\n",
       "      <td>13</td>\n",
       "      <td>een27c3</td>\n",
       "      <td>[0.30238152, -0.19871923, 0.5790955, 0.1019106...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>I didn't know that, thank you for teaching me ...</td>\n",
       "      <td>15</td>\n",
       "      <td>eelgwd1</td>\n",
       "      <td>[0.10757125, 0.11642991, 0.12003417, 0.1528351...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>They got bored from haunting earth for thousan...</td>\n",
       "      <td>27</td>\n",
       "      <td>eem5uti</td>\n",
       "      <td>[0.6161459, 0.041393895, 0.23162544, 0.3027191...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                text emotion       id  \\\n",
       "0  I’m really sorry about your situation :( Altho...      25  eecwqtt   \n",
       "1    It's wonderful because it's awful. At not with.       0  ed5f85d   \n",
       "2  Kings fan here, good luck to you guys! Will be...      13  een27c3   \n",
       "3  I didn't know that, thank you for teaching me ...      15  eelgwd1   \n",
       "4  They got bored from haunting earth for thousan...      27  eem5uti   \n",
       "\n",
       "                                           embedding  \n",
       "0  [0.08825632, -0.06718819, 0.1527591, -0.310085...  \n",
       "1  [0.06496311, 0.18670015, 0.26324463, 0.0971679...  \n",
       "2  [0.30238152, -0.19871923, 0.5790955, 0.1019106...  \n",
       "3  [0.10757125, 0.11642991, 0.12003417, 0.1528351...  \n",
       "4  [0.6161459, 0.041393895, 0.23162544, 0.3027191...  "
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Load data with BERT embeddings\n",
    "with open('data_with_embeddings.pkl', 'rb') as f1:\n",
    "    df1 = pickle.load(f1)\n",
    "\n",
    "df1.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "##############################################################################\n",
    "### TODO: Use the BERT embeddings as features and the emotion as the target variable ###\n",
    "### TODO: Split the data into training and testing sets (test_size=0.2) ###\n",
    "##############################################################################\n",
    "X = np.array(df1['embedding'].tolist())\n",
    "y = df1['emotion']\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "##############################################################################\n",
    "#                               END OF YOUR CODE                             #\n",
    "##############################################################################"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Logistic Regression Accuracy: 0.3876611418047882\n"
     ]
    }
   ],
   "source": [
    "##############################################################################\n",
    "### TODO: Perform Logistic Regression to fit the training data, predict the emotion, \n",
    "### and calculate the prediction accuracy ###\n",
    "##############################################################################\n",
    "log_reg = LogisticRegression()\n",
    "log_reg.fit(X_train, y_train)\n",
    "y_pred_log_reg = log_reg.predict(X_test)\n",
    "accuracy_log_reg = accuracy_score(y_test, y_pred_log_reg)\n",
    "print(\"Logistic Regression Accuracy:\", accuracy_log_reg)\n",
    "##############################################################################\n",
    "#                               END OF YOUR CODE                             #\n",
    "##############################################################################"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Random Forest Accuracy: 0.3434622467771639\n"
     ]
    }
   ],
   "source": [
    "##############################################################################\n",
    "### TODO: Perform Random Forest to fit the training data, predict the emotion, \n",
    "### and calculate the prediction accuracy ###\n",
    "##############################################################################\n",
    "rf = RandomForestClassifier()\n",
    "rf.fit(X_train, y_train)\n",
    "y_pred_rf = rf.predict(X_test)\n",
    "accuracy_rf = accuracy_score(y_test, y_pred_rf)\n",
    "print(\"Random Forest Accuracy:\", accuracy_rf)\n",
    "##############################################################################\n",
    "#                               END OF YOUR CODE                             #\n",
    "##############################################################################"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
